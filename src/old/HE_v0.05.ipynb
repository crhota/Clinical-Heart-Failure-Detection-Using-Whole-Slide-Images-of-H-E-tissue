{"nbformat":4,"nbformat_minor":0,"metadata":{"@webio":{"lastCommId":null,"lastKernelId":null},"colab":{"name":"HE_v0.05.ipynb","provenance":[],"collapsed_sections":["AvHgttBNTUx2","8QpqHhxkTUx2","G-HdlAy_TUx3","iVqvp6TDTUx4","-MOqlD8qTUx4","mtvpF6A6TUyG"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VTkgKJvoTUxt"},"source":["# Clinical Heart Failure Detection Using Whole-Slide Images of H&E tissue"]},{"cell_type":"markdown","metadata":{"id":"Z__HJG6gIxMj"},"source":["## Version"]},{"cell_type":"markdown","metadata":{"id":"4E9zAmtKTUx1"},"source":["- **0.05**: Migrate to Google Colab/Drive, changed loss function to 'binary_crossentropy', epochs to 1 : Train/Val/Test Acc = 55.7/55.9/55.2\n","- **0.04**: Class Label Info in List was not accurate - fixed it. Now, Train/Validate/Test Accuracy is more realistic = ~55%\n","- **0.03**: Tweak CNN model done for MNIST to work for this dataset to have a working end to end CNN model. Train/Validate/Test Accuracy = ~100%\n","- **0.02**: Prepare Train/Validate/Test Labels and Images \n","- **0.01**: Prepare Train/Validate/Test Images"]},{"cell_type":"markdown","metadata":{"id":"aTijnel0I8P9"},"source":["## Improvement Opportunity"]},{"cell_type":"markdown","metadata":{"id":"43vNOnzBTUx1"},"source":["- Convert code sections in data preparation for train/validation/test to functions\n","- As this is a 2 class classification - loss function can be changed to binary_crossentropy instead of categorical_crossentropy\n","- Reduce parameters, epochs."]},{"cell_type":"markdown","metadata":{"id":"GELaKt4nTUx2"},"source":["## Download Dataset"]},{"cell_type":"markdown","metadata":{"id":"AvHgttBNTUx2"},"source":["### Download Train, Validate and Test Images\n","- Source Link to the Dataset / Annotation File: https://idr.openmicroscopy.org/webclient/?show=project-402\n","- Follow the instructions at following link, install IBM Aspera Desktop Client to download the dataset.\n","- Copy downloaded folders to '**data/images**' folder in your working directory where you have this Jupyter Notebook:\n","  - 'held-out_validation'\n","  - 'training'"]},{"cell_type":"markdown","metadata":{"id":"8QpqHhxkTUx2"},"source":["### Download Label Information for Train, Validate and Test Images \n","- Following link will point to below Github link which has the annotation File: https://idr.openmicroscopy.org/webclient/?show=project-402\n","- Source Link for the Annotation File: https://github.com/IDR/idr0042-nirschl-wsideeplearning/tree/master/experimentA\n","- Download and copy file '**idr0042-experimentA-annotation.csv**' to '**data/labels/**' folder in your working directory where you have this Jupyter Notebook"]},{"cell_type":"markdown","metadata":{"id":"jV7ukSgPJKra"},"source":["## References"]},{"cell_type":"markdown","metadata":{"id":"G-HdlAy_TUx3"},"source":["#### Data Preparation\n","- Access Google Drive files from Google Colab\n","  - https://www.youtube.com/watch?reload=9&v=lHRC5gFvQnA\n","- Reading an image\n","  - mathplotlib: https://stackoverflow.com/questions/9298665/cannot-import-scipy-misc-imread\n","  - pathlib: https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f#:~:text=To%20use%20it%2C%20you%20just,for%20the%20current%20operating%20system.\n","  - OpenCV: https://www.geeksforgeeks.org/python-opencv-cv2-imread-method/\n","- Load multiple images into a numpy array\n","  - glob / os.listdir: https://stackoverflow.com/questions/39195113/how-to-load-multiple-images-in-a-numpy-array\n","  - glob / cv2: https://medium.com/@muskulpesent/create-numpy-array-of-images-fecb4e514c4b\n","- Load a CSV file\n","  - Datacamp: https://www.datacamp.com/community/tutorials/pandas-read-csv?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=278443377095&utm_targetid=dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=9061994&gclid=EAIaIQobChMIz5TKz-v17QIV1AorCh0bfw96EAAYASAAEgKiGPD_BwE\n","- Split a String\n","  - Python Central: https://www.pythoncentral.io/cutting-and-slicing-strings-in-python/\n"]},{"cell_type":"markdown","metadata":{"id":"YYdvA7O8KAK0"},"source":["## Understand Dataset"]},{"cell_type":"markdown","metadata":{"id":"iVqvp6TDTUx4"},"source":["### Understand Images Folder Structure and Number of Images Available\n","\n","Training/Validation\n","- \\..\\training\\fold_1: has images for training = 770#\n","- \\..\\training\\test_fold_1: has images for validation = 374#\n","- Total = 770 + 374 = 1144 images\n","\n","Test\n","- \\..\\held-out_validation: has images for testing = 1155#"]},{"cell_type":"markdown","metadata":{"id":"-MOqlD8qTUx4"},"source":["### Understand Annotation File and Label Information Available\n","\n","Relevant columns of interest:\n","- Column A: Dataset Name: Classifies each row/instance as 'training' or 'test'\n","- Column B: Image Name: Specifies filename of the image for the row/instance\n","- Column Z: Experimental Condition [Diagnosis]: has 3 classes:\n","  - 'chronic heart failure'\n","  - 'heart tissue pathology' - We will treat this as 'not chronic heart failure'\n","  - 'not chronic heart failure'\n","- Column AA: Channels: mentions RGB => images are color images and will have 3 channels Red/Green/Blue (for CNN). \n","  \n","Breakup of training/test instances:\n","- training\n","  - 'chronic heart failure' = 517\n","  - 'not chronic heart failure' = 627\n","- test\n","  - 'chronic heart failure' = 517\n","  - 'not chronic heart failure' = 638\n","\n","Total 'training' = 517 + 627 = 1144  (Note: 'validate' is a portion of this 'training' set.)\n","\n","Total 'test' = 517 + 638 = 1155"]},{"cell_type":"markdown","metadata":{"id":"4Oem7YyjKL7Z"},"source":["## Load Libraries"]},{"cell_type":"markdown","metadata":{"id":"BxnppA2lTUx4"},"source":["We need to read 'train, validate and test images' to arrays so that we can then use them to feed to our CNN model. We need to import the annotation file into a dataframe so that we can then access the labels information."]},{"cell_type":"code","metadata":{"id":"4rqxeoKlTUx5"},"source":["# install OpenCV package - this is required only once\n","# pip install opencv-python"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvKVTkfxTUx5"},"source":["# aids in reading image files\r\n","import cv2\r\n","import glob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yhluyj4TUx6"},"source":["# aids in working with arrays\r\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qyBfK1j9TUx6"},"source":["# aids in working with dataframes\r\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fL4wKtMLhw3"},"source":["We need to mount the google drive so that we can then access the files from google drive."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhVh4qU1U47e","executionInfo":{"status":"ok","timestamp":1610603769621,"user_tz":-330,"elapsed":1886,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"4fbe3818-9554-4d09-8c77-43255b9da1f3"},"source":["# run this. click on the link it will ask for. get the authentication code. Copy/Paste in the cell. Hit Enter.\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rmu8WoMlNJFY"},"source":["## Get labels info into a dataframe"]},{"cell_type":"code","metadata":{"id":"COjL64aeTUx7"},"source":["# Google Drive / Colab\r\n","filepath_annotation_file = r'/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/labels/idr0042-experimentA-annotation.csv'\r\n","labels = pd.read_csv(filepath_annotation_file)\r\n","\r\n","# Local Drive / Jupyter\r\n","# labels = pd.read_csv('data/labels/idr0042-experimentA-annotation.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Umta4jPKMzCR"},"source":["### Explore and Understand"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":793},"id":"nr21_2SiTUx7","executionInfo":{"status":"ok","timestamp":1610603770252,"user_tz":-330,"elapsed":2502,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"48e146a6-6a5d-45c2-c33e-60c101d58a1d"},"source":["# uncomment & check the contents of labels is as expected\r\n","labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset Name</th>\n","      <th>Image Name</th>\n","      <th>Characteristics [Organism]</th>\n","      <th>Term Source 1 REF</th>\n","      <th>Term Source 1 Accession</th>\n","      <th>Characteristics [Organism Part]</th>\n","      <th>Term Source 2 REF</th>\n","      <th>Term Source 2 Accession</th>\n","      <th>Characteristics [Diagnosis]</th>\n","      <th>Term Source 3 REF</th>\n","      <th>Term Source 3 Accession</th>\n","      <th>Characteristics [Disease Subtype]</th>\n","      <th>Term Source 4 REF</th>\n","      <th>Term Source 4 Accession</th>\n","      <th>Characteristics [Sex]</th>\n","      <th>Term Source 5 REF</th>\n","      <th>Term Source 5 Accession</th>\n","      <th>Characteristics [Ethnic or Racial Group]</th>\n","      <th>Term Source 6 REF</th>\n","      <th>Term Source 6 Accession</th>\n","      <th>Characteristics [Age]</th>\n","      <th>Characteristics [Individual]</th>\n","      <th>Characteristics [Clinical History]</th>\n","      <th>Protocol REF</th>\n","      <th>Protocol REF.1</th>\n","      <th>Experimental Condition [Diagnosis]</th>\n","      <th>Channels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>training</td>\n","      <td>33381_0_fal_10_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>training</td>\n","      <td>33381_0_fal_14_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>training</td>\n","      <td>33381_0_fal_16_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>training</td>\n","      <td>33381_0_fal_18_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>training</td>\n","      <td>33381_0_fal_25_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2294</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_18_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2295</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_1_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2296</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_20_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2297</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_21_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2298</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_2_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2299 rows × 27 columns</p>\n","</div>"],"text/plain":["     Dataset Name  ... Channels\n","0        training  ...      RGB\n","1        training  ...      RGB\n","2        training  ...      RGB\n","3        training  ...      RGB\n","4        training  ...      RGB\n","...           ...  ...      ...\n","2294         test  ...      RGB\n","2295         test  ...      RGB\n","2296         test  ...      RGB\n","2297         test  ...      RGB\n","2298         test  ...      RGB\n","\n","[2299 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_f1boOAdTUx8","executionInfo":{"status":"ok","timestamp":1610603770256,"user_tz":-330,"elapsed":2495,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"b1a57586-76e0-4799-d78f-6e5f547c2562"},"source":["print(labels['Dataset Name'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0       training\n","1       training\n","2       training\n","3       training\n","4       training\n","          ...   \n","2294        test\n","2295        test\n","2296        test\n","2297        test\n","2298        test\n","Name: Dataset Name, Length: 2299, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7D8mQdhTUx8","executionInfo":{"status":"ok","timestamp":1610603770258,"user_tz":-330,"elapsed":2486,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"23d2a959-24e7-4682-8d3f-3fc206b1b414"},"source":["print(labels['Dataset Name'][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2HQQ_GzTUx9","executionInfo":{"status":"ok","timestamp":1610603770259,"user_tz":-330,"elapsed":2475,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"ef1a9f20-b75f-47fe-b12c-866d94521fef"},"source":["type(labels['Dataset Name'][0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O3qnTY8rTUx9","executionInfo":{"status":"ok","timestamp":1610603770259,"user_tz":-330,"elapsed":2465,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"7b4ca892-55bc-4eb2-8730-d5bef97bcfe9"},"source":["print(labels['Image Name'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0       33381_0_fal_10_0.png\n","1       33381_0_fal_14_0.png\n","2       33381_0_fal_16_0.png\n","3       33381_0_fal_18_0.png\n","4       33381_0_fal_25_0.png\n","                ...         \n","2294    36175_1_nrm_18_0.png\n","2295     36175_1_nrm_1_0.png\n","2296    36175_1_nrm_20_0.png\n","2297    36175_1_nrm_21_0.png\n","2298     36175_1_nrm_2_0.png\n","Name: Image Name, Length: 2299, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUjbBjagTUx9","executionInfo":{"status":"ok","timestamp":1610603770260,"user_tz":-330,"elapsed":2456,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"3e7a94c8-ddd0-4fc9-ed0e-04869a40b71b"},"source":["print(labels['Image Name'][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["33381_0_fal_10_0.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlEwMNmXTUx-","executionInfo":{"status":"ok","timestamp":1610603770262,"user_tz":-330,"elapsed":2448,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"9faae419-e0bc-485d-a47b-78c25668bf62"},"source":["type(labels['Image Name'][0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7-b5mycTUx-","executionInfo":{"status":"ok","timestamp":1610603770263,"user_tz":-330,"elapsed":2439,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"86864092-5321-45d6-9fb1-b92172eff520"},"source":["print(labels['Experimental Condition [Diagnosis]'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0           chronic heart failure\n","1           chronic heart failure\n","2           chronic heart failure\n","3           chronic heart failure\n","4           chronic heart failure\n","                  ...            \n","2294    not chronic heart failure\n","2295    not chronic heart failure\n","2296    not chronic heart failure\n","2297    not chronic heart failure\n","2298    not chronic heart failure\n","Name: Experimental Condition [Diagnosis], Length: 2299, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljWCGdQZTUx-","executionInfo":{"status":"ok","timestamp":1610603770265,"user_tz":-330,"elapsed":2431,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"986861cd-608a-427b-d516-8247ebf034e8"},"source":["print(labels['Experimental Condition [Diagnosis]'][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["chronic heart failure\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-MoFvzPTUx-","executionInfo":{"status":"ok","timestamp":1610603770266,"user_tz":-330,"elapsed":2420,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"ed749776-d32c-4ca5-de5c-eacdfdfcc833"},"source":["type(labels['Experimental Condition [Diagnosis]'][0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{"tags":[]},"execution_count":120}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UiPxrxBTUx_","executionInfo":{"status":"ok","timestamp":1610603770266,"user_tz":-330,"elapsed":2409,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"cba2fcbc-ae6b-4ffc-a98a-eeab27f3e0d6"},"source":["# confirm 'no info' cells have been encoded as 'nan'... check one entry\n","print(labels['Characteristics [Disease Subtype]'][463])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nan\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0Rczcv_kTUx_"},"source":["## Prepare Train Images and Train Labels"]},{"cell_type":"markdown","metadata":{"id":"Jz_-xEdgNtBZ"},"source":["All the images are of type '*.png'. We will read filepath for all \"filenames with extension as 'png'\" into a list. Here, filepath means 'relative directory + filename'."]},{"cell_type":"code","metadata":{"id":"XRQUsN0mTUx_"},"source":["# Google Drive / Colab\n","filepathlist_train = glob.glob('/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/fold_1/*.png')\n","\n","# Local Drive / Jupyter\n","# filepathlist_train = glob.glob('data/images/training/fold_1/*.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eG9DoyKpOrEq"},"source":["We will extract filename of the image from the file path. This filename can then be used to get the label information from the annotation file."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlwIDpjETUx_","executionInfo":{"status":"ok","timestamp":1610603770268,"user_tz":-330,"elapsed":2398,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"aa9d647b-bd0c-4e8a-c671-5dba67b3b981"},"source":["# confirm you have got the total number of desired items in the list\n","len(filepathlist_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["770"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"f1dvk1dxTUyA","executionInfo":{"status":"ok","timestamp":1610603770269,"user_tz":-330,"elapsed":2386,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"06a8977b-8dae-4f10-9e03-a22845aa2d8d"},"source":["# check what an element in the filelist contain.\n","# it has both directory information and the filename, we need to extract filename \n","# the filename can then be used to check for the label info in the labels dataframe\n","filepathlist_train[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/fold_1/33392_0_fal_4_0.png'"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"markdown","metadata":{"id":"S_oFfXABTJKJ"},"source":["Local Drive / Jupyter "]},{"cell_type":"code","metadata":{"id":"8OPsW8eT_MFA"},"source":["# this scenario has '\\\\' between the directory and filename\r\n","# split the string\r\n","# directory, filename = filepathlist_train[0].split('\\\\')\r\n","# gives the directory info\r\n","# directory\r\n","# gives the filname we need\r\n","# filename"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wLmi5HsgSeEo"},"source":["Google Drive / Colab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ir9jzf_78oJu","executionInfo":{"status":"ok","timestamp":1610603770271,"user_tz":-330,"elapsed":2374,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"93e6cef2-b7e5-42da-9c78-6eb202a1eaf2"},"source":["len(filepathlist_train[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"J16b0aYw8uAr","executionInfo":{"status":"ok","timestamp":1610603770272,"user_tz":-330,"elapsed":2361,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"2294cc19-4820-4df9-e9f5-58f3897e51b5"},"source":["filepathlist_train[0][-19:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'33392_0_fal_4_0.png'"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vxczcvry97HG","executionInfo":{"status":"ok","timestamp":1610603770274,"user_tz":-330,"elapsed":2348,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"b0a19b90-be27-445f-d200-9c913ec9b96b"},"source":["filepathlist_train[0][len(filepathlist_train[0]) - 1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'g'"]},"metadata":{"tags":[]},"execution_count":128}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"0OXQGUkc-Inp","executionInfo":{"status":"ok","timestamp":1610603770275,"user_tz":-330,"elapsed":2334,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"eae75278-ef5d-4cc1-d4e5-2033a109bb00"},"source":["filepathlist_train[0][-1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'g'"]},"metadata":{"tags":[]},"execution_count":129}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2_o3p9y9TUyA","executionInfo":{"status":"ok","timestamp":1610603770276,"user_tz":-330,"elapsed":2323,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"7b5d771f-7518-454f-fad9-dfb65f6894a1"},"source":["# POC\n","idx = -1\n","while (filepathlist_train[0][idx] != '/'):\n","  idx = idx - 1 \n","# index currently points to '/' location, we need to start reading from next location to get file name\n","print(idx)\n","filename = filepathlist_train[0][idx + 1:]\n","print(filename)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-20\n","33392_0_fal_4_0.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gmFAoRozX4xX"},"source":["# POC\r\n","index_filepathlist = 0\r\n","for filepath in filepathlist_train:\r\n","    #print(index_filepathlist, filepath)\r\n","    index_filepathlist += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXlYHbSPTBfy"},"source":["# read a file using the list containing the file path\r\n","img = cv2.imread(filepathlist_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eSZtYnQrTUyB"},"source":["# define the empty list that need to populated with info\n","train_images = []\n","train_labels = []\n","index_filepathlist = 0\n","# iterate for all items in the file path list\n","for filepath in filepathlist_train:\n","    # prepare image list\n","    img = cv2.imread(filepath)\n","    train_images.append(img)\n","    # prepare labels list\n","    # extract filename from the file path\n","    # Local Drive / Jupyter\n","    # directory, filename = filepath.split('\\\\')\n","    # Google Drive / Colab\n","    index_character = -1\n","    while (filepathlist_train[index_filepathlist][index_character] != '/'):\n","      index_character = index_character - 1 \n","    # character index currently points to '/' location, we need to start reading from next location to get file name\n","    filename = filepathlist_train[index_filepathlist][index_character + 1:]\n","    index_filepathlist += 1\n","    # iterate for all items in our labels dataframe to search for the label\n","    for index in range(len(labels)):\n","        # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\n","        # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\n","        if (filename == labels['Image Name'][index]):\n","            label = labels['Experimental Condition [Diagnosis]'][index]\n","            # encode Class1 and Class0 as applicable\n","            if (label == 'chronic heart failure'):\n","                label = 1\n","            elif (label == 'not chronic heart failure'):\n","                label = 0\n","            elif (label == 'heart tissue pathology'):\n","                label = 0\n","            # append the label to the list\n","            train_labels.append(label) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrhMe6CvTUyB"},"source":["# train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6xHVSfMKTUyC"},"source":["Convert images to numpy arrays and confirm shape is as required for CNN. "]},{"cell_type":"code","metadata":{"id":"CGFHcbYNTUyC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603781998,"user_tz":-330,"elapsed":14012,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"b033dfbc-ae5d-41d4-d767-14ab079887dd"},"source":["# confirm you have got the total number desired images in the list\n","len(train_images)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["770"]},"metadata":{"tags":[]},"execution_count":135}]},{"cell_type":"code","metadata":{"id":"imoqMNZHTUyC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603781999,"user_tz":-330,"elapsed":14003,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"9909e160-b003-4fd1-9d0b-100a273308e9"},"source":["# train is a list\n","type(train_images)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{"tags":[]},"execution_count":136}]},{"cell_type":"code","metadata":{"id":"rE1sBd7wTUyC"},"source":["# convert list to a numpy array and the values to float\n","train_images = np.array(train_images, dtype = 'float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwnwE79LTUyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603782000,"user_tz":-330,"elapsed":13988,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"0380b5a0-01e0-433f-8b45-d8b299c6bdb3"},"source":["# check the shape to confirm it is ready for CNN\n","# number of instances, width, height, number of channels\n","# number of instances = number of image\n","# number of channels = 3 ... as these are color images\n","train_images.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(770, 250, 250, 3)"]},"metadata":{"tags":[]},"execution_count":138}]},{"cell_type":"markdown","metadata":{"id":"ThTHsjK5TUyD"},"source":["Convert labels to numpy arrays and confirm shape is as required for CNN. "]},{"cell_type":"code","metadata":{"id":"HvNJR0CVTUyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603782001,"user_tz":-330,"elapsed":13979,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"4b03b7cd-d4f1-46ee-d383-f5fe04babcdf"},"source":["len(train_labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["770"]},"metadata":{"tags":[]},"execution_count":139}]},{"cell_type":"code","metadata":{"id":"8MlrY4_HTUyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603782001,"user_tz":-330,"elapsed":13969,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"b4aa8d89-616f-4d6f-f4a2-0aa60bde5b50"},"source":["type(train_labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{"tags":[]},"execution_count":140}]},{"cell_type":"code","metadata":{"id":"q3So3_2FTUyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603782001,"user_tz":-330,"elapsed":13958,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"349d235c-63a1-4dcb-c444-ff538add7899"},"source":["train_labels[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":141}]},{"cell_type":"code","metadata":{"id":"VE5e9MDoTUyE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603782002,"user_tz":-330,"elapsed":13949,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"eeb63d6e-0a01-42c0-9442-c3e30f971d94"},"source":["train_labels[432]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":142}]},{"cell_type":"code","metadata":{"id":"zS5caNeTTUyE"},"source":["# convert list to a numpy array and the values to int64\n","train_labels = np.array(train_labels, dtype = 'int64')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDLfwCgDTUyE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603782003,"user_tz":-330,"elapsed":13934,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"39a4fc9a-18b5-44a8-8aa6-81fd052bcc51"},"source":["# check the shape to confirm it is ready for CNN\n","train_labels.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(770,)"]},"metadata":{"tags":[]},"execution_count":144}]},{"cell_type":"code","metadata":{"id":"FATnUKBQTUyE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603782004,"user_tz":-330,"elapsed":13925,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"faa2ff89-66f9-426d-a863-82f749b0875d"},"source":["len(train_labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["770"]},"metadata":{"tags":[]},"execution_count":145}]},{"cell_type":"markdown","metadata":{"id":"7MiV5FQfTUyF"},"source":["Let us check on the number of Class 0 and Class 1s that we have. "]},{"cell_type":"code","metadata":{"id":"4OnLtQmPTUyF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603782005,"user_tz":-330,"elapsed":13916,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"eb23f523-316f-461d-e6af-393282493fb7"},"source":["count_ones = 0\n","count_zeroes = 0\n","for i in range(len(train_labels)):\n","    if (train_labels[i] == 1):\n","            count_ones += 1\n","    elif(train_labels[i] == 0):\n","            count_zeroes += 1\n","print('Total Labels:',(count_ones + count_zeroes))\n","print('# of Class 1:',count_ones)   \n","print('# of Class 0:',count_zeroes)    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total Labels: 770\n","# of Class 1: 352\n","# of Class 0: 418\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CDYnWqw6TUyF"},"source":["We will convert the labels to 2bit values: 01 and 10 to correspond to the 2 classes. This is required to match to the model's output layer expectation so that we can effectively train and test. "]},{"cell_type":"code","metadata":{"id":"wY6Wz_rgTUyF"},"source":["from keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwBRGFFVTUyG"},"source":["# convert labels to categorical\n","train_labels = to_categorical(train_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mtvpF6A6TUyG"},"source":["### Prepare Validation Images and Validation Labels"]},{"cell_type":"code","metadata":{"id":"GvhlW2iETUyG"},"source":["# read filepath for all \"filenames with extension as 'png'\" into a list\n","# here filepath means 'relative directory + filename'\n","\n","# Google Drive / Colab\n","filepathlist_validation = glob.glob('/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/test_fold_1/*.png')\n","\n","# Local Drive / Jupyter\n","# filepathlist_validation = glob.glob('data/images/training/test_fold_1/*.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1o2S4A8akrX"},"source":["# define the empty list that need to populated with info\r\n","validation_images = []\r\n","validation_labels = []\r\n","index_filepathlist = 0\r\n","# iterate for all items in the file path list\r\n","for filepath in filepathlist_validation:\r\n","    # prepare image list\r\n","    img = cv2.imread(filepath)\r\n","    validation_images.append(img)\r\n","    # prepare labels list\r\n","    # extract filename from the file path\r\n","    # Local Drive / Jupyter\r\n","    # directory, filename = filepath.split('\\\\')\r\n","    # Google Drive / Colab\r\n","    index_character = -1\r\n","    while (filepathlist_validation[index_filepathlist][index_character] != '/'):\r\n","      index_character = index_character - 1 \r\n","    # character index currently points to '/' location, we need to start reading from next location to get file name\r\n","    filename = filepathlist_validation[index_filepathlist][index_character + 1:]\r\n","    index_filepathlist += 1\r\n","    # iterate for all items in our labels dataframe to search for the label\r\n","    for index in range(len(labels)):\r\n","        # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\r\n","        # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\r\n","        if (filename == labels['Image Name'][index]):\r\n","            label = labels['Experimental Condition [Diagnosis]'][index]\r\n","            # encode Class1 and Class0 as applicable\r\n","            if (label == 'chronic heart failure'):\r\n","                label = 1\r\n","            elif (label == 'not chronic heart failure'):\r\n","                label = 0\r\n","            elif (label == 'heart tissue pathology'):\r\n","                label = 0\r\n","            # append the label to the list\r\n","            validation_labels.append(label) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fJuHg1dTUyH"},"source":["# convert list to a numpy array and the values to float\n","validation_images = np.array(validation_images, dtype = 'float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xlFbfassTUyH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603788042,"user_tz":-330,"elapsed":19917,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"baa4866e-adc5-490b-e58a-906655d36d6d"},"source":["# check the shape to confirm it is ready for CNN\n","validation_images.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(374, 250, 250, 3)"]},"metadata":{"tags":[]},"execution_count":152}]},{"cell_type":"code","metadata":{"id":"EfuLDkHbTUyI"},"source":["# convert list to a numpy array and the values to int64\n","validation_labels = np.array(validation_labels, dtype = 'int64')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOIVr3VRTUyI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603788046,"user_tz":-330,"elapsed":19910,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"0d6ddecb-d594-4dc0-bc81-86908656dd17"},"source":["# check the shape to confirm it is ready for CNN\n","validation_labels.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(374,)"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"markdown","metadata":{"id":"p_TwktKETUyI"},"source":["Let us check on the number of Class 0 and Class 1s that we have. "]},{"cell_type":"code","metadata":{"id":"rUBixGIuTUyI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610603788047,"user_tz":-330,"elapsed":19906,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"eb4d8648-f13b-403d-8351-fe216a05fc94"},"source":["count_ones = 0\n","count_zeroes = 0\n","for i in range(len(validation_labels)):\n","    if (validation_labels[i] == 1):\n","            count_ones += 1\n","    elif(validation_labels[i] == 0):\n","            count_zeroes += 1\n","print('Total Labels:',(count_ones + count_zeroes))\n","print('# of Class 1:',count_ones)   \n","print('# of Class 0:',count_zeroes)   "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total Labels: 374\n","# of Class 1: 165\n","# of Class 0: 209\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4euJT10hTUyJ"},"source":["# convert labels to categorical\n","validation_labels = to_categorical(validation_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EzMWmY9PTUyJ"},"source":["### Prepare Test Images and Test Labels"]},{"cell_type":"code","metadata":{"id":"72lSvVYpTUyJ"},"source":["# read filepath for all \"filenames with extension as 'png'\" into a list\n","# here filepath means 'relative directory + filename'\n","\n","# Google Drive / Colab\n","filepathlist_test = glob.glob('/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/held-out_validation/*.png')\n","\n","# Local Drive / Jupyter\n","# filepathlist_test = glob.glob('data/images/held-out_validation/*.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9xbC5sOcvsa"},"source":["# define the empty list that need to populated with info\r\n","test_images = []\r\n","test_labels = []\r\n","index_filepathlist = 0\r\n","# iterate for all items in the file path list\r\n","for filepath in filepathlist_test:\r\n","    # prepare image list\r\n","    img = cv2.imread(filepath)\r\n","    test_images.append(img)\r\n","    # prepare labels list\r\n","    # extract filename from the file path\r\n","    # Local Drive / Jupyter\r\n","    # directory, filename = filepath.split('\\\\')\r\n","    # Google Drive / Colab\r\n","    index_character = -1\r\n","    while (filepathlist_test[index_filepathlist][index_character] != '/'):\r\n","      index_character = index_character - 1 \r\n","    # character index currently points to '/' location, we need to start reading from next location to get file name\r\n","    filename = filepathlist_test[index_filepathlist][index_character + 1:]\r\n","    index_filepathlist += 1\r\n","    # iterate for all items in our labels dataframe to search for the label\r\n","    for index in range(len(labels)):\r\n","        # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\r\n","        # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\r\n","        if (filename == labels['Image Name'][index]):\r\n","            label = labels['Experimental Condition [Diagnosis]'][index]\r\n","            # encode Class1 and Class0 as applicable\r\n","            if (label == 'chronic heart failure'):\r\n","                label = 1\r\n","            elif (label == 'not chronic heart failure'):\r\n","                label = 0\r\n","            elif (label == 'heart tissue pathology'):\r\n","                label = 0\r\n","            # append the label to the list\r\n","            test_labels.append(label) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qz2_tYI5TUyJ"},"source":["# define the empty list that need to populated with info\n","#test_images = []\n","#test_labels = []\n","# iterate for all items in the file path list\n","#for filepath in filepathlist_test:\n","    # prepare image list\n","#    img = cv2.imread(filepath)\n","#    test_images.append(img)\n","    # prepare labels list\n","    # extract filename from the file path\n","#    directory, filename = filepath.split('\\\\')\n","    # iterate for all items in our labels dataframe to search for the label\n","#    for index in range(len(labels)):\n","        # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\n","        # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\n","#        if (filename == labels['Image Name'][index]):\n","#            label = labels['Experimental Condition [Diagnosis]'][index]\n","            # encode Class1 and Class0 as applicable\n","#            if (label == 'chronic heart failure'):\n","#                label = 1\n","#            elif (label == 'not chronic heart failure'):\n","#                label = 0\n","#            elif (label == 'heart tissue pathology'):\n","#                label = 0\n","            # append the label to the list\n","#            test_labels.append(label) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xCjwEDeCTUyN"},"source":["# convert list to a numpy array and the values to float\n","test_images = np.array(test_images, dtype = 'float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKORF7UjTUyN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610604749899,"user_tz":-330,"elapsed":845,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"21eade2b-1101-4280-cbb8-76bdff6bbd57"},"source":["# check the shape to confirm it is ready for CNN\n","test_images.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1155, 250, 250, 3)"]},"metadata":{"tags":[]},"execution_count":170}]},{"cell_type":"code","metadata":{"id":"1sfmo-v2TUyO"},"source":["# convert list to a numpy array and the values to int64\n","test_labels = np.array(test_labels, dtype = 'int64')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"njHiGVDRTUyO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610604752815,"user_tz":-330,"elapsed":1222,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"be2633c0-f873-4b0c-a271-d38fb9a93cd1"},"source":["# check the shape to confirm it is ready for CNN\n","test_labels.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1155,)"]},"metadata":{"tags":[]},"execution_count":172}]},{"cell_type":"markdown","metadata":{"id":"Gk05ShqrTUyQ"},"source":["Let us check on the number of Class 0 and Class 1s that we have. "]},{"cell_type":"code","metadata":{"id":"GvRldQOOTUyQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610604754819,"user_tz":-330,"elapsed":1159,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"46bb7ace-d3a6-4e4b-af8c-7aa87dd96abe"},"source":["count_ones = 0\n","count_zeroes = 0\n","for i in range(len(test_labels)):\n","    if (test_labels[i] == 1):\n","            count_ones += 1\n","    elif(test_labels[i] == 0):\n","            count_zeroes += 1\n","print('Total Labels:',(count_ones + count_zeroes))\n","print('# of Class 1:',count_ones)   \n","print('# of Class 0:',count_zeroes)   "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total Labels: 1155\n","# of Class 1: 517\n","# of Class 0: 638\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dScQ0oPFTUyR"},"source":["# convert labels to categorical\n","test_labels = to_categorical(test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"47ncBdcCTUyR"},"source":["## Define Model"]},{"cell_type":"code","metadata":{"id":"s5UbQ64nTUyS"},"source":["from keras import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uw2Tq10rTUyT"},"source":["from keras import layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwjE7kqETUyT"},"source":["model_cnn = models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OxtajKtwTUyT"},"source":["Layer Details:\n","- 2 dimensional Convolution Layer\n","- Number of filters/kernels = 32\n","- Filter/Kernel Size = 3x3\n","- Activation Function = relu (for non-linearity detection)\n","- Input Shape = 250x250 matrix with 3 channel (as we have a color image)"]},{"cell_type":"code","metadata":{"id":"HZufLU64TUyb"},"source":["model_cnn.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(250,250,3)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m-ghBmtITUyc"},"source":["Layer Details:\n","- Downsample the output from previous layer\n","- We will take the max value for a every 2x2 window ... moved over the input"]},{"cell_type":"code","metadata":{"id":"qdR97kG6TUyc"},"source":["model_cnn.add(layers.MaxPooling2D(2,2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rjyz22r_TUyd"},"source":["Layer Details:\n","- 2 dimensional Convolution Layer\n","- Number of filters/kernels = 64\n","- Filter/Kernel Size = 3x3\n","- Activation Function = relu (for non-linearity detection)"]},{"cell_type":"code","metadata":{"id":"o5WGB3M7TUyd"},"source":["model_cnn.add(layers.Conv2D(64, (3,3), activation = 'relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hgzEflXITUyd"},"source":["Layer Details:\n","- Downsample the output from previous layer\n","- We will take the max value for a every 2x2 window ... moved over the input"]},{"cell_type":"code","metadata":{"id":"1d01W_KZTUye"},"source":["model_cnn.add(layers.MaxPooling2D(2,2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xNynUsocTUyf"},"source":["Layer Details:\n","- 2 dimensional Convolution Layer\n","- Number of filters/kernels = 64\n","- Filter/Kernel Size = 3x3\n","- Activation Function = relu (for non-linearity detection)"]},{"cell_type":"code","metadata":{"id":"xb-3np4lTUyf"},"source":["model_cnn.add(layers.Conv2D(64, (3,3), activation='relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ctumDSPhTUyf"},"source":["Data at this stage is in matrix form. We will convert it to vector form to feed to a fully connected network (FCN)."]},{"cell_type":"code","metadata":{"id":"mqQSKT_-TUyg"},"source":["model_cnn.add(layers.Flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4U1FqTgeTUyh"},"source":["We will design for 64 outputs with activation function as relu (to learn non-linearity)."]},{"cell_type":"code","metadata":{"id":"gx27z1AITUyh"},"source":["model_cnn.add(layers.Dense(64, activation = 'relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fd4mjf1HTUyi"},"source":["This is the final layer. Hence, the outputs will be 2 corresponding to the 2 classes:\n","- clinical heart failure = yes: 1\n","- clinical heart failure = no: 0\n","\n","Activation Function chosen here is softmax to have a probabilistic output. "]},{"cell_type":"code","metadata":{"id":"t93_iKrcTUyi"},"source":["model_cnn.add(layers.Dense(2, activation = 'softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqcdLtDiTUyi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610604778590,"user_tz":-330,"elapsed":1046,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"cdebcdfb-fc26-412e-c777-23a7d134dec6"},"source":["model_cnn.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 248, 248, 32)      896       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 124, 124, 32)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 122, 122, 64)      18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 61, 61, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 59, 59, 64)        36928     \n","_________________________________________________________________\n","flatten (Flatten)            (None, 222784)            0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                14258240  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 130       \n","=================================================================\n","Total params: 14,314,690\n","Trainable params: 14,314,690\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rZokehl0TUyk"},"source":["## Define Optimizer, Loss Function and Metrics to be used for the Model\n","- Going ahead with the well known functions at this point in time\n","- Selected accuracy as the metrics to understand validation / test accuracy of the model"]},{"cell_type":"code","metadata":{"id":"rhGIjHqwTUyk"},"source":["model_cnn.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x7xorJZnTUyk"},"source":["## Train and Validate the Model\n","#### We will now train the model using train images and train labels. \n","- We will use a batch size = 10.\n","- 1 epoch = 770 / 10 = 77 batches\n","- 1 epoch = 1 complete run of all train samples for training the model\n","- We will go for a total of 5 epochs = 5 complete run of the all train samples\n","\n","#### We will validate the model using validation images and validation labels."]},{"cell_type":"code","metadata":{"id":"xK47GWw0TUyl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610604795031,"user_tz":-330,"elapsed":10263,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"5e390cfe-5a4b-4100-c530-39ffa38bc4e6"},"source":["model_cnn.fit(train_images, train_labels, epochs = 1, batch_size = 10, validation_data = (validation_images, validation_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["77/77 [==============================] - 10s 28ms/step - loss: 274.9980 - accuracy: 0.5574 - val_loss: 3.3631 - val_accuracy: 0.5588\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa7b005f7b8>"]},"metadata":{"tags":[]},"execution_count":188}]},{"cell_type":"markdown","metadata":{"id":"WMcV48RGTUym"},"source":["## Test the Model\n","We will now test model's performance with the test data.\n","- We predict the class for each of the 1155 test using the model.\n","- We will check the test accuracy."]},{"cell_type":"code","metadata":{"id":"hUwVqJXOTUym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610604796187,"user_tz":-330,"elapsed":9890,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"bd0362fd-4805-487e-9f56-caaa3d0cd1b7"},"source":["test_loss, test_acc = model_cnn.evaluate(test_images, test_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["37/37 [==============================] - 1s 19ms/step - loss: 3.4084 - accuracy: 0.5524\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OxF28n6gTUyn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610604796189,"user_tz":-330,"elapsed":9182,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"09b6351a-7c7e-4ee1-de4d-0c60149905d3"},"source":["print('test accuracy:', (test_acc*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test accuracy: 55.23809790611267\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lquCeUFQhrTI"},"source":[""],"execution_count":null,"outputs":[]}]}