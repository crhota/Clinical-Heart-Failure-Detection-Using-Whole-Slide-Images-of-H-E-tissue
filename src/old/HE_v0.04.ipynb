{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Heart Failure Detection Using Whole-Slide Images of H&E tissue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version**\n",
    "- **0.04**: Class Label Info in List was not accurate - fixed it. Now, Train/Validate/Test Accuracy is more realistic = ~55%\n",
    "- **0.03**: Tweak CNN model done for MNIST to work for this dataset to have a working end to end CNN model. Train/Validate/Test Accuracy = ~100%\n",
    "- **0.02**: Prepare Train/Validate/Test Labels and Images \n",
    "- **0.01**: Prepare Train/Validate/Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improvement Opportunity**\n",
    "- Convert code sections in data preparation for train/validation/test to functions\n",
    "- As this is a 2 class classification - loss function can be changed to binary_crossentropy instead of categorical_crossentropy\n",
    "- Reduce parameters, epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Train, Validate and Test Images\n",
    "- Source Link to the Dataset / Annotation File: https://idr.openmicroscopy.org/webclient/?show=project-402\n",
    "- Follow the instructions at following link, install IBM Aspera Desktop Client to download the dataset.\n",
    "- Copy downloaded folders to '**data/images**' folder in your working directory where you have this Jupyter Notebook:\n",
    "  - 'held-out_validation'\n",
    "  - 'training'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Label Information for Train, Validate and Test Images \n",
    "- Following link will point to below Github link which has the annotation File: https://idr.openmicroscopy.org/webclient/?show=project-402\n",
    "- Source Link for the Annotation File: https://github.com/IDR/idr0042-nirschl-wsideeplearning/tree/master/experimentA\n",
    "- Download and copy file '**idr0042-experimentA-annotation.csv**' to '**data/labels/**' folder in your working directory where you have this Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "#### Data Preparation\n",
    "- Reading an image\n",
    "  - mathplotlib: https://stackoverflow.com/questions/9298665/cannot-import-scipy-misc-imread\n",
    "  - pathlib: https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f#:~:text=To%20use%20it%2C%20you%20just,for%20the%20current%20operating%20system.\n",
    "  - OpenCV: https://www.geeksforgeeks.org/python-opencv-cv2-imread-method/\n",
    "- Load multiple images into a numpy array\n",
    "  - glob / os.listdir: https://stackoverflow.com/questions/39195113/how-to-load-multiple-images-in-a-numpy-array\n",
    "  - glob / cv2: https://medium.com/@muskulpesent/create-numpy-array-of-images-fecb4e514c4b\n",
    "- Load a CSV file\n",
    "  - Datacamp: https://www.datacamp.com/community/tutorials/pandas-read-csv?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=278443377095&utm_targetid=dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=9061994&gclid=EAIaIQobChMIz5TKz-v17QIV1AorCh0bfw96EAAYASAAEgKiGPD_BwE\n",
    "- Split a String\n",
    "  - Python Central: https://www.pythoncentral.io/cutting-and-slicing-strings-in-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand Images Folder Structure and Number of Images Available\n",
    "\n",
    "**Training/Validation**\n",
    "- \\..\\training\\fold_1: has images for training = 770#\n",
    "- \\..\\training\\test_fold_1: has images for validation = 374#\n",
    "- Total = 770 + 374 = 1144 images\n",
    "\n",
    "**Test**\n",
    "- \\..\\held-out_validation: has images for testing = 1155#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand Annotation File and Label Information Available\n",
    "\n",
    "Relevant columns of interest:\n",
    "- Column A: Dataset Name: Classifies each row/instance as 'training' or 'test'\n",
    "- Column B: Image Name: Specifies filename of the image for the row/instance\n",
    "- Column Z: Experimental Condition [Diagnosis]: has 3 classes:\n",
    "  - 'chronic heart failure'\n",
    "  - 'heart tissue pathology' - We will treat this as 'not chronic heart failure'\n",
    "  - 'not chronic heart failure'\n",
    "- Column AA: Channels: mentions RGB => images are color images and will have 3 channels Red/Green/Blue (for CNN). \n",
    "  \n",
    "Breakup of training/test instances:\n",
    "- **training**\n",
    "  - 'chronic heart failure' = 517\n",
    "  - 'not chronic heart failure' = 627\n",
    "- **test**\n",
    "  - 'chronic heart failure' = 517\n",
    "  - 'not chronic heart failure' = 638\n",
    "\n",
    "Total '**training**' = 517 + 627 = 1144\n",
    "- Note: 'validate' is a portion of this 'training' set.\n",
    "\n",
    "Total '**test**' = 517 + 638 = 1155"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries to aid in converting images to arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the images to arrays so that we can then use them to feed to our CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install OpenCV package\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries to aid reading CSV file to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the annotation file into a Pandas Dataframe so that we can then access the labels information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('data/labels/idr0042-experimentA-annotation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Characteristics [Organism]</th>\n",
       "      <th>Term Source 1 REF</th>\n",
       "      <th>Term Source 1 Accession</th>\n",
       "      <th>Characteristics [Organism Part]</th>\n",
       "      <th>Term Source 2 REF</th>\n",
       "      <th>Term Source 2 Accession</th>\n",
       "      <th>Characteristics [Diagnosis]</th>\n",
       "      <th>Term Source 3 REF</th>\n",
       "      <th>...</th>\n",
       "      <th>Characteristics [Ethnic or Racial Group]</th>\n",
       "      <th>Term Source 6 REF</th>\n",
       "      <th>Term Source 6 Accession</th>\n",
       "      <th>Characteristics [Age]</th>\n",
       "      <th>Characteristics [Individual]</th>\n",
       "      <th>Characteristics [Clinical History]</th>\n",
       "      <th>Protocol REF</th>\n",
       "      <th>Protocol REF.1</th>\n",
       "      <th>Experimental Condition [Diagnosis]</th>\n",
       "      <th>Channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training</td>\n",
       "      <td>33381_0_fal_10_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>African American</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-62310</td>\n",
       "      <td>65 years</td>\n",
       "      <td>33381</td>\n",
       "      <td>ischemic cardiomyopathy</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training</td>\n",
       "      <td>33381_0_fal_14_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>African American</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-62310</td>\n",
       "      <td>65 years</td>\n",
       "      <td>33381</td>\n",
       "      <td>ischemic cardiomyopathy</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training</td>\n",
       "      <td>33381_0_fal_16_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>African American</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-62310</td>\n",
       "      <td>65 years</td>\n",
       "      <td>33381</td>\n",
       "      <td>ischemic cardiomyopathy</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training</td>\n",
       "      <td>33381_0_fal_18_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>African American</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-62310</td>\n",
       "      <td>65 years</td>\n",
       "      <td>33381</td>\n",
       "      <td>ischemic cardiomyopathy</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training</td>\n",
       "      <td>33381_0_fal_25_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>African American</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-62310</td>\n",
       "      <td>65 years</td>\n",
       "      <td>33381</td>\n",
       "      <td>ischemic cardiomyopathy</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>test</td>\n",
       "      <td>36175_1_nrm_18_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-0003D</td>\n",
       "      <td>53 years</td>\n",
       "      <td>36175</td>\n",
       "      <td>normal cardiovascular function by cardiac cath...</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>test</td>\n",
       "      <td>36175_1_nrm_1_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-0003D</td>\n",
       "      <td>53 years</td>\n",
       "      <td>36175</td>\n",
       "      <td>normal cardiovascular function by cardiac cath...</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>test</td>\n",
       "      <td>36175_1_nrm_20_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-0003D</td>\n",
       "      <td>53 years</td>\n",
       "      <td>36175</td>\n",
       "      <td>normal cardiovascular function by cardiac cath...</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>test</td>\n",
       "      <td>36175_1_nrm_21_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-0003D</td>\n",
       "      <td>53 years</td>\n",
       "      <td>36175</td>\n",
       "      <td>normal cardiovascular function by cardiac cath...</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>test</td>\n",
       "      <td>36175_1_nrm_2_0.png</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NCBITaxon</td>\n",
       "      <td>NCBITaxon_9606</td>\n",
       "      <td>heart</td>\n",
       "      <td>UBERON</td>\n",
       "      <td>UBERON_0000948</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>...</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>SNOMED_S-0003D</td>\n",
       "      <td>53 years</td>\n",
       "      <td>36175</td>\n",
       "      <td>normal cardiovascular function by cardiac cath...</td>\n",
       "      <td>treatment protocol</td>\n",
       "      <td>image acquisition</td>\n",
       "      <td>not chronic heart failure</td>\n",
       "      <td>RGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2299 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Name            Image Name Characteristics [Organism]  \\\n",
       "0        training  33381_0_fal_10_0.png               Homo sapiens   \n",
       "1        training  33381_0_fal_14_0.png               Homo sapiens   \n",
       "2        training  33381_0_fal_16_0.png               Homo sapiens   \n",
       "3        training  33381_0_fal_18_0.png               Homo sapiens   \n",
       "4        training  33381_0_fal_25_0.png               Homo sapiens   \n",
       "...           ...                   ...                        ...   \n",
       "2294         test  36175_1_nrm_18_0.png               Homo sapiens   \n",
       "2295         test   36175_1_nrm_1_0.png               Homo sapiens   \n",
       "2296         test  36175_1_nrm_20_0.png               Homo sapiens   \n",
       "2297         test  36175_1_nrm_21_0.png               Homo sapiens   \n",
       "2298         test   36175_1_nrm_2_0.png               Homo sapiens   \n",
       "\n",
       "     Term Source 1 REF Term Source 1 Accession  \\\n",
       "0            NCBITaxon          NCBITaxon_9606   \n",
       "1            NCBITaxon          NCBITaxon_9606   \n",
       "2            NCBITaxon          NCBITaxon_9606   \n",
       "3            NCBITaxon          NCBITaxon_9606   \n",
       "4            NCBITaxon          NCBITaxon_9606   \n",
       "...                ...                     ...   \n",
       "2294         NCBITaxon          NCBITaxon_9606   \n",
       "2295         NCBITaxon          NCBITaxon_9606   \n",
       "2296         NCBITaxon          NCBITaxon_9606   \n",
       "2297         NCBITaxon          NCBITaxon_9606   \n",
       "2298         NCBITaxon          NCBITaxon_9606   \n",
       "\n",
       "     Characteristics [Organism Part] Term Source 2 REF  \\\n",
       "0                              heart            UBERON   \n",
       "1                              heart            UBERON   \n",
       "2                              heart            UBERON   \n",
       "3                              heart            UBERON   \n",
       "4                              heart            UBERON   \n",
       "...                              ...               ...   \n",
       "2294                           heart            UBERON   \n",
       "2295                           heart            UBERON   \n",
       "2296                           heart            UBERON   \n",
       "2297                           heart            UBERON   \n",
       "2298                           heart            UBERON   \n",
       "\n",
       "     Term Source 2 Accession Characteristics [Diagnosis] Term Source 3 REF  \\\n",
       "0             UBERON_0000948       chronic heart failure            SNOMED   \n",
       "1             UBERON_0000948       chronic heart failure            SNOMED   \n",
       "2             UBERON_0000948       chronic heart failure            SNOMED   \n",
       "3             UBERON_0000948       chronic heart failure            SNOMED   \n",
       "4             UBERON_0000948       chronic heart failure            SNOMED   \n",
       "...                      ...                         ...               ...   \n",
       "2294          UBERON_0000948   not chronic heart failure            SNOMED   \n",
       "2295          UBERON_0000948   not chronic heart failure            SNOMED   \n",
       "2296          UBERON_0000948   not chronic heart failure            SNOMED   \n",
       "2297          UBERON_0000948   not chronic heart failure            SNOMED   \n",
       "2298          UBERON_0000948   not chronic heart failure            SNOMED   \n",
       "\n",
       "      ... Characteristics [Ethnic or Racial Group] Term Source 6 REF  \\\n",
       "0     ...                         African American            SNOMED   \n",
       "1     ...                         African American            SNOMED   \n",
       "2     ...                         African American            SNOMED   \n",
       "3     ...                         African American            SNOMED   \n",
       "4     ...                         African American            SNOMED   \n",
       "...   ...                                      ...               ...   \n",
       "2294  ...                                Caucasian            SNOMED   \n",
       "2295  ...                                Caucasian            SNOMED   \n",
       "2296  ...                                Caucasian            SNOMED   \n",
       "2297  ...                                Caucasian            SNOMED   \n",
       "2298  ...                                Caucasian            SNOMED   \n",
       "\n",
       "     Term Source 6 Accession Characteristics [Age]  \\\n",
       "0             SNOMED_S-62310              65 years   \n",
       "1             SNOMED_S-62310              65 years   \n",
       "2             SNOMED_S-62310              65 years   \n",
       "3             SNOMED_S-62310              65 years   \n",
       "4             SNOMED_S-62310              65 years   \n",
       "...                      ...                   ...   \n",
       "2294          SNOMED_S-0003D              53 years   \n",
       "2295          SNOMED_S-0003D              53 years   \n",
       "2296          SNOMED_S-0003D              53 years   \n",
       "2297          SNOMED_S-0003D              53 years   \n",
       "2298          SNOMED_S-0003D              53 years   \n",
       "\n",
       "     Characteristics [Individual]  \\\n",
       "0                           33381   \n",
       "1                           33381   \n",
       "2                           33381   \n",
       "3                           33381   \n",
       "4                           33381   \n",
       "...                           ...   \n",
       "2294                        36175   \n",
       "2295                        36175   \n",
       "2296                        36175   \n",
       "2297                        36175   \n",
       "2298                        36175   \n",
       "\n",
       "                     Characteristics [Clinical History]        Protocol REF  \\\n",
       "0                               ischemic cardiomyopathy  treatment protocol   \n",
       "1                               ischemic cardiomyopathy  treatment protocol   \n",
       "2                               ischemic cardiomyopathy  treatment protocol   \n",
       "3                               ischemic cardiomyopathy  treatment protocol   \n",
       "4                               ischemic cardiomyopathy  treatment protocol   \n",
       "...                                                 ...                 ...   \n",
       "2294  normal cardiovascular function by cardiac cath...  treatment protocol   \n",
       "2295  normal cardiovascular function by cardiac cath...  treatment protocol   \n",
       "2296  normal cardiovascular function by cardiac cath...  treatment protocol   \n",
       "2297  normal cardiovascular function by cardiac cath...  treatment protocol   \n",
       "2298  normal cardiovascular function by cardiac cath...  treatment protocol   \n",
       "\n",
       "         Protocol REF.1 Experimental Condition [Diagnosis] Channels  \n",
       "0     image acquisition              chronic heart failure      RGB  \n",
       "1     image acquisition              chronic heart failure      RGB  \n",
       "2     image acquisition              chronic heart failure      RGB  \n",
       "3     image acquisition              chronic heart failure      RGB  \n",
       "4     image acquisition              chronic heart failure      RGB  \n",
       "...                 ...                                ...      ...  \n",
       "2294  image acquisition          not chronic heart failure      RGB  \n",
       "2295  image acquisition          not chronic heart failure      RGB  \n",
       "2296  image acquisition          not chronic heart failure      RGB  \n",
       "2297  image acquisition          not chronic heart failure      RGB  \n",
       "2298  image acquisition          not chronic heart failure      RGB  \n",
       "\n",
       "[2299 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       training\n",
      "1       training\n",
      "2       training\n",
      "3       training\n",
      "4       training\n",
      "          ...   \n",
      "2294        test\n",
      "2295        test\n",
      "2296        test\n",
      "2297        test\n",
      "2298        test\n",
      "Name: Dataset Name, Length: 2299, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(labels['Dataset Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    }
   ],
   "source": [
    "print(labels['Dataset Name'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels['Dataset Name'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       33381_0_fal_10_0.png\n",
      "1       33381_0_fal_14_0.png\n",
      "2       33381_0_fal_16_0.png\n",
      "3       33381_0_fal_18_0.png\n",
      "4       33381_0_fal_25_0.png\n",
      "                ...         \n",
      "2294    36175_1_nrm_18_0.png\n",
      "2295     36175_1_nrm_1_0.png\n",
      "2296    36175_1_nrm_20_0.png\n",
      "2297    36175_1_nrm_21_0.png\n",
      "2298     36175_1_nrm_2_0.png\n",
      "Name: Image Name, Length: 2299, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(labels['Image Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33381_0_fal_10_0.png\n"
     ]
    }
   ],
   "source": [
    "print(labels['Image Name'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels['Image Name'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           chronic heart failure\n",
      "1           chronic heart failure\n",
      "2           chronic heart failure\n",
      "3           chronic heart failure\n",
      "4           chronic heart failure\n",
      "                  ...            \n",
      "2294    not chronic heart failure\n",
      "2295    not chronic heart failure\n",
      "2296    not chronic heart failure\n",
      "2297    not chronic heart failure\n",
      "2298    not chronic heart failure\n",
      "Name: Experimental Condition [Diagnosis], Length: 2299, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(labels['Experimental Condition [Diagnosis]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chronic heart failure\n"
     ]
    }
   ],
   "source": [
    "print(labels['Experimental Condition [Diagnosis]'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels['Experimental Condition [Diagnosis]'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# confirm 'no info' cells have been encoded as 'nan'... check one entry\n",
    "print(labels['Characteristics [Disease Subtype]'][463])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Train Images and Train Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read filepath for all \"filenames with extension as 'png'\" into a list\n",
    "# here filepath means 'relative directory + filename'\n",
    "filepathlist_train = glob.glob('data/images/training/fold_1/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm you have got the total number of desired items in the list\n",
    "len(filepathlist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract label info (for an image) from the labels dataframe by using the filename of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/images/training/fold_1\\\\33381_0_fal_10_0.png'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what an element in the filelist contain\n",
    "# it has both directory information and the filename\n",
    "# we need to split the string to get the filename \n",
    "# the filename can then be used to check for the label info in the labels dataframe\n",
    "filepathlist_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the string\n",
    "directory, filename = filepathlist_train[0].split('\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/images/training/fold_1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives the directory info\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33381_0_fal_10_0.png'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives the filname we need\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a file using the list containing the file path\n",
    "img = cv2.imread(filepathlist_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the empty list that need to populated with info\n",
    "train_images = []\n",
    "train_labels = []\n",
    "# iterate for all items in the file path list\n",
    "for filepath in filepathlist_train:\n",
    "    # prepare image list\n",
    "    img = cv2.imread(filepath)\n",
    "    train_images.append(img)\n",
    "    # prepare labels list\n",
    "    # extract filename from the file path\n",
    "    directory, filename = filepath.split('\\\\')\n",
    "    # iterate for all items in our labels dataframe to search for the label\n",
    "    for index in range(len(labels)):\n",
    "        # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\n",
    "        # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\n",
    "        if (filename == labels['Image Name'][index]):\n",
    "            label = labels['Experimental Condition [Diagnosis]'][index]\n",
    "            # encode Class1 and Class0 as applicable\n",
    "            if (label == 'chronic heart failure'):\n",
    "                label = 1\n",
    "            elif (label == 'not chronic heart failure'):\n",
    "                label = 0\n",
    "            elif (label == 'heart tissue pathology'):\n",
    "                label = 0\n",
    "            # append the label to the list\n",
    "            train_labels.append(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert images to numpy arrays and confirm shape is as required for CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm you have got the total number desired images in the list\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train is a list\n",
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to a numpy array and the values to float\n",
    "train_images = np.array(train_images, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770, 250, 250, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape to confirm it is ready for CNN\n",
    "# number of instances, width, height, number of channels\n",
    "# number of instances = number of image\n",
    "# number of channels = 3 ... as these are color images\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to numpy arrays and confirm shape is as required for CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to a numpy array and the values to int64\n",
    "train_labels = np.array(train_labels, dtype = 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape to confirm it is ready for CNN\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check on the number of Class 0 and Class 1s that we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Labels: 770\n",
      "# of Class 1: 352\n",
      "# of Class 0: 418\n"
     ]
    }
   ],
   "source": [
    "count_ones = 0\n",
    "count_zeroes = 0\n",
    "for i in range(len(train_labels)):\n",
    "    if (train_labels[i] == 1):\n",
    "            count_ones += 1\n",
    "    elif(train_labels[i] == 0):\n",
    "            count_zeroes += 1\n",
    "print('Total Labels:',(count_ones + count_zeroes))\n",
    "print('# of Class 1:',count_ones)   \n",
    "print('# of Class 0:',count_zeroes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the labels to 2bit values: 01 and 10 to correspond to the 2 classes. This is required to match to the model's output layer expectation so that we can effectively train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to categorical\n",
    "train_labels = to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Validation Images and Validation Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read filepath for all \"filenames with extension as 'png'\" into a list\n",
    "# here filepath means 'relative directory + filename'\n",
    "filepathlist_validation = glob.glob('data/images/training/test_fold_1/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the empty list that need to populated with info\n",
    "validation_images = []\n",
    "validation_labels = []\n",
    "# iterate for all items in the file path list\n",
    "for filepath in filepathlist_validation:\n",
    "    # prepare image list\n",
    "    img = cv2.imread(filepath)\n",
    "    validation_images.append(img)\n",
    "    # prepare labels list\n",
    "    # extract filename from the file path\n",
    "    directory, filename = filepath.split('\\\\')\n",
    "    # iterate for all items in our labels dataframe to search for the label\n",
    "    for index in range(len(labels)):\n",
    "        # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\n",
    "        # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\n",
    "        if (filename == labels['Image Name'][index]):\n",
    "            label = labels['Experimental Condition [Diagnosis]'][index]\n",
    "            # encode Class1 and Class0 as applicable\n",
    "            if (label == 'chronic heart failure'):\n",
    "                label = 1\n",
    "            elif (label == 'not chronic heart failure'):\n",
    "                label = 0\n",
    "            elif (label == 'heart tissue pathology'):\n",
    "                label = 0\n",
    "            # append the label to the list\n",
    "            validation_labels.append(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to a numpy array and the values to float\n",
    "validation_images = np.array(validation_images, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374, 250, 250, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape to confirm it is ready for CNN\n",
    "validation_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to a numpy array and the values to int64\n",
    "validation_labels = np.array(validation_labels, dtype = 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape to confirm it is ready for CNN\n",
    "validation_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check on the number of Class 0 and Class 1s that we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Labels: 374\n",
      "# of Class 1: 165\n",
      "# of Class 0: 209\n"
     ]
    }
   ],
   "source": [
    "count_ones = 0\n",
    "count_zeroes = 0\n",
    "for i in range(len(validation_labels)):\n",
    "    if (validation_labels[i] == 1):\n",
    "            count_ones += 1\n",
    "    elif(validation_labels[i] == 0):\n",
    "            count_zeroes += 1\n",
    "print('Total Labels:',(count_ones + count_zeroes))\n",
    "print('# of Class 1:',count_ones)   \n",
    "print('# of Class 0:',count_zeroes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to categorical\n",
    "validation_labels = to_categorical(validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Images and Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read filepath for all \"filenames with extension as 'png'\" into a list\n",
    "# here filepath means 'relative directory + filename'\n",
    "filepathlist_test = glob.glob('data/images/held-out_validation/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the empty list that need to populated with info\n",
    "test_images = []\n",
    "test_labels = []\n",
    "# iterate for all items in the file path list\n",
    "for filepath in filepathlist_test:\n",
    "    # prepare image list\n",
    "    img = cv2.imread(filepath)\n",
    "    test_images.append(img)\n",
    "    # prepare labels list\n",
    "    # extract filename from the file path\n",
    "    directory, filename = filepath.split('\\\\')\n",
    "    # iterate for all items in our labels dataframe to search for the label\n",
    "    for index in range(len(labels)):\n",
    "        # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\n",
    "        # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\n",
    "        if (filename == labels['Image Name'][index]):\n",
    "            label = labels['Experimental Condition [Diagnosis]'][index]\n",
    "            # encode Class1 and Class0 as applicable\n",
    "            if (label == 'chronic heart failure'):\n",
    "                label = 1\n",
    "            elif (label == 'not chronic heart failure'):\n",
    "                label = 0\n",
    "            elif (label == 'heart tissue pathology'):\n",
    "                label = 0\n",
    "            # append the label to the list\n",
    "            test_labels.append(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to a numpy array and the values to float\n",
    "test_images = np.array(test_images, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1155, 250, 250, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape to confirm it is ready for CNN\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to a numpy array and the values to int64\n",
    "test_labels = np.array(test_labels, dtype = 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1155,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape to confirm it is ready for CNN\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check on the number of Class 0 and Class 1s that we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Labels: 1155\n",
      "# of Class 1: 517\n",
      "# of Class 0: 638\n"
     ]
    }
   ],
   "source": [
    "count_ones = 0\n",
    "count_zeroes = 0\n",
    "for i in range(len(test_labels)):\n",
    "    if (test_labels[i] == 1):\n",
    "            count_ones += 1\n",
    "    elif(test_labels[i] == 0):\n",
    "            count_zeroes += 1\n",
    "print('Total Labels:',(count_ones + count_zeroes))\n",
    "print('# of Class 1:',count_ones)   \n",
    "print('# of Class 0:',count_zeroes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to categorical\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Details:\n",
    "- 2 dimensional Convolution Layer\n",
    "- Number of filters/kernels = 32\n",
    "- Filter/Kernel Size = 3x3\n",
    "- Activation Function = relu (for non-linearity detection)\n",
    "- Input Shape = 250x250 matrix with 3 channel (as we have a color image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(250,250,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Details:\n",
    "- Downsample the output from previous layer\n",
    "- We will take the max value for a every 2x2 window ... moved over the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(layers.MaxPooling2D(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Details:\n",
    "- 2 dimensional Convolution Layer\n",
    "- Number of filters/kernels = 64\n",
    "- Filter/Kernel Size = 3x3\n",
    "- Activation Function = relu (for non-linearity detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(layers.Conv2D(64, (3,3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Details:\n",
    "- Downsample the output from previous layer\n",
    "- We will take the max value for a every 2x2 window ... moved over the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(layers.MaxPooling2D(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Details:\n",
    "- 2 dimensional Convolution Layer\n",
    "- Number of filters/kernels = 64\n",
    "- Filter/Kernel Size = 3x3\n",
    "- Activation Function = relu (for non-linearity detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(layers.Conv2D(64, (3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data at this stage is in matrix form. We will convert it to vector form to feed to a fully connected network (FCN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will design for 64 outputs with activation function as relu (to learn non-linearity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(layers.Dense(64, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final layer. Hence, the outputs will be 2 corresponding to the 2 classes:\n",
    "- clinical heart failure = yes: 1\n",
    "- clinical heart failure = no: 0\n",
    "\n",
    "Activation Function chosen here is softmax to have a probabilistic output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(layers.Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 248, 248, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 122, 122, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 59, 59, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 222784)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                14258240  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 14,314,690\n",
      "Trainable params: 14,314,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Optimizer, Loss Function and Metrics to be used for the Model\n",
    "- Going ahead with the well known functions at this point in time\n",
    "- Selected accuracy as the metrics to understand validation / test accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validate the Model\n",
    "#### We will now train the model using train images and train labels. \n",
    "- We will use a batch size = 10.\n",
    "- 1 epoch = 770 / 10 = 77 batches\n",
    "- 1 epoch = 1 complete run of all train samples for training the model\n",
    "- We will go for a total of 5 epochs = 5 complete run of the all train samples\n",
    "\n",
    "#### We will validate the model using validation images and validation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 770 samples, validate on 374 samples\n",
      "Epoch 1/5\n",
      "770/770 [==============================] - 71s 92ms/step - loss: 524.3493 - accuracy: 0.5130 - val_loss: 0.6987 - val_accuracy: 0.4759\n",
      "Epoch 2/5\n",
      "770/770 [==============================] - 69s 90ms/step - loss: 49.0332 - accuracy: 0.5299 - val_loss: 0.6958 - val_accuracy: 0.4866\n",
      "Epoch 3/5\n",
      "770/770 [==============================] - 69s 89ms/step - loss: 2.1133 - accuracy: 0.5675 - val_loss: 0.6910 - val_accuracy: 0.5588\n",
      "Epoch 4/5\n",
      "770/770 [==============================] - 68s 88ms/step - loss: 13.8183 - accuracy: 0.5545 - val_loss: 0.6893 - val_accuracy: 0.5588\n",
      "Epoch 5/5\n",
      "770/770 [==============================] - 68s 88ms/step - loss: 1.3702 - accuracy: 0.5481 - val_loss: 11.1439 - val_accuracy: 0.5588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2753664b588>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.fit(train_images, train_labels, epochs = 5, batch_size = 10, validation_data = (validation_images, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "We will now test model's performance with the test data.\n",
    "- We predict the class for each of the 1155 test using the model.\n",
    "- We will check the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155/1155 [==============================] - 20s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_cnn.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 55.23809790611267\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy:', (test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
