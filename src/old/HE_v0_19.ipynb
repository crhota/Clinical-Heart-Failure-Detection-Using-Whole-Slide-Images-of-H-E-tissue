{"nbformat":4,"nbformat_minor":0,"metadata":{"@webio":{"lastCommId":null,"lastKernelId":null},"accelerator":"GPU","colab":{"name":"HE_v0_19.ipynb","provenance":[],"collapsed_sections":["0_Wbu528IW4x"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VTkgKJvoTUxt"},"source":["# Clinical Heart Failure Detection Using Whole-Slide Images of H&E tissue"]},{"cell_type":"markdown","metadata":{"id":"6CzT5I5ZnTOM"},"source":["## Version"]},{"cell_type":"markdown","metadata":{"id":"GuVfy-J79VSx"},"source":["### Version 0.18-0.19:"]},{"cell_type":"markdown","metadata":{"id":"2qPxxxso9YF7"},"source":["- **0.18-0.19**:\r\n","  - Implemented time function to calculate the desired time more precisely as the time from colab and verbose are not matching.\r\n","  - XFR = Transfer Learning, FT = Fine tuning\r\n","  - For Regular Run: Train & Test Acc is w.r.t. Best Val Accuracy.\r\n","  - Common Hyper parameters: Batchsize = 10, Learning Rate = 0.01, Neurons after Conv = 512, Dropout = 0.4. \r\n","  - **Resnet50 XFR**\r\n","    - Conv Layer / Total Params / Trainable Params / FLOPS = 5 / 25M / 1M / 0.0021G \r\n","      - Total params: 24,637,826, Trainable params: 1,050,114, Non-trainable params: 23,587,712  \r\n","    - Regular Run:\r\n","      - Train Time (time / verbose) = 446.35871052742004s / 411s\r\n","      - Test Time (time / verbose) = 4.191006660461426s / 4s\r\n","      - Test Time / sample (time / verbose) = 0.0036285771952046975s / 0.00346s \r\n","      - Train / Val / Test Acc % = 92.2 / 90.4 / 82.6\r\n","    - CV: \r\n","      - Validation Time (time) = 2644.3752892017365s\r\n","      - Validation Accuracy Mean (+/- Std Deviation): 88.30% (+/- 0.80%)\r\n","  - **MobileNet**\r\n","    - Conv Layer / FLOPS = 13 / 1.15G \r\n","    - **XFR**\r\n","      - Total Params / Trainable Params = 4.8M / 0.5M\r\n","        - Total params: 4,767,402 , Trainable params: 513,538 , Non-trainable params: 4,253,864\r\n","      - Regular Run:\r\n","        - Train Time (time / verbose) = 162.90089511871338s / 202s\r\n","        - Test Time (time / verbose) = 1.819808006286621s / 2s\r\n","        - Test Time / sample (time / verbose) = 0.001575591347434304s / 0.00173s\r\n","        - Train / Val / Test Acc % = 83.2 / 85.0 / 78.4\r\n","      - CV: \r\n","        - Validation Time (time) = 988.1067225933075s\r\n","        - Validation Accuracy Mean (+/- Std Deviation): 78.03% (+/- 0.78%)\r\n","    - **FT**\r\n","      - Total Params / Trainable Params = 4.8M / 2.6M\r\n","        - Total params: 4,767,402 , Trainable params: 2,600,426 , Non-trainable params: 2,166,976\r\n","      - Regular Run: \r\n","        - Train Time (time / verbose) = 160.71819162368774s / 200s\r\n","        - Test Time (time / verbose) = 1.453615665435791s / 1s\r\n","        - Test Time / sample (time / verbose) = 0.0012585417016760096s / 0.00087s\r\n","        - Train / Val / Test Acc % = 84.8 / 89.6 / 83.6  \r\n","      - CV: \r\n","        - Validation Time (time) = 992.2293410301208s\r\n","        - Validation Accuracy Mean (+/- Std Deviation): 78.29% (+/- 1.35%)"]},{"cell_type":"markdown","metadata":{"id":"HETNgK2Mgbai"},"source":["### Version 0.17:\r\n","- **0.17**: run for Epoch = 100\r\n","  - XFR = Transfer Learning, FT = Fine tuning\r\n","  - For Regular Run: Train & Test Acc is w.r.t. Best Val Accuracy.\r\n","  - Common Hyper parameters: Batchsize = 10, Learning Rate = 0.01, Neurons after Conv = 512, Dropout = 0.4. \r\n","  - **Resnet50 XFR**\r\n","    - Conv Layer / Total Params / Trainable Params / FLOPS = 5 / 25M / 1M / 0.0021G   \r\n","    - Regular Run: \r\n","      - Train Time Verbose / Colab = 404s / 474.015s\r\n","      - Test Time Verbose / Colab (1155 samples) = 4s / 490.921s ?\r\n","      - Test Time per sample = 3.5ms / 425ms ?\r\n","      - Train / Val / Test Acc % = 86.7 / 90.1 / 81.8\r\n","    - CV: \r\n","      - Validation Time (Colab) = 3030.406s\r\n","      - Val Acc Mean (+/- Std Deviation): 87.86% (+/- 1.24%)\r\n","  - **MobileNet**\r\n","    - Conv Layer / FLOPS = 13 / 1.15G \r\n","    - **XFR**\r\n","      - Total Params / Trainable Params = 5M / 0.5M\r\n","      - Regular Run:\r\n","        - Train Time Verbose / Colab =  202s / 3192.38s ?\r\n","        - Test Time Verbose / Colab (1155 samples) = 1s / 3198.253s ?\r\n","        - Test Time per sample = 0.87ms / 2.77s ?\r\n","        - Train / Val / Test Acc % = 82.1 / 84.2 / 77.8\r\n","      - CV: \r\n","        - Validation Time (Colab) = 4169.914s\r\n","        - Val Acc Mean (+/- Std Deviation): 78.34% (+/- 1.30%)\r\n","    - **FT**\r\n","      - Total Params / Trainable Params = 5M / 2.6M\r\n","      - Regular Run: \r\n","        - Train Time Verbose / Colab = 200s / 4328.194s ?\r\n","        - Test Time Verbose / Colab (1155 samples) = 1s / 4333.798s ?\r\n","        - Test Time per sample = 0.87ms / 3.75s ?\r\n","        - Train / Val / Test Acc % = 82.6 / 89.3 / 84.9  \r\n","      - CV: \r\n","        - Validation Time (Colab) = 5311.684s\r\n","        - Val Acc Mean (+/- Std Deviation): 79.16% (+/- 1.23%)\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"SE4-TN-AYYu1"},"source":["### Version 0.16\r\n","- **0.16**\r\n","  - Changed 'tf.keras.applications.mobilenet.MobileNet()' to 'mobilenet = tf.keras.applications.MobileNet()' to reconfirm using MobilenetV1\r\n","  - mobilenet = tf.keras.applications.mobilenet.MobileNet()\r\n","    - Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\r\n","  - mobilenet = tf.keras.applications.MobileNet()\r\n","    - Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\r\n","  - ResNet50 Transfer\r\n","      - Regular Run: Train/Val/Test Acc = 61.2 / 74.3 / 73.3   \r\n","      - CV Run:  Validation Accuracy Mean (+/- Std Deviation): 77.90% (+/- 1.05%)\r\n","  - MobileNet Transfer\r\n","      - Regular Run: Train/Val/Test Acc = 70.1 / 76.5 / 74.0\r\n","      - CV Run:  Validation Accuracy Mean (+/- Std Deviation): 76.69% (+/- 1.32%)\r\n","  - MobileNet FineTune\r\n","      - Regular Run: Train/Val/Test Acc = 76.4 / 80.5 / 76.5 \r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 77.77% (+/- 2.34%)"]},{"cell_type":"markdown","metadata":{"id":"GlW_uOwYIEv3"},"source":["### Version 0.15"]},{"cell_type":"markdown","metadata":{"id":"DaYet9a9IFz9"},"source":["- **0.15**: implemented flops\r\n","    - ResNet50 Transfer - 0.0021G\r\n","      - Regular Run: Train/Val/Test Acc = 59.5 / 73.5 / 71.0 \r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 79.34% (+/- 1.76%)\r\n","    - MobileNet Transfer - 1.15G\r\n","      - Regular Run: Train/Val/Test Acc =  71.0 / 82.4 / 75.6\r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 76.03% (+/- 1.57%)\r\n","    - MobileNet FineTune - 1.15G\r\n","      - Regular Run: Train/Val/Test Acc =  76.9 / 83.2 / 77.1  \r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 75.16% (+/- 0.93%)\r\n","\r\n","- Note: XFR = Transfer Learning, FT = Fine tuning, Train & Test Acc is w.r.t. Best Val Accuracy. Common Hyper parameters: Batchsize = 10, Learning Rate = 0.01, Neurons after Conv = 512, Dropout = 0.4.\r\n","  - Without cross-validation, with same hyper parameters, Test Accuracy/Total Params/Trainable Params/No. of Convolution Layers/FLOPS/Train Time/Test Time/Test Time per Sample    \r\n","    - Below is for Epoch = 100    \r\n","    - Resnet50 XFR (~81%/~25M/~1M/5 Conv/0.0021G/~300s/3s/~2.6ms)    \r\n","    - MobileNet XFR (~78%/~5M/~0.5M/13 Conv/1.15G/~200s/1s/~0.87ms)    \r\n","    - MobileNet FT (~79%/~5M/~2.6M/13 Conv/1.15G/~200s/1s/~0.87ms)\r\n","  - With cross-validation, with same hyper parameters, Test Accuracy Mean +/- Std Dev/Total Params/Trainable Params/No. of Convolution Layers/FLOPS    \r\n","    - Below is for Epoch = 1, Cross Validation Folds = 4    \r\n","    - Resnet50 XFR (79.34% (+/- 1.76%)/~25M/~1M/5 Conv/0.0021G)    \r\n","    - MobileNet XFR (76.03% (+/- 1.57%)/~5M/~0.5M/13 Conv/1.15G)    \r\n","    - MobileNet FT (75.16% (+/- 0.93%)/~5M/~2.6M/13 Conv/1.15G)"]},{"cell_type":"markdown","metadata":{"id":"0dalPY9JlUjk"},"source":["### Version 0.12-0.14 (Implemented Cross Validation for 1 Epoch, 4 Folds: Other hyperparameters same as in v0.11)"]},{"cell_type":"markdown","metadata":{"id":"SdyIzgHjlaS6"},"source":["- **0.12**: rerun to baseline\r\n","- **0.13**\r\n","  - **epoch = 1, fold = 2**\r\n","  - saved labels before conversion to categorical\r\n","  - added code macros for cross validation = true, fold = 2 \r\n","  - added code for cross-validation for resnet50 transfer learning\r\n","  - added code for cross-validation for mobilenet transfer learning \r\n","  - ResNet50 Transfer\r\n","    - Regular Run: Train/Val/Test Acc = 57.0 / 73.5 / 70.7\r\n","    - CV Run: Validation Accuracy Mean (+/- Std Deviation): 74.64% (+/- 1.51%)\r\n","  - MobileNet Transfer\r\n","    - Regular Run: Train/Val/Test Acc = 69.1 / 77.3 / 74.5\r\n","    - CV Run: Validation Accuracy Mean (+/- Std Deviation): 75.82% (+/- 0.27%)\r\n","- **0.14**\r\n","  - **epoch = 100, fold = 4**\r\n","    - ResNet50 Transfer\r\n","      - Regular Run: Train/Val/Test Acc = 88.1 / 88.8 / 79\r\n","      - CV Run: only for 1 fold ... 88.4 .. later I interrupted\r\n","    - MobileNet Transfer\r\n","      - Regular Run: Train/Val/Test Acc .. later I interrupted\r\n","      - CV Run: .. later I interrupted\r\n","  - **epoch = 1, fold = 4**\r\n","    - ResNet50 Transfer\r\n","      - Regular Run: Train/Val/Test Acc =  60.0 / 72.7 / 69.7\r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 79.16% (+/- 2.54%)\r\n","    - MobileNet Transfer\r\n","      - Regular Run: Train/Val/Test Acc =  71.6 / 80.5 / 74.8\r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 75.64% (+/- 1.61%) \r\n","    - MobileNet FineTune\r\n","      - CV done before the regular run of train/val/test to ensure we use the weights from transfer and not from regular run of finetune.\r\n","      - CV Run:  Validation Accuracy Mean (+/- Std Deviation): 77.82% (+/- 2.03%)\r\n","      - Regular Run: Train/Val/Test Acc =  75.3 / 81.8 / 76.6\r\n","  - Updated code to have separate checkpoint files for each model. Cross-validation of MobileNet FineTune Model uses MobileNet Transfer file for initialization.\r\n","    - **epoch = 1, fold = 4**\r\n","    - ResNet50 Transfer\r\n","      - Regular Run: Train/Val/Test Acc = 61.5 / 71.9 / 72.1 \r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 78.78% (+/- 3.65%)\r\n","    - MobileNet Transfer\r\n","      - Regular Run: Train/Val/Test Acc = 68.0 / 81.3 / 75.6 \r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 76.64% (+/- 0.98%)\r\n","    - MobileNet FineTune\r\n","      - Regular Run: Train/Val/Test Acc = 74.6 / 81.8 / 76.9  \r\n","      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 76.03% (+/- 1.67%)\r\n"]},{"cell_type":"markdown","metadata":{"id":"rttCQhWPHOCE"},"source":["### Version 0.11"]},{"cell_type":"markdown","metadata":{"id":"siGkxsXEHSUJ"},"source":["- **0.11** \r\n","  - As is Rerun\r\n","    - Epoch = 100, Batchsize = 10, Learning Rate = 0.01, Neurons = 512, Dropout = 0.4. Train & Test Acc is w.r.t. Best Val Accuracy.\r\n","    - ResNet50 (Transfer Learning) - 5 Convolution Layers\r\n","      - Total/Trainable Params: 24.64M/1.05M\r\n","      - Train + Validation Time: (8s x 1) + (3s x 99) = 305s\r\n","      - Test Time: 3s, Test/sample = (3/1155)s = 0.0026s = 2.6ms  \r\n","      - Train/Val/Test Acc: 93.7 / 89.0 / 80.7\r\n","    - MobileNet - 13 Convolution Layers\r\n","      - Transfer Learning\r\n","        - Total/Trainable Params: 4.77M/0.51M\r\n","        - Train + Validation Time: (4s x 1) + (max 2s x 99) = 202s\r\n","        - Test Time: 1s, Test/sample = (1/1155)s = 0.87ms \r\n","        - Train/Val/Test Acc: 79.5 / 84.2 / 78.0\r\n","      - Finetuning\r\n","        - Total/Trainable Params: 4.77M/2.60M\r\n","        - Train + Validation Time: (max 2s x 100) = 200s\r\n","        - Test Time: 1s, Test/sample = (1/1155)s = 0.87ms \r\n","        - Train/Val/Test Acc: 88.2 / 84.2 / 78.8"]},{"cell_type":"markdown","metadata":{"id":"y1XTl8F6sKrr"},"source":["### Version 0.10"]},{"cell_type":"markdown","metadata":{"id":"4CrC5fg4sTgX"},"source":["- **0.10** \r\n","  - Cleaned up indenting\r\n","  - Added hyperparameter macros that can be used for all models\r\n","    - ResNet50 was with 1024 neurons, 40% dropout\r\n","    - MobileNet was with 512 neurons, 60% dropout.\r\n","    - Made EPOCHS = 100, BATCH_SIZE = 10, LEARNING_RATE = 0.01, DENSE_LAYER_NEURONS = 512, DENSE_LAYER_DROPOUT = 0.4\r\n","  - Implemented 'checkpoint' as a function to be used a callback by any model. Enabled callback for ResNet50\r\n","  - Accuracy\r\n","    - ResNet50 (XFR Learning): Best_Train/Best_Val/Test = 89.4 / 88.8 / 80.7\r\n","    - MobileNet (XFR Learning): Best_Train/Best_Val/Test = 83.6 / 85.0 / 77.6\r\n","    - MobileNet (Fine Tuning): Best_Train/Best_Val/Test = 86.9 / 84.0 / 77.7\r\n","  \r\n"]},{"cell_type":"markdown","metadata":{"id":"Z__HJG6gIxMj"},"source":["### Version 0.09"]},{"cell_type":"markdown","metadata":{"id":"4E9zAmtKTUx1"},"source":["- **0.09** **MobileNet**\n","  - **Epoch=100**: img resize: lr=0.01: BN = N: **Dropout = 0.4**: Params (Total/Trainable/Non-trainable)= 5,280,938 / 1,027,074 / 4,253,864: Train/Val/Test Acc = 87.4/80.8/78.0\n","  - Epoch=100: **Best Model**: Train/Val/Test Acc = 82.1/84.0/77.8\n","  - **Epoch=200**: Best Model: Train/Val/Test Acc = 79.0/84.0/78.9\n","  - **Epoch=100**: Best Model: **Regularizer: Kernel/Bias L2(0.01) for Dense(1024)**: Train/Val/Test Acc = 70.6/80.0/72.5\n","  - Epoch=100: Best Model: Regularizer: Kernel/Bias L2(0.01) for Dense(1024), **Dense(2)**: Train/Val/Test Acc = 69.0/78.3/72.6\n","  - Epoch=100: Best Model: Regularizer: Kernel/Bias **L1**(0.01) for Dense(1024), Dense(2): Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n","  - Epoch=100: Best Model: Regularizer: Kernel/Bias/**Activity L2**(0.01) for Dense(1024), Dense(2): Train/Val/Test Acc = 68.1/79.1/72.4\n","  - Epoch=100: Best Model: Regularizer: Kernel/Bias/Activity L2**(0.2)** for Dense(1024), Dense(2): Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n","  - Epoch=100: Best Model: Regularizer: Kernel/Bias/Activity L2**(1e-4/1e-4/1e-5)** for Dense(1024), Dense(2): Train/Val/Test Acc = 77.6/84.0/77.5 ... regularizer is not helping much ... revert to No Regularizer\n","  - **Best Model**: **Epoch=100**: Train/Val/Test Acc = 81.5/84.5/77.8\n","  - Best Model: **Epoch=1**: **Nottrainable/trainabele layers = 0-79/80-94**:  Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n","  - Best Model: **Epoch=100**: NonTrainable(MobileNet)+ Trainable(Dense(1024), Dropout, Dense(2)): Train/Val/Test Acc = 82.3/85/79\n","  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(**512**), Dropout, Dense(2)): Train/Val/Test Acc = 82.1/84.8/78.7\n","  - Best Model: Epoch=100: **MobileNet NT till Conv13 (0-85), T for Rest** + Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n","  - Best Model: Epoch=100: MobileNet NT **till Conv12 (0-79)**, T for Rest** + Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n","  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(**512**), Dropout, Dense(2)): Train/Val/Test Acc = 88.5/85.0/77.7\n","  - Best Model: Epoch=100: **NonTrainable(MobileNet)+ Trainable(Dense(**512**), Dropout, Dense(2)) -> save and load weights -> NonTrainable(MobileNet till <86) Trainable (86 and later = GAP...)+ Trainable(Dense(**512**), Dropout, Dense(2))**: Train/Val/Test Acc = 78.7/84.8/76.8 -> ../84.8/76.8\n","  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(512), Dropout, Dense(2)) -> save and load weights -> NonTrainable(MobileNet **till <80**) Trainable (80 and later = **Conv13,GAP...**)+ Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = 82.1/84.2/78.2 -> ../84.2/78.2\n","  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(512), Dropout, Dense(2)) -> save and load weights -> NonTrainable(MobileNet **till <73**) Trainable (73 and later = **Conv12,Conv13,GAP...**)+ Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = 80.1/84.2/78.4 -> ../84.2/78.4 \n","  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(512), Dropout, Dense(2)) -> save and load weights -> **Trainable(MobileNet till <73**) Trainable (73 and later = **Conv12,Conv13,GAP...**)+ Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = 81.8/84.2/78.3 -> 86.2/84.5/78.4\n","  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(512), Dropout, Dense(2)) -> save and load weights -> NonTrainable(MobileNet **till <80**) Trainable (80 and later = **Conv13,GAP...**)+ Trainable(Dense(512), Dropout, Dense(2)): Params (Total/Trainable/Non-trainable)= 4,767,402 / 2,600,426 / 2,166,976: Train/Val/Test Acc = 79.8/84.8/78.4 -> ../84.8/78.4\n","\n","\n","\n","\n","   \n"]},{"cell_type":"markdown","metadata":{"id":"q4Ryh-JimjiK"},"source":["### Version 0.08"]},{"cell_type":"markdown","metadata":{"id":"0pCxVDSZmlkq"},"source":["- **0.08** **MobileNet**\r\n","  - Changed model to Pre-trained MobileNet\r\n","  - Epoch=1: **img resize**: lr=0.01: BN = N: Dropout = N: Train/Val/Test Acc = 68.2/76.5/73.8\r\n","  - Epoch=10: img resize: lr=0.01: BN = N: Dropout = N: Train/Val/Test Acc = 80.5/82.4/78.9\r\n","  - **Epoch=20**: img resize: lr=0.01: BN = N: Dropout = N:Train/Val/Test Acc = 83.7/79.2/76.5 ... revert to Epoch=10\r\n","  - **Epoch=10**: img resize: **lr=0.0001**: BN = N: Dropout = N:Train/Val/Test Acc = 71.9/78.6/73.6 ... revert to lr=0.01\r\n","  - Epoch=10: img resize: **lr=0.01**: **BN = Y**: Dropout = N: Train/Val/Test Acc = 83.0/77.8/71.0 revert to BN = N\r\n","  - Epoch=10: img resize: lr=0.01: **BN = N**: **Dropout = 0.2**: Train/Val/Test Acc = 77.1/80.8/76.9\r\n","  - Epoch=10: img resize: lr=0.01: BN = N: **Dropout = 0.4**: Train/Val/Test Acc = 78.8/82.6/78.0\r\n","  - **Epoch=20**: img resize: lr=0.01: BN = N: Dropout = 0.4: Train/Val/Test Acc = 81.6/76.6/75.4 ... revert to Epoch = 10\r\n","  - **Epoch=10**: img resize: lr=0.01: BN = N: **Dropout = 0.5**: Train/Val/Test Acc = 78.3/84.2/77.8 ... revert to Dropout = 0.4\r\n","  - Epoch=10: img resize: lr=0.01: BN = N: **Dropout = 0.4**: Params (Total/Trainable/Non-trainable)= 5,280,938 / 1,027,074 / 4,253,864: Train/Val/Test Acc = 78.3/79.1/76.5"]},{"cell_type":"markdown","metadata":{"id":"Ho0vVgWAmbpf"},"source":["### Version 0.07"]},{"cell_type":"markdown","metadata":{"id":"ySQuE0MtmeoC"},"source":["- **0.07** **ResNet50**\r\n","  - As is rerun: Epoch=20: Adam(lr=0.01): Dropout(0.4): No BN: batch size = 10: Train/Val/Test Acc = 86.7/86.6/81.4\r\n","  - Change **batch size** from 10 to 20: Train/Val/Test Acc = 91.2/83.7/78.9 ... reduces accuracy, so reverted to batch size of 10\r\n","  - Implemented **Data Augmentation** with batch size of 10: Train/Val/Test Acc = 78.1/79.7/69.0 ...reduces accuracy, should we increase batch size?\r\n","  - Implemented **Data Augmentation** with batch size of 100: Train/Val/Test Acc = 89.3/72.2/67.9 ...reduces accuracy, should we decrease batch size?\r\n","  - Implemented **Data Augmentation** with batch size of 5: Train/Val/Test Acc = 58.3/48.4/48.1  ... reduces accuracy, reverted to batch size of 10, and no Data Augmentation\r\n","  - Epoch=20: Adam(lr=0.01): Dropout(0.4): No BN: **batch size = 10**: **No DataAug**: Params (Total/Trainable/Non-trainable)= 25,687,938 / 2,100,226 / 23,587,712: Train/Val/Test Acc = 91.8/90.6/81.1"]},{"cell_type":"markdown","metadata":{"id":"zs0QIeKrmMQ1"},"source":["### Version 0.06"]},{"cell_type":"markdown","metadata":{"id":"4nvsJYrimP-N"},"source":["- **0.06** **ResNet50**\r\n","  - Before any modification: full rerun took ~15mins (most of it for loading train/val/test images/labels... and very less for model training/test)\r\n","  - Before any modification: Train/Val/Test Acc = 53/51.1/51.3\r\n","  - Changed model = Pre-trained ResNet50 + Modified FCN Layer\r\n","    - SGD (LR=0.0001, M=0.9), Categorical Crossentropy\r\n","    - 1st run: Train/Val/Test Acc = 57.5/72.7/67.1\r\n","    - Converted ones/zeroes count to function\r\n","    - Converted images/label prep to function\r\n","    - Epoch=1: Train/Val/Test Acc = 61/67.9/67\r\n","    - Epoch=5: Train/Val/Test Acc = 85.6/80.8/75.9\r\n","    - Epoch=10: Train/Val/Test Acc = 93.0/85.6/77.7\r\n","    - Epoch=20: Train/Val/Test Acc = 94.1/89.0/80.4\r\n","    - Epoch=20: Changed loss function to 'binary crossentropy', reduced the accuracy: Train/Val/Test Acc = 90.2/84.0/77.7 Hence, reverted to categorical crossentropy as the loss function\r\n","    - Epoch=20: Changed optimizer to Adam(lr=0.01), increased accuracy: Train/Val/Test Acc = 99.3/86.9/83.2\r\n","    - In above training accuracy is high, validation and test accuracy is low ... it is overfitting ... let us implement Dropout\r\n","    - Epoch=20: Adam(lr=0.01): Dropout(0.2): Train/Val/Test Acc = 93.0/88.8/82.1\r\n","    - Epoch=20: Adam(lr=0.01): Dropout(0.4): Train/Val/Test Acc = 90.8/89.8/83.4\r\n","    - Epoch=20: Adam(lr=0.01): Dropout(0.5): Train/Val/Test Acc = 92.2/90.6/82.3 .. reverted to Dropout(0.4)\r\n","    - Let us try Batch Normalization. ResNet50 -> Dense (1024) -> Batch Norm -> relu -> Dropout -> Dense(2,softmax)\r\n","    - Epoch=20: Adam(lr=0.01): Dropout(0.4): BN: Train/Val/Test Acc = 90.6/81.6/79.0 ... reduced accuracy\r\n","    - Epoch=20: Adam(lr=0.01): Dropout(0.2): BN: Train/Val/Test Acc = 95.2/86.9/81.9 ... reduced accuracy will revert to no BN, Dropout(0.4)\r\n","    - Epoch=20: Adam(lr=0.01): Dropout(0.4): Train/Val/Test Acc = 88.2/89.3/81.7"]},{"cell_type":"markdown","metadata":{"id":"mg96Q_kol8D-"},"source":["### Version 0.01 - 0.05"]},{"cell_type":"markdown","metadata":{"id":"NpcAkTc8hKcL"},"source":["- **0.05**: Migrate to Google Colab/Drive, changed loss function to 'binary_crossentropy', epochs to 1 : Train/Val/Test Acc = 55.7/55.9/55.2\r\n","- **0.04**: Class Label Info in List was not accurate - fixed it. Now, Train/Validate/Test Accuracy is more realistic = ~55%\r\n","- **0.03**: Tweak CNN model done for MNIST to work for this dataset to have a working end to end CNN model. Train/Validate/Test Accuracy = ~100%\r\n","- **0.02**: Prepare Train/Validate/Test Labels and Images \r\n","- **0.01**: Prepare Train/Validate/Test Images"]},{"cell_type":"markdown","metadata":{"id":"aTijnel0I8P9"},"source":["## Improvement Opportunity"]},{"cell_type":"markdown","metadata":{"id":"43vNOnzBTUx1"},"source":["- **TRIED**: As this is a 2 class classification - loss function can be changed to binary_crossentropy instead of categorical_crossentropy\n","- **DONE**: Change model to ResNet50\n","- **DONE**: Convert code sections in data preparation for train/validation/test to functions\n","- **TRIED**: Reduce parameters, epochs.\n","- **TRIED**: Try changing batch size\n","- **TRIED**: Use Data Augmentation\n","- **DONE**: Try to train last few layers of ResNet50 with the data\n","- **TRIED**: Accuracy is fluctuating... optimize hyper parameters to have a smooth increase\n","- **TRIED** Try Regularization\n","- Our image size is 250x250. ResNet50 expects 224x224. Do we need to do anything or ResNet50 will understand ?\n","- **DONE**: Change Model to MobileNet\n","- **DONE**: Is image resize done correctly for MobileNet ?\n","- **DONE**: Implement K Cross Validation for Epoch = 1, Fold = 4\n","- **DONE**: Implement FLOPS\n","- Check version of MobileNet ... try using tf.keras.applications.MobileNet() instead of tf.keras.applications.mobilenet.MobileNet()\n","- Query: Should the batch_size be 1 or 10 for FLOPS calculation\n","- Query: There should not be any difference in FLOPS for Transfer/FineTune Model, correct ?\n","- Run K Cross Validation for Epoch = 100, Fold = 4\n","- IO: Convert K-cross validation sections into functions\n","- IO: Save best k fold of MobileNet Transfer and use for FineTune\n"]},{"cell_type":"markdown","metadata":{"id":"GELaKt4nTUx2"},"source":["## Download Dataset"]},{"cell_type":"markdown","metadata":{"id":"ouwKeET6nbZK"},"source":["### Download Train, Validate and Test Images"]},{"cell_type":"markdown","metadata":{"id":"AvHgttBNTUx2"},"source":["- Source Link to the Dataset / Annotation File: https://idr.openmicroscopy.org/webclient/?show=project-402\n","- Follow the instructions at following link, install IBM Aspera Desktop Client to download the dataset.\n","- Copy downloaded folders to '**data/images**' folder in your working directory where you have this Jupyter Notebook:\n","  - 'held-out_validation'\n","  - 'training'"]},{"cell_type":"markdown","metadata":{"id":"Sa6xmGhlniIH"},"source":["### Download Label Information for Train, Validate and Test Images "]},{"cell_type":"markdown","metadata":{"id":"8QpqHhxkTUx2"},"source":["- Following link will point to below Github link which has the annotation File: https://idr.openmicroscopy.org/webclient/?show=project-402\n","- Source Link for the Annotation File: https://github.com/IDR/idr0042-nirschl-wsideeplearning/tree/master/experimentA\n","- Download and copy file '**idr0042-experimentA-annotation.csv**' to '**data/labels/**' folder in your working directory where you have this Jupyter Notebook"]},{"cell_type":"markdown","metadata":{"id":"jV7ukSgPJKra"},"source":["## References"]},{"cell_type":"markdown","metadata":{"id":"KLXoJsxynoCB"},"source":["### Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"G-HdlAy_TUx3"},"source":["- Access Google Drive files from Google Colab\n","  - https://www.youtube.com/watch?reload=9&v=lHRC5gFvQnA\n","- Reading an image\n","  - mathplotlib: https://stackoverflow.com/questions/9298665/cannot-import-scipy-misc-imread\n","  - pathlib: https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f#:~:text=To%20use%20it%2C%20you%20just,for%20the%20current%20operating%20system.\n","  - OpenCV: https://www.geeksforgeeks.org/python-opencv-cv2-imread-method/\n","- Load multiple images into a numpy array\n","  - glob / os.listdir: https://stackoverflow.com/questions/39195113/how-to-load-multiple-images-in-a-numpy-array\n","  - glob / cv2: https://medium.com/@muskulpesent/create-numpy-array-of-images-fecb4e514c4b\n","- Load a CSV file\n","  - Datacamp: https://www.datacamp.com/community/tutorials/pandas-read-csv?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=278443377095&utm_targetid=dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=9061994&gclid=EAIaIQobChMIz5TKz-v17QIV1AorCh0bfw96EAAYASAAEgKiGPD_BwE\n","- Split a String\n","  - Python Central: https://www.pythoncentral.io/cutting-and-slicing-strings-in-python/\n","- Image Resize\n","  - https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n","  - https://stackoverflow.com/questions/55571664/mobilenets-for-a-custom-image-size\n","- Merge Train/Val/Test data\n","  - Merge Dataframes\n","    - https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n","  - Merge and Split Dataframes\n","    - https://datascience.stackexchange.com/questions/81617/how-to-combine-and-separate-test-and-train-data-for-data-cleaning\n","  - \n","\n"]},{"cell_type":"markdown","metadata":{"id":"XEayMrPQnvSL"},"source":["### Model Definition"]},{"cell_type":"markdown","metadata":{"id":"9CPryaAbn0xA"},"source":["- ResNet50\r\n","  - https://cv-tricks.com/keras/understand-implement-resnets/\r\n","  - Finetuning ResNet50\r\n","    - https://www.pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/\r\n","- MobileNet\r\n","  - https://deeplizard.com/learn/video/Zrt76AIbeh4\r\n","  - https://towardsdatascience.com/exploring-mobilenets-from-paper-to-keras-f01308ada818\r\n","  - Fine Tuning MobileNet - Last few layers trainable\r\n","    - https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299\r\n","  - MobileNet Version:\r\n","    - https://keras.io/api/applications/mobilenet/\r\n","- SqueezeNet\r\n","  - https://codelabs.developers.google.com/codelabs/keras-flowers-squeezenet#6"]},{"cell_type":"markdown","metadata":{"id":"6s5vSukpETho"},"source":["### Model Validation\r\n"]},{"cell_type":"markdown","metadata":{"id":"nOGLP3V-EcGc"},"source":["- Keras Optimizer / Adam\r\n","  - https://keras.io/api/optimizers/\r\n","- Regularizer\r\n","  - https://keras.io/api/layers/regularizers/\r\n","- Save Weights for Best Model\r\n","  - https://medium.com/@italojs/saving-your-weights-for-each-epoch-keras-callbacks-b494d9648202\r\n","  - Monitoring Validaiton Accuracy - Skipping Error Solution\r\n","    - https://github.com/tensorflow/tensorflow/issues/33163\r\n","  - Predict using saved model\r\n","    - https://stackoverflow.com/questions/44259651/how-to-use-predefined-trained-hdf5-file-with-wights-to-predict-a-class-of-new\r\n","- K-cross validation: https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538\r\n","  - use non-categorical labels for k-cross validation splits: https://stackoverflow.com/questions/48508036/sklearn-stratifiedkfold-valueerror-supported-target-types-are-binary-mul\r\n","  - https://machinelearningmastery.com/ : Deep Learning with Python Book\r\n","- FLOPS calculation\r\n","  - https://pypi.org/project/keras-flops/\r\n","  - https://www.manongdao.com/article-1967231.html\r\n","- Time calculation\r\n","  - https://www.tutorialspoint.com/How-to-get-current-time-in-milliseconds-in-Python#:~:text=You%20can%20get%20the%20current,1000%20and%20round%20it%20off.\r\n"]},{"cell_type":"markdown","metadata":{"id":"YYdvA7O8KAK0"},"source":["## Understand Dataset"]},{"cell_type":"markdown","metadata":{"id":"3586paiFoAvW"},"source":["### Understand Images Folder Structure and Number of Images Available"]},{"cell_type":"markdown","metadata":{"id":"iVqvp6TDTUx4"},"source":["Training/Validation\n","- \\..\\training\\fold_1: has images for training = 770#\n","- \\..\\training\\test_fold_1: has images for validation = 374#\n","- Total = 770 + 374 = 1144 images\n","\n","Test\n","- \\..\\held-out_validation: has images for testing = 1155#"]},{"cell_type":"markdown","metadata":{"id":"Avjn1GKeoEd4"},"source":["### Understand Annotation File and Label Information Available"]},{"cell_type":"markdown","metadata":{"id":"-MOqlD8qTUx4"},"source":["Relevant columns of interest:\n","- Column A: Dataset Name: Classifies each row/instance as 'training' or 'test'\n","- Column B: Image Name: Specifies filename of the image for the row/instance\n","- Column Z: Experimental Condition [Diagnosis]: has 3 classes:\n","  - 'chronic heart failure'\n","  - 'heart tissue pathology' - We will treat this as 'not chronic heart failure'\n","  - 'not chronic heart failure'\n","- Column AA: Channels: mentions RGB => images are color images and will have 3 channels Red/Green/Blue (for CNN). \n","  \n","Breakup of training/test instances:\n","- training\n","  - 'chronic heart failure' = 517\n","  - 'not chronic heart failure' = 627\n","- test\n","  - 'chronic heart failure' = 517\n","  - 'not chronic heart failure' = 638\n","\n","Total 'training' = 517 + 627 = 1144  (Note: 'validate' is a portion of this 'training' set.)\n","\n","Total 'test' = 517 + 638 = 1155"]},{"cell_type":"markdown","metadata":{"id":"rLtVEWyYoiVU"},"source":["## Access Dataset"]},{"cell_type":"markdown","metadata":{"id":"4Oem7YyjKL7Z"},"source":["### Load Libraries"]},{"cell_type":"markdown","metadata":{"id":"BxnppA2lTUx4"},"source":["We need to read 'train, validate and test images' to arrays so that we can then use them to feed to our CNN model. We need to import the annotation file into a dataframe so that we can then access the labels information."]},{"cell_type":"code","metadata":{"id":"4rqxeoKlTUx5","executionInfo":{"status":"ok","timestamp":1611775320534,"user_tz":-330,"elapsed":2649,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# install OpenCV package - this is required only once\n","# pip install opencv-python"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvKVTkfxTUx5","executionInfo":{"status":"ok","timestamp":1611775323943,"user_tz":-330,"elapsed":6052,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# aids in reading image files\r\n","import cv2\r\n","import glob"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yhluyj4TUx6","executionInfo":{"status":"ok","timestamp":1611775323945,"user_tz":-330,"elapsed":6050,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# aids in working with arrays\r\n","import numpy as np"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"qyBfK1j9TUx6","executionInfo":{"status":"ok","timestamp":1611775323945,"user_tz":-330,"elapsed":6046,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# aids in working with dataframes\r\n","import pandas as pd"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PmuzEGsl12zy"},"source":["### Mount Google Drive"]},{"cell_type":"markdown","metadata":{"id":"1fL4wKtMLhw3"},"source":["We need to mount the google drive so that we can then access the files from google drive."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhVh4qU1U47e","executionInfo":{"status":"ok","timestamp":1611775512999,"user_tz":-330,"elapsed":195082,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"5fcc3ea6-248a-416a-cfce-800fed3a26d8"},"source":["# run this. click on the link it will ask for. get the authentication code. Copy/Paste in the cell. Hit Enter.\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"scKwsOqb96HO"},"source":["### Libraries for Calculating Time Duration"]},{"cell_type":"code","metadata":{"id":"dispug5sRA9E","executionInfo":{"status":"ok","timestamp":1611775513644,"user_tz":-330,"elapsed":195725,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["import time"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rmu8WoMlNJFY"},"source":["### Get labels info into a dataframe"]},{"cell_type":"code","metadata":{"id":"COjL64aeTUx7","executionInfo":{"status":"ok","timestamp":1611775514592,"user_tz":-330,"elapsed":196670,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# Google Drive / Colab\r\n","filepath_annotation_file = r'/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/labels/idr0042-experimentA-annotation.csv'\r\n","labels = pd.read_csv(filepath_annotation_file)\r\n","\r\n","# Local Drive / Jupyter\r\n","# labels = pd.read_csv('data/labels/idr0042-experimentA-annotation.csv')"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Umta4jPKMzCR"},"source":["### Explore and Understand"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":793},"id":"nr21_2SiTUx7","executionInfo":{"status":"ok","timestamp":1611775514598,"user_tz":-330,"elapsed":196656,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"2a203185-3e61-4b2b-8cf9-cacd18ccebc8"},"source":["# uncomment & check the contents of labels is as expected\r\n","labels"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset Name</th>\n","      <th>Image Name</th>\n","      <th>Characteristics [Organism]</th>\n","      <th>Term Source 1 REF</th>\n","      <th>Term Source 1 Accession</th>\n","      <th>Characteristics [Organism Part]</th>\n","      <th>Term Source 2 REF</th>\n","      <th>Term Source 2 Accession</th>\n","      <th>Characteristics [Diagnosis]</th>\n","      <th>Term Source 3 REF</th>\n","      <th>Term Source 3 Accession</th>\n","      <th>Characteristics [Disease Subtype]</th>\n","      <th>Term Source 4 REF</th>\n","      <th>Term Source 4 Accession</th>\n","      <th>Characteristics [Sex]</th>\n","      <th>Term Source 5 REF</th>\n","      <th>Term Source 5 Accession</th>\n","      <th>Characteristics [Ethnic or Racial Group]</th>\n","      <th>Term Source 6 REF</th>\n","      <th>Term Source 6 Accession</th>\n","      <th>Characteristics [Age]</th>\n","      <th>Characteristics [Individual]</th>\n","      <th>Characteristics [Clinical History]</th>\n","      <th>Protocol REF</th>\n","      <th>Protocol REF.1</th>\n","      <th>Experimental Condition [Diagnosis]</th>\n","      <th>Channels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>training</td>\n","      <td>33381_0_fal_10_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>training</td>\n","      <td>33381_0_fal_14_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>training</td>\n","      <td>33381_0_fal_16_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>training</td>\n","      <td>33381_0_fal_18_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>training</td>\n","      <td>33381_0_fal_25_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_D3-16007</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>CVDO</td>\n","      <td>CVDO_0000558</td>\n","      <td>male</td>\n","      <td>PATO</td>\n","      <td>PATO_0000384</td>\n","      <td>African American</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-62310</td>\n","      <td>65 years</td>\n","      <td>33381</td>\n","      <td>ischemic cardiomyopathy</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2294</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_18_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2295</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_1_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2296</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_20_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2297</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_21_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","    <tr>\n","      <th>2298</th>\n","      <td>test</td>\n","      <td>36175_1_nrm_2_0.png</td>\n","      <td>Homo sapiens</td>\n","      <td>NCBITaxon</td>\n","      <td>NCBITaxon_9606</td>\n","      <td>heart</td>\n","      <td>UBERON</td>\n","      <td>UBERON_0000948</td>\n","      <td>not chronic heart failure</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_F-30001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>female</td>\n","      <td>PATO</td>\n","      <td>PATO_0000383</td>\n","      <td>Caucasian</td>\n","      <td>SNOMED</td>\n","      <td>SNOMED_S-0003D</td>\n","      <td>53 years</td>\n","      <td>36175</td>\n","      <td>normal cardiovascular function by cardiac cath...</td>\n","      <td>treatment protocol</td>\n","      <td>image acquisition</td>\n","      <td>not chronic heart failure</td>\n","      <td>RGB</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2299 rows × 27 columns</p>\n","</div>"],"text/plain":["     Dataset Name  ... Channels\n","0        training  ...      RGB\n","1        training  ...      RGB\n","2        training  ...      RGB\n","3        training  ...      RGB\n","4        training  ...      RGB\n","...           ...  ...      ...\n","2294         test  ...      RGB\n","2295         test  ...      RGB\n","2296         test  ...      RGB\n","2297         test  ...      RGB\n","2298         test  ...      RGB\n","\n","[2299 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_f1boOAdTUx8","executionInfo":{"status":"ok","timestamp":1611775514600,"user_tz":-330,"elapsed":196646,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"30a2d0eb-16a7-4935-c99b-9322cd192b29"},"source":["print(labels['Dataset Name'])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["0       training\n","1       training\n","2       training\n","3       training\n","4       training\n","          ...   \n","2294        test\n","2295        test\n","2296        test\n","2297        test\n","2298        test\n","Name: Dataset Name, Length: 2299, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7D8mQdhTUx8","executionInfo":{"status":"ok","timestamp":1611775514601,"user_tz":-330,"elapsed":196636,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"353ff985-42ae-4e14-f30b-a01438672fd5"},"source":["print(labels['Dataset Name'][0])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2HQQ_GzTUx9","executionInfo":{"status":"ok","timestamp":1611775514603,"user_tz":-330,"elapsed":196627,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"5b1bd58a-ddeb-46a5-c65a-9b61d1b12691"},"source":["type(labels['Dataset Name'][0])"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O3qnTY8rTUx9","executionInfo":{"status":"ok","timestamp":1611775514605,"user_tz":-330,"elapsed":196617,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"92fd3c11-53d7-4a7a-df14-186befe9daca"},"source":["print(labels['Image Name'])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["0       33381_0_fal_10_0.png\n","1       33381_0_fal_14_0.png\n","2       33381_0_fal_16_0.png\n","3       33381_0_fal_18_0.png\n","4       33381_0_fal_25_0.png\n","                ...         \n","2294    36175_1_nrm_18_0.png\n","2295     36175_1_nrm_1_0.png\n","2296    36175_1_nrm_20_0.png\n","2297    36175_1_nrm_21_0.png\n","2298     36175_1_nrm_2_0.png\n","Name: Image Name, Length: 2299, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUjbBjagTUx9","executionInfo":{"status":"ok","timestamp":1611775514608,"user_tz":-330,"elapsed":196610,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"00411c34-a406-4324-d0fb-1b42bf3ebb44"},"source":["print(labels['Image Name'][0])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["33381_0_fal_10_0.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlEwMNmXTUx-","executionInfo":{"status":"ok","timestamp":1611775514610,"user_tz":-330,"elapsed":196601,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"7fddf140-a33d-4582-b2ee-144a51acf64f"},"source":["type(labels['Image Name'][0])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7-b5mycTUx-","executionInfo":{"status":"ok","timestamp":1611775514611,"user_tz":-330,"elapsed":196591,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"245b78fb-54f7-4012-dc17-484f0c437c0f"},"source":["print(labels['Experimental Condition [Diagnosis]'])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["0           chronic heart failure\n","1           chronic heart failure\n","2           chronic heart failure\n","3           chronic heart failure\n","4           chronic heart failure\n","                  ...            \n","2294    not chronic heart failure\n","2295    not chronic heart failure\n","2296    not chronic heart failure\n","2297    not chronic heart failure\n","2298    not chronic heart failure\n","Name: Experimental Condition [Diagnosis], Length: 2299, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljWCGdQZTUx-","executionInfo":{"status":"ok","timestamp":1611775514612,"user_tz":-330,"elapsed":196581,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"72cdce72-9490-4df2-f11f-d4ecee554246"},"source":["print(labels['Experimental Condition [Diagnosis]'][0])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["chronic heart failure\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-MoFvzPTUx-","executionInfo":{"status":"ok","timestamp":1611775514613,"user_tz":-330,"elapsed":196571,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"001546da-e788-4149-f8a7-7fca86f2e761"},"source":["type(labels['Experimental Condition [Diagnosis]'][0])"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UiPxrxBTUx_","executionInfo":{"status":"ok","timestamp":1611775514614,"user_tz":-330,"elapsed":196560,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"93669460-72a0-477e-dbba-6635bf19fd33"},"source":["# confirm 'no info' cells have been encoded as 'nan'... check one entry\n","print(labels['Characteristics [Disease Subtype]'][463])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["nan\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0Rczcv_kTUx_"},"source":["### Prepare Train Images and Train Labels"]},{"cell_type":"markdown","metadata":{"id":"9c3UtN962MOe"},"source":["#### Explore and Understand"]},{"cell_type":"code","metadata":{"id":"XRQUsN0mTUx_","executionInfo":{"status":"ok","timestamp":1611775517922,"user_tz":-330,"elapsed":199864,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# Google Drive / Colab\n","filepathlist_train = glob.glob('/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/fold_1/*.png')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlwIDpjETUx_","executionInfo":{"status":"ok","timestamp":1611775517923,"user_tz":-330,"elapsed":199853,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"0c0e9cd0-40fb-415e-ad5e-b7c7513fab54"},"source":["# confirm you have got the total number of desired items in the list\n","len(filepathlist_train)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["770"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"f1dvk1dxTUyA","executionInfo":{"status":"ok","timestamp":1611775517925,"user_tz":-330,"elapsed":199840,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"7d4e7ebc-ec6a-422a-8aee-17a6adcd00c9"},"source":["# check what an element in the filelist contain.\n","# it has both directory information and the filename, we need to extract filename \n","# the filename can then be used to check for the label info in the labels dataframe\n","filepathlist_train[0]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/fold_1/33392_0_fal_4_0.png'"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"w7ktSh4J2WTy"},"source":["#### Extract Filename and Label Info"]},{"cell_type":"markdown","metadata":{"id":"Jz_-xEdgNtBZ"},"source":["All the images are of type '*.png'. We will read filepath for all \"filenames with extension as 'png'\" into a list. Here, filepath means 'relative directory + filename'. We will extract filename of the image from the file path. This filename can then be used to get the label information from the annotation file."]},{"cell_type":"markdown","metadata":{"id":"S_oFfXABTJKJ"},"source":["##### Local Drive / Jupyter "]},{"cell_type":"code","metadata":{"id":"8OPsW8eT_MFA","executionInfo":{"status":"ok","timestamp":1611775517926,"user_tz":-330,"elapsed":199837,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# this scenario has '\\\\' between the directory and filename\r\n","# split the string\r\n","# directory, filename = filepathlist_train[0].split('\\\\')\r\n","# gives the directory info\r\n","# directory\r\n","# gives the filname we need\r\n","# filename"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wLmi5HsgSeEo"},"source":["##### Google Drive / Colab"]},{"cell_type":"markdown","metadata":{"id":"5qmSWkpX2qCW"},"source":["###### Explore and Understand"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ir9jzf_78oJu","executionInfo":{"status":"ok","timestamp":1611775517927,"user_tz":-330,"elapsed":199824,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"352f97c4-6138-4bf3-b3c5-0c493122377e"},"source":["len(filepathlist_train[0])"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"J16b0aYw8uAr","executionInfo":{"status":"ok","timestamp":1611775517929,"user_tz":-330,"elapsed":199810,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"a43b28d7-c12c-46af-fa02-ba436d09ed56"},"source":["filepathlist_train[0][-19:]"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'33392_0_fal_4_0.png'"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vxczcvry97HG","executionInfo":{"status":"ok","timestamp":1611775517930,"user_tz":-330,"elapsed":199795,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"a1a12b8a-5542-4c68-895b-fb414147296a"},"source":["filepathlist_train[0][len(filepathlist_train[0]) - 1]"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'g'"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"0OXQGUkc-Inp","executionInfo":{"status":"ok","timestamp":1611775517934,"user_tz":-330,"elapsed":199783,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"39564dab-76db-43f7-c669-c00fdf5ef490"},"source":["filepathlist_train[0][-1]"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'g'"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2_o3p9y9TUyA","executionInfo":{"status":"ok","timestamp":1611775517936,"user_tz":-330,"elapsed":199773,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"9535d668-6c08-44a7-a1a7-fbe54fe13058"},"source":["# POC\n","idx = -1\n","while (filepathlist_train[0][idx] != '/'):\n","  idx = idx - 1 \n","# index currently points to '/' location, we need to start reading from next location to get file name\n","print(idx)\n","filename = filepathlist_train[0][idx + 1:]\n","print(filename)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["-20\n","33392_0_fal_4_0.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gmFAoRozX4xX","executionInfo":{"status":"ok","timestamp":1611775517938,"user_tz":-330,"elapsed":199772,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# POC\r\n","index_filepathlist = 0\r\n","for filepath in filepathlist_train:\r\n","    #print(index_filepathlist, filepath)\r\n","    index_filepathlist += 1"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXlYHbSPTBfy","executionInfo":{"status":"ok","timestamp":1611775518308,"user_tz":-330,"elapsed":200140,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# read a file using the list containing the file path\r\n","img = cv2.imread(filepathlist_train[0])"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K54cMICV2vc9"},"source":["##### Define a Call Function to prepare images and labels"]},{"cell_type":"code","metadata":{"id":"NC6R5bJlpRLR","executionInfo":{"status":"ok","timestamp":1611775518311,"user_tz":-330,"elapsed":200141,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# function to prepare images & labels for the model\r\n","def prepare_images_labels (path_to_img_files, labels_dataframe, resize = 0):\r\n","  filepathlist = glob.glob(path_to_img_files)\r\n","  # define the empty list that need to populated with info\r\n","  images = []\r\n","  labels = []\r\n","  index_filepathlist = 0\r\n","  # iterate for all items in the file path list\r\n","  for filepath in filepathlist:\r\n","      # prepare image list\r\n","      img = cv2.imread(filepath)\r\n","      if (resize == 1):\r\n","        dim = (224,224)\r\n","        img = cv2.resize(img, dim)#, interpolation = inter)\r\n","      images.append(img)\r\n","      # prepare labels list\r\n","      # extract filename from the file path\r\n","      # Local Drive / Jupyter\r\n","      # directory, filename = filepath.split('\\\\')\r\n","      # Google Drive / Colab\r\n","      index_character = -1\r\n","      while (filepathlist[index_filepathlist][index_character] != '/'):\r\n","        index_character = index_character - 1 \r\n","      # character index currently points to '/' location, we need to start reading from next location to get file name\r\n","      filename = filepathlist[index_filepathlist][index_character + 1:]\r\n","      index_filepathlist += 1\r\n","      # iterate for all items in our labels dataframe to search for the label\r\n","      for index in range(len(labels_dataframe)):\r\n","          # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\r\n","          # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\r\n","          if (filename == labels_dataframe['Image Name'][index]):\r\n","              label = labels_dataframe['Experimental Condition [Diagnosis]'][index]\r\n","              # encode Class1 and Class0 as applicable\r\n","              if (label == 'chronic heart failure'):\r\n","                  label = 1\r\n","              elif (label == 'not chronic heart failure'):\r\n","                  label = 0\r\n","              elif (label == 'heart tissue pathology'):\r\n","                  label = 0\r\n","              # append the label to the list\r\n","              labels.append(label)\r\n","  return images, labels"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a2xpvmempoa4"},"source":["##### Prepare Train Images and Train Labels"]},{"cell_type":"code","metadata":{"id":"0PyeiK-Ulctu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816566,"user_tz":-330,"elapsed":498383,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"b78a2c05-1a1a-4795-bd3f-f459a835dda7"},"source":["# read filepath for all \"filenames with extension as 'png'\" into a list\r\n","# here filepath means 'relative directory + filename'\r\n","\r\n","# Google Drive / Colab\r\n","path_to_img_files = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/fold_1/*.png'\r\n","# for resnet50\r\n","# train_images, train_labels = prepare_images_labels (path_to_img_files, labels, 0)\r\n","# for mobilenet\r\n","start_time = time.time()\r\n","duration = time.time() - start_time\r\n","train_images, train_labels = prepare_images_labels (path_to_img_files, labels, 1)\r\n","print(f'Train Image/Labels Prep Core Time = {duration}s')\r\n","\r\n","# Local Drive / Jupyter\r\n","# filepathlist_train = glob.glob('data/images/training/fold_1/*.png')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Train Image/Labels Prep Core Time = 1.6450881958007812e-05s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YrhMe6CvTUyB","executionInfo":{"status":"ok","timestamp":1611775816568,"user_tz":-330,"elapsed":498380,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# train_labels"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6xHVSfMKTUyC"},"source":["Convert images to numpy arrays and confirm shape is as required for CNN. "]},{"cell_type":"code","metadata":{"id":"CGFHcbYNTUyC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816568,"user_tz":-330,"elapsed":498374,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"16d64a2e-7960-4d5c-d69e-c14d2eb0e942"},"source":["# confirm you have got the total number desired images in the list\n","len(train_images)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["770"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"imoqMNZHTUyC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816571,"user_tz":-330,"elapsed":498375,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"4e9ff80f-0e8a-4624-d4bf-87c5520c29b9"},"source":["# train is a list\n","type(train_images)"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"rE1sBd7wTUyC","executionInfo":{"status":"ok","timestamp":1611775816572,"user_tz":-330,"elapsed":498374,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert list to a numpy array and the values to float\n","train_images = np.array(train_images, dtype = 'float32')"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwnwE79LTUyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816573,"user_tz":-330,"elapsed":498372,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"119f75f6-72a2-4c9b-f8d6-6cec78c81848"},"source":["# check the shape to confirm it is ready for CNN\n","# number of instances, width, height, number of channels\n","# number of instances = number of image\n","# number of channels = 3 ... as these are color images\n","train_images.shape"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(770, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"ThTHsjK5TUyD"},"source":["Convert labels to numpy arrays and confirm shape is as required for CNN. "]},{"cell_type":"code","metadata":{"id":"HvNJR0CVTUyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816574,"user_tz":-330,"elapsed":498371,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"ba9bbebc-dd9e-47ae-c6c9-511aaacd89f8"},"source":["len(train_labels)"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["770"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"8MlrY4_HTUyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816577,"user_tz":-330,"elapsed":498371,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"60e3272f-1b4f-495b-cdac-99da6d9c8c2f"},"source":["type(train_labels)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"q3So3_2FTUyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816578,"user_tz":-330,"elapsed":498369,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"8b0249c2-1903-43bd-e958-4bcf47fb1d6c"},"source":["train_labels[0]"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"VE5e9MDoTUyE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816578,"user_tz":-330,"elapsed":498367,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"213168d4-957c-47cc-d637-66b74aa881e5"},"source":["train_labels[432]"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"zS5caNeTTUyE","executionInfo":{"status":"ok","timestamp":1611775816579,"user_tz":-330,"elapsed":498366,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert list to a numpy array and the values to int64\n","train_labels = np.array(train_labels, dtype = 'int64')"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDLfwCgDTUyE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816580,"user_tz":-330,"elapsed":498364,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"d31d08f1-476e-4d4d-a71c-1ff3a9603c3c"},"source":["# check the shape to confirm it is ready for CNN\n","train_labels.shape"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(770,)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"FATnUKBQTUyE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816580,"user_tz":-330,"elapsed":498362,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"0330d8d9-1dc0-4049-d1e7-74de0a1c8310"},"source":["len(train_labels)"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["770"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"7MiV5FQfTUyF"},"source":["Let us check on the number of Class 0 and Class 1s that we have. "]},{"cell_type":"code","metadata":{"id":"7KqlbiYajI1D","executionInfo":{"status":"ok","timestamp":1611775816581,"user_tz":-330,"elapsed":498361,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# function to count ones and zeroes in the label array\r\n","def print_ones_zeroes (labels):\r\n","  count_ones = 0\r\n","  count_zeroes = 0\r\n","  for i in range(len(labels)):\r\n","    if (labels[i] == 1):\r\n","      count_ones += 1\r\n","    elif (labels[i] == 0):\r\n","      count_zeroes += 1\r\n","  print('Total Labels:',(count_ones + count_zeroes))\r\n","  print('# of Class 1:',count_ones)   \r\n","  print('# of Class 0:',count_zeroes)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"STcznNLMjR7q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816582,"user_tz":-330,"elapsed":498360,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"16f0870b-3ed1-4da2-c993-0d3a8cec4ab9"},"source":["print_ones_zeroes(train_labels)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Total Labels: 770\n","# of Class 1: 352\n","# of Class 0: 418\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4MWLV_Zumm3A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775816583,"user_tz":-330,"elapsed":498358,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"3c0a72ce-8368-4098-a3dd-d1c3688464f7"},"source":["# save the train labels before converting to categorical to use for cross validation splits\r\n","train_labels_before_categorical = train_labels\r\n","print(type(train_labels_before_categorical), len(train_labels_before_categorical), train_labels_before_categorical.shape)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> 770 (770,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CDYnWqw6TUyF"},"source":["We will convert the labels to 2bit values: 01 and 10 to correspond to the 2 classes. This is required to match to the model's output layer expectation so that we can effectively train and test. "]},{"cell_type":"code","metadata":{"id":"wY6Wz_rgTUyF","executionInfo":{"status":"ok","timestamp":1611775818209,"user_tz":-330,"elapsed":499982,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["from keras.utils import to_categorical"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwBRGFFVTUyG","executionInfo":{"status":"ok","timestamp":1611775818211,"user_tz":-330,"elapsed":499982,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert labels to categorical\n","train_labels = to_categorical(train_labels)"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mtvpF6A6TUyG"},"source":["### Prepare Validation Images and Validation Labels"]},{"cell_type":"code","metadata":{"id":"O1PsdEXm6T8n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775952944,"user_tz":-330,"elapsed":634711,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"71ff6843-09f9-4913-93e1-4389bc0e88a4"},"source":["# read filepath for all \"filenames with extension as 'png'\" into a list\r\n","# here filepath means 'relative directory + filename'\r\n","\r\n","# Google Drive / Colab\r\n","path_to_img_files = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/test_fold_1/*.png'\r\n","# for resnet50\r\n","# validation_images, validation_labels = prepare_images_labels (path_to_img_files, labels, 0)\r\n","# for mobilenet\r\n","start_time = time.time()\r\n","validation_images, validation_labels = prepare_images_labels (path_to_img_files, labels, 1)\r\n","duration = time.time() - start_time\r\n","print(f'Validation Image/Labels Prep Core Time = {duration}s')\r\n","\r\n","# Local Drive / Jupyter\r\n","# filepathlist_validation = glob.glob('data/images/training/test_fold_1/*.png')"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Validation Image/Labels Prep Core Time = 134.65818333625793s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7fJuHg1dTUyH","executionInfo":{"status":"ok","timestamp":1611775952946,"user_tz":-330,"elapsed":634711,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert list to a numpy array and the values to float\n","validation_images = np.array(validation_images, dtype = 'float32')"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"xlFbfassTUyH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775952947,"user_tz":-330,"elapsed":634709,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"6e61a68e-eac2-4dba-c3f4-37f785b4cca5"},"source":["# check the shape to confirm it is ready for CNN\n","validation_images.shape"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(374, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"EfuLDkHbTUyI","executionInfo":{"status":"ok","timestamp":1611775952949,"user_tz":-330,"elapsed":634709,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert list to a numpy array and the values to int64\n","validation_labels = np.array(validation_labels, dtype = 'int64')"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOIVr3VRTUyI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775952949,"user_tz":-330,"elapsed":634707,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"1b4fa479-7b21-42fa-e9f9-a9510f9ccb85"},"source":["# check the shape to confirm it is ready for CNN\n","validation_labels.shape"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(374,)"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"markdown","metadata":{"id":"p_TwktKETUyI"},"source":["Let us check on the number of Class 0 and Class 1s that we have. "]},{"cell_type":"code","metadata":{"id":"Q_yJRYt-kvfD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775952950,"user_tz":-330,"elapsed":634705,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"cd2ca49e-078b-4e6e-a5f1-c9ca83422d12"},"source":["print_ones_zeroes(validation_labels)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Total Labels: 374\n","# of Class 1: 165\n","# of Class 0: 209\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rxEMClStmtAT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611775952951,"user_tz":-330,"elapsed":634703,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"161497a4-ce0d-4ace-a58b-f5d3d0cf3594"},"source":["# save the train labels before converting to categorical to use for cross validation splits\r\n","validation_labels_before_categorical = validation_labels\r\n","print(type(validation_labels_before_categorical), len(validation_labels_before_categorical), validation_labels_before_categorical.shape)"],"execution_count":55,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> 374 (374,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4euJT10hTUyJ","executionInfo":{"status":"ok","timestamp":1611775952951,"user_tz":-330,"elapsed":634701,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert labels to categorical\n","validation_labels = to_categorical(validation_labels)"],"execution_count":56,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EzMWmY9PTUyJ"},"source":["### Prepare Test Images and Test Labels"]},{"cell_type":"code","metadata":{"id":"9D4Ol2gZ60PN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366152,"user_tz":-330,"elapsed":1047900,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"40cbd165-b9d2-44a9-da82-2bd0af06d1e8"},"source":["# read filepath for all \"filenames with extension as 'png'\" into a list\r\n","# here filepath means 'relative directory + filename'\r\n","\r\n","# Google Drive / Colab\r\n","path_to_img_files = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/held-out_validation/*.png'\r\n","# for resnet50\r\n","# test_images, test_labels = prepare_images_labels (path_to_img_files, labels, 0)\r\n","# for mobilenet\r\n","start_time = time.time()\r\n","test_images, test_labels = prepare_images_labels (path_to_img_files, labels, 1)\r\n","duration = time.time() - start_time\r\n","print(f'Test Image/Labels Prep Core Time = {duration}s')\r\n","\r\n","# Local Drive / Jupyter\r\n","# filepathlist_test = glob.glob('data/images/held-out_validation/*.png')"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Test Image/Labels Prep Core Time = 413.149288892746s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xCjwEDeCTUyN","executionInfo":{"status":"ok","timestamp":1611776366154,"user_tz":-330,"elapsed":1047899,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert list to a numpy array and the values to float\n","test_images = np.array(test_images, dtype = 'float32')"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKORF7UjTUyN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366155,"user_tz":-330,"elapsed":1047898,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"b8f8a9ae-4899-4a56-f036-819c63ffba71"},"source":["# check the shape to confirm it is ready for CNN\n","test_images.shape"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1155, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"1sfmo-v2TUyO","executionInfo":{"status":"ok","timestamp":1611776366155,"user_tz":-330,"elapsed":1047896,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert list to a numpy array and the values to int64\n","test_labels = np.array(test_labels, dtype = 'int64')"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"njHiGVDRTUyO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366156,"user_tz":-330,"elapsed":1047894,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"bc422d8c-50bd-48b8-c4a2-69662951317f"},"source":["# check the shape to confirm it is ready for CNN\n","test_labels.shape"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1155,)"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"Gk05ShqrTUyQ"},"source":["Let us check on the number of Class 0 and Class 1s that we have. "]},{"cell_type":"code","metadata":{"id":"yw7aYatDlCHD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366157,"user_tz":-330,"elapsed":1047893,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"1cffc4a9-ef97-4590-e1d9-fcab3fbe7cdc"},"source":["print_ones_zeroes(test_labels)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Total Labels: 1155\n","# of Class 1: 517\n","# of Class 0: 638\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"utT38t8Qmzx4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366158,"user_tz":-330,"elapsed":1047891,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"39ab776c-9a55-43af-d6fd-4e5d276a6e99"},"source":["# save the train labels before converting to categorical to use for cross validation splits\r\n","test_labels_before_categorical = test_labels\r\n","print(type(test_labels_before_categorical), len(test_labels_before_categorical), test_labels_before_categorical.shape)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> 1155 (1155,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dScQ0oPFTUyR","executionInfo":{"status":"ok","timestamp":1611776366158,"user_tz":-330,"elapsed":1047889,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# convert labels to categorical\n","test_labels = to_categorical(test_labels)"],"execution_count":64,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t2qDQBwAozQt"},"source":["### Prepare All Images and Labels for Cross Validation"]},{"cell_type":"code","metadata":{"id":"YFPwNCSro94S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366159,"user_tz":-330,"elapsed":1047886,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"cd8833e3-02e4-4461-c16f-723b58d76645"},"source":["# confirm all are numpy arrays, length and shape\r\n","print(type(train_images), len(train_images), train_images.shape)\r\n","print(type(validation_images), len(validation_images), validation_images.shape)\r\n","print(type(test_images), len(test_images), test_images.shape)\r\n","print(len(train_images) + len(validation_images) + len(test_images))\r\n","print(type(train_labels), len(train_labels), train_labels.shape)\r\n","print(type(validation_labels), len(validation_labels), validation_labels.shape)\r\n","print(type(test_labels), len(test_labels), test_labels.shape)\r\n","print(len(train_labels) + len(validation_labels) + len(test_labels))"],"execution_count":65,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> 770 (770, 224, 224, 3)\n","<class 'numpy.ndarray'> 374 (374, 224, 224, 3)\n","<class 'numpy.ndarray'> 1155 (1155, 224, 224, 3)\n","2299\n","<class 'numpy.ndarray'> 770 (770, 2)\n","<class 'numpy.ndarray'> 374 (374, 2)\n","<class 'numpy.ndarray'> 1155 (1155, 2)\n","2299\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"htuhdmUgpoJq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366585,"user_tz":-330,"elapsed":1048309,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"8d80acbf-bf0b-4291-bd0c-e20b091cb7b3"},"source":["# join train / validation / test arrays for images\r\n","all_images = np.concatenate((train_images, validation_images, test_images))\r\n","print(type(all_images), len(all_images), all_images.shape)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> 2299 (2299, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kp1QvE9qrMxV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366586,"user_tz":-330,"elapsed":1048307,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"a82d03be-0d7d-438a-e3f6-48f012a2a85c"},"source":["# join train / validation / test arrays for labels\r\n","all_labels = np.concatenate((train_labels, validation_labels, test_labels))\r\n","print(type(all_labels), len(all_labels), all_labels.shape)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> 2299 (2299, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vPzfLLNsm9Dq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776366587,"user_tz":-330,"elapsed":1048306,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"a9616f18-d9a7-4d8c-f882-8bba8665506a"},"source":["# prepare the labels to enable split during k-cross validation\r\n","all_labels_before_categorical = np.concatenate((train_labels_before_categorical, validation_labels_before_categorical, test_labels_before_categorical))\r\n","print(type(all_labels_before_categorical), len(all_labels_before_categorical), all_labels_before_categorical.shape)"],"execution_count":68,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> 2299 (2299,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"47ncBdcCTUyR"},"source":["## Model Definition / Train / Validate / Test\r\n"]},{"cell_type":"markdown","metadata":{"id":"4f-ntz2xgQKW"},"source":["### MNIST CNN modified for HE"]},{"cell_type":"code","metadata":{"id":"7FkIenzmgTbG","executionInfo":{"status":"ok","timestamp":1611776366587,"user_tz":-330,"elapsed":1048304,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# import libraries (general)\r\n","# from keras import models\r\n","# from keras import layers\r\n","# model_cnn = models.Sequential()\r\n","\r\n","# Layer Details:\r\n","# - 2 dimensional Convolution Layer\r\n","# - Number of filters/kernels = 32\r\n","# - Filter/Kernel Size = 3x3\r\n","# - Activation Function = relu (for non-linearity detection)\r\n","# - Input Shape = 250x250 matrix with 3 channel (as we have a color image)\r\n","# model_cnn.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(250,250,3)))\r\n","\r\n","# Layer Details:\r\n","# - Downsample the output from previous layer\r\n","# - We will take the max value for a every 2x2 window ... moved over the input\r\n","# model_cnn.add(layers.MaxPooling2D(2,2))\r\n","\r\n","# Layer Details:\r\n","# - 2 dimensional Convolution Layer\r\n","# - Number of filters/kernels = 64\r\n","# - Filter/Kernel Size = 3x3\r\n","# - Activation Function = relu (for non-linearity detection)\r\n","# model_cnn.add(layers.Conv2D(64, (3,3), activation = 'relu'))\r\n","\r\n","# Layer Details:\r\n","# - Downsample the output from previous layer\r\n","# - We will take the max value for a every 2x2 window ... moved over the input\r\n","# model_cnn.add(layers.MaxPooling2D(2,2))\r\n","\r\n","# Layer Details:\r\n","# - 2 dimensional Convolution Layer\r\n","# - Number of filters/kernels = 64\r\n","# - Filter/Kernel Size = 3x3\r\n","# - Activation Function = relu (for non-linearity detection)\r\n","# model_cnn.add(layers.Conv2D(64, (3,3), activation='relu'))\r\n","\r\n","# Data at this stage is in matrix form. We will convert it to vector form to feed to a fully connected network (FCN).\r\n","# model_cnn.add(layers.Flatten())\r\n","\r\n","# We will design for 64 outputs with activation function as relu (to learn non-linearity).\r\n","# model_cnn.add(layers.Dense(64, activation = 'relu'))\r\n","\r\n","# This is the final layer. Hence, the outputs will be 2 corresponding to the 2 classes:\r\n","# - clinical heart failure = yes: 1\r\n","# - clinical heart failure = no: 0\r\n","# Activation Function chosen here is softmax to have a probabilistic output. \r\n","# model_cnn.add(layers.Dense(2, activation = 'softmax'))\r\n","\r\n","# model_cnn.summary()\r\n","\r\n","# Define Optimizer, Loss Function and Metrics to be used for the Model\r\n","# - Going ahead with the well known functions at this point in time\r\n","# - Selected accuracy as the metrics to understand validation / test accuracy of the model\r\n","# model_cnn.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\r\n","\r\n","# Train and Validate the Model\r\n","# We will now train the model using train images and train labels. \r\n","# - We will use a batch size = 10.\r\n","# - 1 epoch = 770 / 10 = 77 batches\r\n","# - 1 epoch = 1 complete run of all train samples for training the model\r\n","# - We will go for a total of 5 epochs = 5 complete run of the all train samples\r\n","# We will validate the model using validation images and validation labels.\r\n","# model_cnn.fit(train_images, train_labels, epochs = 1, batch_size = 10, validation_data = (validation_images, validation_labels))\r\n","\r\n","# Test the Model\r\n","# We will now test model's performance with the test data.\r\n","# - We predict the class for each of the 1155 test using the model.\r\n","# - We will check the test accuracy.\r\n","# test_loss, test_acc = model_cnn.evaluate(test_images, test_labels)\r\n","# print('test accuracy:', (test_acc*100))\r\n"],"execution_count":69,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mVZqztGYtAA1"},"source":["### Define Common Hyperparameters"]},{"cell_type":"code","metadata":{"id":"SMuD8SLxtKW_","executionInfo":{"status":"ok","timestamp":1611776366588,"user_tz":-330,"elapsed":1048302,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["BATCH_SIZE = 10\r\n","EPOCHS = 100\r\n","LEARNING_RATE = 0.01\r\n","DENSE_LAYER_NEURONS = 512\r\n","DENSE_LAYER_DROPOUT = 0.4\r\n","CROSS_VALIDATE = True\r\n","CROSS_VALIDATION_FOLDS = 4"],"execution_count":70,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LU3ToUb9j4A"},"source":["### Define a checkpoint function"]},{"cell_type":"code","metadata":{"id":"t1GuG7z79iou","executionInfo":{"status":"ok","timestamp":1611776366589,"user_tz":-330,"elapsed":1048300,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["from keras.callbacks import ModelCheckpoint\r\n","def checkpoint(path_to_model_parameters_file):\r\n","  # 1st argument: file to which the weights need to be saved\r\n","  # 2nd argument: defines the quantity to monitor ... we will monitor validation accuracy\r\n","  # 3rd argument: verbose yes/no\r\n","  # 4th argument: true then save weghts else save entire model\r\n","  # 5th argument: max if val_acc, min if val_loss, auto decides based on the quantity getting monitored\r\n","  # 6th argument: period:  check after every epoch therefore 1\r\n","  # 6th arguemnt: save_freq:  specify the frequency in number of batches seen\r\n","  #checkpoint = ModelCheckpoint(\"/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_freq = 'epoch') #period=1\r\n","  checkpoint_value = ModelCheckpoint(path_to_model_parameters_file, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_freq = 'epoch') #period=1\r\n","  return checkpoint_value"],"execution_count":71,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0_Wbu528IW4x"},"source":["### Libraries for FLOPS"]},{"cell_type":"code","metadata":{"id":"jYV7nnkQIik7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776369940,"user_tz":-330,"elapsed":1051649,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"1babd6ae-301b-45fd-b901-7cb750dbec1b"},"source":["pip install keras-flops"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Collecting keras-flops\n","  Downloading https://files.pythonhosted.org/packages/bc/77/e384f6e427e1920624a9229b411010eaa244134cff6a230d303d3b1ea0be/keras_flops-0.1.2-py3-none-any.whl\n","Requirement already satisfied: tensorflow<3.0,>=2.2 in /usr/local/lib/python3.6/dist-packages (from keras-flops) (2.4.1)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.3.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.6.3)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.36.2)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.1.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.12.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.12.4)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.10.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.15.0)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.32.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.3.3)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.1.2)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.4.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.19.5)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.7.4.3)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.4.1)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.12)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.2.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<3.0,>=2.2->keras-flops) (51.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.17.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (0.4.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.3.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.8.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (2.23.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (4.7)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (4.2.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.24.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.4.0)\n","Installing collected packages: keras-flops\n","Successfully installed keras-flops-0.1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vasKqBI9IcZl","executionInfo":{"status":"ok","timestamp":1611776369942,"user_tz":-330,"elapsed":1051648,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["from keras_flops import get_flops"],"execution_count":73,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SVYSHHC7Ed3E"},"source":["### ResNet50 - Transfer Learning"]},{"cell_type":"code","metadata":{"id":"TeMu7VER-G67","executionInfo":{"status":"ok","timestamp":1611776369944,"user_tz":-330,"elapsed":1051648,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# import libraries (resnet50)\r\n","from keras.applications.resnet50 import ResNet50\r\n","from keras.layers import Dense, GlobalAveragePooling2D\r\n","from keras.models import Model\r\n","from keras.optimizers import SGD\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.optimizers import Adam\r\n","# from keras.layers import Dropout\r\n","from keras.layers.normalization import BatchNormalization\r\n","from keras.layers.core import Dense, Dropout, Activation\r\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"qYABR-6C-Px4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776377815,"user_tz":-330,"elapsed":1059516,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"4820f62d-db95-411f-fcf2-8b3246763ef1"},"source":["# load ResNet50 with pre-trained parameters for 'imagenet' challenge\r\n","# disable the last layer ... so that we can have our own FCN layer for our desired classes\r\n","resnet50 = ResNet50(include_top=False, weights='imagenet')\r\n","\r\n","# define the last layers\r\n","# get the output of the last layer of the ResNet50\r\n","prediction = resnet50.output\r\n","# add a Global Average Pooling layer (GAP) - this helps reduce number of parameters as compared to a flatten/dense layer\r\n","prediction = GlobalAveragePooling2D()(prediction)\r\n","# add a FCN with 1024 output neurons\r\n","#prediction = Dense(1024, activation = 'relu')(prediction)\r\n","# we will split the actions to have the Batch Normalization done befor relu\r\n","prediction = Dense(DENSE_LAYER_NEURONS)(prediction)\r\n","#prediction = BatchNormalization()(prediction)\r\n","prediction = Activation('relu')(prediction)\r\n","# add a dropout of 40% to avoid overfitting\r\n","prediction = Dropout(DENSE_LAYER_DROPOUT)(prediction)\r\n","# add a FCN with 2 output neurons corresponding to the 2 classes we want to predict\r\n","prediction = Dense(2, activation = 'softmax')(prediction)\r\n","\r\n","# connect the last layer with ResNet50 layer to define the model\r\n","model = Model(inputs = resnet50.input, outputs = prediction)\r\n","\r\n","# we wish use the pretrained resnet50 model as is i.e. do not want it's parameters to get updated during training\r\n","for layer in resnet50.layers:\r\n","  layer.trainable = False\r\n","\r\n","# define the optimizer, loss function, metrics we will use\r\n","#model.compile(optimizer = SGD(lr=0.0001, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n","model.compile(optimizer = Adam(lr=LEARNING_RATE), loss = 'categorical_crossentropy', metrics = ['accuracy'])"],"execution_count":75,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nUDFCMRsij86","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776377816,"user_tz":-330,"elapsed":1059515,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"abe7c59d-bb34-4c0e-b642-05cc16c40bf2"},"source":["model.summary()"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None, None,  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 512)          0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 512)          0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 2)            1026        dropout[0][0]                    \n","==================================================================================================\n","Total params: 24,637,826\n","Trainable params: 1,050,114\n","Non-trainable params: 23,587,712\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uy-8-MBIjmpI","executionInfo":{"status":"ok","timestamp":1611776377818,"user_tz":-330,"elapsed":1059515,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# len(resnet50.layers)\r\n","# resnet50.layers\r\n","# resnet50.summary()"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"eUohnO6qJNfc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776380807,"user_tz":-330,"elapsed":1062501,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"5e303aae-8efb-43f1-ee46-fa82c95f3fdb"},"source":["# calculate FLOPS for the model\r\n","flops_resnet50_xfr = get_flops(model, batch_size = 1)\r\n","print(f\"ResNet50 Transfer FLOPS: {flops_resnet50_xfr / 10 ** 9:.03} G\")"],"execution_count":78,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py:4893: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","ResNet50 Transfer FLOPS: 0.0021 G\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zRvHh5zEZ3Yc","executionInfo":{"status":"ok","timestamp":1611776380808,"user_tz":-330,"elapsed":1062500,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# data augmentation helps change the data slightly so that the model does not overfit\r\n","# train_generator = ImageDataGenerator(rotation_range = 8, width_shift_range = 0.08, shear_range = 0.3, height_shift_range = 0.08, zoom_range = 0.08)\r\n","# validation_generator = ImageDataGenerator()\r\n","# below ensures the augmented data is provided in batches to the model\r\n","# train_augmented = train_generator.flow(train_images, train_labels, batch_size = 10)\r\n","# validation_augmented = validation_generator.flow(validation_images, validation_labels, batch_size = 10)"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"324Kefh_-8nQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776827673,"user_tz":-330,"elapsed":1509362,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"956c6a82-f5f6-4f52-943d-c1fd98cac38b"},"source":["# train and validate model\r\n","path_to_resnet50_xfr_parameters_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5'\r\n","start_time = time.time()\r\n","model.fit(train_images, train_labels, epochs = EPOCHS, batch_size = BATCH_SIZE, validation_data = (validation_images, validation_labels), callbacks=[checkpoint(path_to_resnet50_xfr_parameters_file)])\r\n","duration = time.time() - start_time\r\n","print(f'ResNet50 XFR Train Time = {duration}s')\r\n","\r\n","# train and validate model with augmented data\r\n","# model.fit(train_augmented, epochs = 20, batch_size = 10, validation_data = validation_augmented)"],"execution_count":80,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","77/77 [==============================] - 15s 70ms/step - loss: 5.6791 - accuracy: 0.6179 - val_loss: 0.4129 - val_accuracy: 0.8102\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.81016, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5\n","Epoch 2/100\n","77/77 [==============================] - 4s 53ms/step - loss: 0.4017 - accuracy: 0.8384 - val_loss: 0.4585 - val_accuracy: 0.7914\n","\n","Epoch 00002: val_accuracy did not improve from 0.81016\n","Epoch 3/100\n","77/77 [==============================] - 4s 51ms/step - loss: 0.3396 - accuracy: 0.8584 - val_loss: 0.4221 - val_accuracy: 0.8342\n","\n","Epoch 00003: val_accuracy improved from 0.81016 to 0.83422, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5\n","Epoch 4/100\n","77/77 [==============================] - 4s 52ms/step - loss: 0.4250 - accuracy: 0.8231 - val_loss: 0.3761 - val_accuracy: 0.8342\n","\n","Epoch 00004: val_accuracy did not improve from 0.83422\n","Epoch 5/100\n","77/77 [==============================] - 4s 52ms/step - loss: 0.3732 - accuracy: 0.8359 - val_loss: 0.3771 - val_accuracy: 0.8235\n","\n","Epoch 00005: val_accuracy did not improve from 0.83422\n","Epoch 6/100\n","77/77 [==============================] - 4s 52ms/step - loss: 0.3638 - accuracy: 0.8283 - val_loss: 0.3563 - val_accuracy: 0.8583\n","\n","Epoch 00006: val_accuracy improved from 0.83422 to 0.85829, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5\n","Epoch 7/100\n","77/77 [==============================] - 4s 52ms/step - loss: 0.2954 - accuracy: 0.8774 - val_loss: 0.4904 - val_accuracy: 0.7861\n","\n","Epoch 00007: val_accuracy did not improve from 0.85829\n","Epoch 8/100\n","77/77 [==============================] - 4s 52ms/step - loss: 0.3394 - accuracy: 0.8627 - val_loss: 0.3561 - val_accuracy: 0.8396\n","\n","Epoch 00008: val_accuracy did not improve from 0.85829\n","Epoch 9/100\n","77/77 [==============================] - 4s 52ms/step - loss: 0.2332 - accuracy: 0.9104 - val_loss: 0.4064 - val_accuracy: 0.8422\n","\n","Epoch 00009: val_accuracy did not improve from 0.85829\n","Epoch 10/100\n","77/77 [==============================] - 4s 52ms/step - loss: 0.2799 - accuracy: 0.8806 - val_loss: 0.3578 - val_accuracy: 0.8476\n","\n","Epoch 00010: val_accuracy did not improve from 0.85829\n","Epoch 11/100\n","77/77 [==============================] - 4s 53ms/step - loss: 0.3361 - accuracy: 0.8193 - val_loss: 0.4117 - val_accuracy: 0.8128\n","\n","Epoch 00011: val_accuracy did not improve from 0.85829\n","Epoch 12/100\n","77/77 [==============================] - 4s 53ms/step - loss: 0.2758 - accuracy: 0.8688 - val_loss: 0.5896 - val_accuracy: 0.7861\n","\n","Epoch 00012: val_accuracy did not improve from 0.85829\n","Epoch 13/100\n","77/77 [==============================] - 4s 54ms/step - loss: 0.2974 - accuracy: 0.8612 - val_loss: 0.4609 - val_accuracy: 0.8262\n","\n","Epoch 00013: val_accuracy did not improve from 0.85829\n","Epoch 14/100\n","77/77 [==============================] - 4s 53ms/step - loss: 0.2705 - accuracy: 0.8770 - val_loss: 0.4180 - val_accuracy: 0.8636\n","\n","Epoch 00014: val_accuracy improved from 0.85829 to 0.86364, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5\n","Epoch 15/100\n","77/77 [==============================] - 4s 54ms/step - loss: 0.2726 - accuracy: 0.8684 - val_loss: 0.4139 - val_accuracy: 0.8610\n","\n","Epoch 00015: val_accuracy did not improve from 0.86364\n","Epoch 16/100\n","77/77 [==============================] - 4s 54ms/step - loss: 0.2619 - accuracy: 0.8806 - val_loss: 0.4249 - val_accuracy: 0.8422\n","\n","Epoch 00016: val_accuracy did not improve from 0.86364\n","Epoch 17/100\n","77/77 [==============================] - 4s 54ms/step - loss: 0.2474 - accuracy: 0.8752 - val_loss: 0.4697 - val_accuracy: 0.8342\n","\n","Epoch 00017: val_accuracy did not improve from 0.86364\n","Epoch 18/100\n","77/77 [==============================] - 4s 54ms/step - loss: 0.2475 - accuracy: 0.8819 - val_loss: 0.5729 - val_accuracy: 0.8556\n","\n","Epoch 00018: val_accuracy did not improve from 0.86364\n","Epoch 19/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2694 - accuracy: 0.8745 - val_loss: 0.4107 - val_accuracy: 0.8556\n","\n","Epoch 00019: val_accuracy did not improve from 0.86364\n","Epoch 20/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2362 - accuracy: 0.8983 - val_loss: 0.4213 - val_accuracy: 0.8610\n","\n","Epoch 00020: val_accuracy did not improve from 0.86364\n","Epoch 21/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1709 - accuracy: 0.9190 - val_loss: 0.5704 - val_accuracy: 0.8476\n","\n","Epoch 00021: val_accuracy did not improve from 0.86364\n","Epoch 22/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1817 - accuracy: 0.9309 - val_loss: 0.5145 - val_accuracy: 0.8556\n","\n","Epoch 00022: val_accuracy did not improve from 0.86364\n","Epoch 23/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1768 - accuracy: 0.9215 - val_loss: 0.4442 - val_accuracy: 0.8556\n","\n","Epoch 00023: val_accuracy did not improve from 0.86364\n","Epoch 24/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2210 - accuracy: 0.8893 - val_loss: 0.5772 - val_accuracy: 0.8610\n","\n","Epoch 00024: val_accuracy did not improve from 0.86364\n","Epoch 25/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.2150 - accuracy: 0.9015 - val_loss: 0.5659 - val_accuracy: 0.8636\n","\n","Epoch 00025: val_accuracy did not improve from 0.86364\n","Epoch 26/100\n","77/77 [==============================] - 4s 57ms/step - loss: 0.1590 - accuracy: 0.9414 - val_loss: 0.6290 - val_accuracy: 0.8529\n","\n","Epoch 00026: val_accuracy did not improve from 0.86364\n","Epoch 27/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.2539 - accuracy: 0.8957 - val_loss: 0.3473 - val_accuracy: 0.8877\n","\n","Epoch 00027: val_accuracy improved from 0.86364 to 0.88770, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5\n","Epoch 28/100\n","77/77 [==============================] - 4s 57ms/step - loss: 0.1976 - accuracy: 0.9267 - val_loss: 0.5383 - val_accuracy: 0.8556\n","\n","Epoch 00028: val_accuracy did not improve from 0.88770\n","Epoch 29/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.2028 - accuracy: 0.8857 - val_loss: 0.4569 - val_accuracy: 0.8877\n","\n","Epoch 00029: val_accuracy did not improve from 0.88770\n","Epoch 30/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.2068 - accuracy: 0.8680 - val_loss: 0.4307 - val_accuracy: 0.8583\n","\n","Epoch 00030: val_accuracy did not improve from 0.88770\n","Epoch 31/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1780 - accuracy: 0.8978 - val_loss: 0.6166 - val_accuracy: 0.8128\n","\n","Epoch 00031: val_accuracy did not improve from 0.88770\n","Epoch 32/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1753 - accuracy: 0.9212 - val_loss: 0.5801 - val_accuracy: 0.8663\n","\n","Epoch 00032: val_accuracy did not improve from 0.88770\n","Epoch 33/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1448 - accuracy: 0.9347 - val_loss: 0.4758 - val_accuracy: 0.8957\n","\n","Epoch 00033: val_accuracy improved from 0.88770 to 0.89572, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5\n","Epoch 34/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1988 - accuracy: 0.8915 - val_loss: 0.5351 - val_accuracy: 0.8369\n","\n","Epoch 00034: val_accuracy did not improve from 0.89572\n","Epoch 35/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1752 - accuracy: 0.9262 - val_loss: 0.5079 - val_accuracy: 0.8663\n","\n","Epoch 00035: val_accuracy did not improve from 0.89572\n","Epoch 36/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1520 - accuracy: 0.9351 - val_loss: 0.7472 - val_accuracy: 0.8583\n","\n","Epoch 00036: val_accuracy did not improve from 0.89572\n","Epoch 37/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2509 - accuracy: 0.8744 - val_loss: 0.5210 - val_accuracy: 0.8396\n","\n","Epoch 00037: val_accuracy did not improve from 0.89572\n","Epoch 38/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2443 - accuracy: 0.8710 - val_loss: 0.4615 - val_accuracy: 0.8583\n","\n","Epoch 00038: val_accuracy did not improve from 0.89572\n","Epoch 39/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2510 - accuracy: 0.8490 - val_loss: 0.5922 - val_accuracy: 0.8610\n","\n","Epoch 00039: val_accuracy did not improve from 0.89572\n","Epoch 40/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1754 - accuracy: 0.9203 - val_loss: 0.6591 - val_accuracy: 0.8610\n","\n","Epoch 00040: val_accuracy did not improve from 0.89572\n","Epoch 41/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.2050 - accuracy: 0.8884 - val_loss: 0.4231 - val_accuracy: 0.8556\n","\n","Epoch 00041: val_accuracy did not improve from 0.89572\n","Epoch 42/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.2402 - accuracy: 0.8780 - val_loss: 0.4102 - val_accuracy: 0.8503\n","\n","Epoch 00042: val_accuracy did not improve from 0.89572\n","Epoch 43/100\n","77/77 [==============================] - 4s 57ms/step - loss: 0.1919 - accuracy: 0.8940 - val_loss: 0.4491 - val_accuracy: 0.8503\n","\n","Epoch 00043: val_accuracy did not improve from 0.89572\n","Epoch 44/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1663 - accuracy: 0.9076 - val_loss: 0.5355 - val_accuracy: 0.8636\n","\n","Epoch 00044: val_accuracy did not improve from 0.89572\n","Epoch 45/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1797 - accuracy: 0.8862 - val_loss: 0.5417 - val_accuracy: 0.8663\n","\n","Epoch 00045: val_accuracy did not improve from 0.89572\n","Epoch 46/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2251 - accuracy: 0.9163 - val_loss: 0.4096 - val_accuracy: 0.8556\n","\n","Epoch 00046: val_accuracy did not improve from 0.89572\n","Epoch 47/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2153 - accuracy: 0.8678 - val_loss: 0.5421 - val_accuracy: 0.8422\n","\n","Epoch 00047: val_accuracy did not improve from 0.89572\n","Epoch 48/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1844 - accuracy: 0.8979 - val_loss: 0.5768 - val_accuracy: 0.8904\n","\n","Epoch 00048: val_accuracy did not improve from 0.89572\n","Epoch 49/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1622 - accuracy: 0.9227 - val_loss: 0.4686 - val_accuracy: 0.8850\n","\n","Epoch 00049: val_accuracy did not improve from 0.89572\n","Epoch 50/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1402 - accuracy: 0.9203 - val_loss: 0.7248 - val_accuracy: 0.8717\n","\n","Epoch 00050: val_accuracy did not improve from 0.89572\n","Epoch 51/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1490 - accuracy: 0.8879 - val_loss: 0.8010 - val_accuracy: 0.8743\n","\n","Epoch 00051: val_accuracy did not improve from 0.89572\n","Epoch 52/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1614 - accuracy: 0.9042 - val_loss: 0.6436 - val_accuracy: 0.8583\n","\n","Epoch 00052: val_accuracy did not improve from 0.89572\n","Epoch 53/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1456 - accuracy: 0.9201 - val_loss: 0.3463 - val_accuracy: 0.8904\n","\n","Epoch 00053: val_accuracy did not improve from 0.89572\n","Epoch 54/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2036 - accuracy: 0.8985 - val_loss: 0.6106 - val_accuracy: 0.8529\n","\n","Epoch 00054: val_accuracy did not improve from 0.89572\n","Epoch 55/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1719 - accuracy: 0.9427 - val_loss: 0.9487 - val_accuracy: 0.8610\n","\n","Epoch 00055: val_accuracy did not improve from 0.89572\n","Epoch 56/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1691 - accuracy: 0.9091 - val_loss: 0.7231 - val_accuracy: 0.8610\n","\n","Epoch 00056: val_accuracy did not improve from 0.89572\n","Epoch 57/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1418 - accuracy: 0.9451 - val_loss: 0.8508 - val_accuracy: 0.8743\n","\n","Epoch 00057: val_accuracy did not improve from 0.89572\n","Epoch 58/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1563 - accuracy: 0.9112 - val_loss: 0.8951 - val_accuracy: 0.8743\n","\n","Epoch 00058: val_accuracy did not improve from 0.89572\n","Epoch 59/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1077 - accuracy: 0.9445 - val_loss: 0.7581 - val_accuracy: 0.8877\n","\n","Epoch 00059: val_accuracy did not improve from 0.89572\n","Epoch 60/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1232 - accuracy: 0.9487 - val_loss: 0.7386 - val_accuracy: 0.8904\n","\n","Epoch 00060: val_accuracy did not improve from 0.89572\n","Epoch 61/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1528 - accuracy: 0.9004 - val_loss: 0.5514 - val_accuracy: 0.8770\n","\n","Epoch 00061: val_accuracy did not improve from 0.89572\n","Epoch 62/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1687 - accuracy: 0.9131 - val_loss: 0.8369 - val_accuracy: 0.8690\n","\n","Epoch 00062: val_accuracy did not improve from 0.89572\n","Epoch 63/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1289 - accuracy: 0.9206 - val_loss: 0.6248 - val_accuracy: 0.8850\n","\n","Epoch 00063: val_accuracy did not improve from 0.89572\n","Epoch 64/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1280 - accuracy: 0.9272 - val_loss: 1.0469 - val_accuracy: 0.8717\n","\n","Epoch 00064: val_accuracy did not improve from 0.89572\n","Epoch 65/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1381 - accuracy: 0.9363 - val_loss: 0.6358 - val_accuracy: 0.8770\n","\n","Epoch 00065: val_accuracy did not improve from 0.89572\n","Epoch 66/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1166 - accuracy: 0.9439 - val_loss: 0.9295 - val_accuracy: 0.8529\n","\n","Epoch 00066: val_accuracy did not improve from 0.89572\n","Epoch 67/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1386 - accuracy: 0.9311 - val_loss: 0.6928 - val_accuracy: 0.8663\n","\n","Epoch 00067: val_accuracy did not improve from 0.89572\n","Epoch 68/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1507 - accuracy: 0.9318 - val_loss: 0.7157 - val_accuracy: 0.8690\n","\n","Epoch 00068: val_accuracy did not improve from 0.89572\n","Epoch 69/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1543 - accuracy: 0.9094 - val_loss: 0.4166 - val_accuracy: 0.8556\n","\n","Epoch 00069: val_accuracy did not improve from 0.89572\n","Epoch 70/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2241 - accuracy: 0.8474 - val_loss: 0.7087 - val_accuracy: 0.8636\n","\n","Epoch 00070: val_accuracy did not improve from 0.89572\n","Epoch 71/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1892 - accuracy: 0.9038 - val_loss: 0.6373 - val_accuracy: 0.8021\n","\n","Epoch 00071: val_accuracy did not improve from 0.89572\n","Epoch 72/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1771 - accuracy: 0.8931 - val_loss: 0.8294 - val_accuracy: 0.8529\n","\n","Epoch 00072: val_accuracy did not improve from 0.89572\n","Epoch 73/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1737 - accuracy: 0.8912 - val_loss: 0.6612 - val_accuracy: 0.8717\n","\n","Epoch 00073: val_accuracy did not improve from 0.89572\n","Epoch 74/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1513 - accuracy: 0.9189 - val_loss: 1.0011 - val_accuracy: 0.8396\n","\n","Epoch 00074: val_accuracy did not improve from 0.89572\n","Epoch 75/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1633 - accuracy: 0.9185 - val_loss: 0.7737 - val_accuracy: 0.8717\n","\n","Epoch 00075: val_accuracy did not improve from 0.89572\n","Epoch 76/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1537 - accuracy: 0.9194 - val_loss: 0.8219 - val_accuracy: 0.8583\n","\n","Epoch 00076: val_accuracy did not improve from 0.89572\n","Epoch 77/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1770 - accuracy: 0.9041 - val_loss: 0.9961 - val_accuracy: 0.8583\n","\n","Epoch 00077: val_accuracy did not improve from 0.89572\n","Epoch 78/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2183 - accuracy: 0.8621 - val_loss: 0.7004 - val_accuracy: 0.8743\n","\n","Epoch 00078: val_accuracy did not improve from 0.89572\n","Epoch 79/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.2399 - accuracy: 0.8587 - val_loss: 0.6757 - val_accuracy: 0.8476\n","\n","Epoch 00079: val_accuracy did not improve from 0.89572\n","Epoch 80/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1643 - accuracy: 0.8950 - val_loss: 0.7221 - val_accuracy: 0.8770\n","\n","Epoch 00080: val_accuracy did not improve from 0.89572\n","Epoch 81/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1612 - accuracy: 0.8947 - val_loss: 0.8728 - val_accuracy: 0.8877\n","\n","Epoch 00081: val_accuracy did not improve from 0.89572\n","Epoch 82/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1109 - accuracy: 0.9293 - val_loss: 1.4468 - val_accuracy: 0.8636\n","\n","Epoch 00082: val_accuracy did not improve from 0.89572\n","Epoch 83/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1109 - accuracy: 0.9473 - val_loss: 0.8180 - val_accuracy: 0.8850\n","\n","Epoch 00083: val_accuracy did not improve from 0.89572\n","Epoch 84/100\n","77/77 [==============================] - 4s 57ms/step - loss: 0.1254 - accuracy: 0.9362 - val_loss: 1.0319 - val_accuracy: 0.8850\n","\n","Epoch 00084: val_accuracy did not improve from 0.89572\n","Epoch 85/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1421 - accuracy: 0.9362 - val_loss: 0.6098 - val_accuracy: 0.8824\n","\n","Epoch 00085: val_accuracy did not improve from 0.89572\n","Epoch 86/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1497 - accuracy: 0.9217 - val_loss: 0.9196 - val_accuracy: 0.9037\n","\n","Epoch 00086: val_accuracy improved from 0.89572 to 0.90374, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5\n","Epoch 87/100\n","77/77 [==============================] - 4s 57ms/step - loss: 0.0990 - accuracy: 0.9487 - val_loss: 0.9785 - val_accuracy: 0.8717\n","\n","Epoch 00087: val_accuracy did not improve from 0.90374\n","Epoch 88/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1425 - accuracy: 0.9250 - val_loss: 0.9645 - val_accuracy: 0.8717\n","\n","Epoch 00088: val_accuracy did not improve from 0.90374\n","Epoch 89/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1097 - accuracy: 0.9322 - val_loss: 0.9494 - val_accuracy: 0.8797\n","\n","Epoch 00089: val_accuracy did not improve from 0.90374\n","Epoch 90/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.0996 - accuracy: 0.9371 - val_loss: 1.4682 - val_accuracy: 0.8155\n","\n","Epoch 00090: val_accuracy did not improve from 0.90374\n","Epoch 91/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1907 - accuracy: 0.9105 - val_loss: 0.9522 - val_accuracy: 0.8690\n","\n","Epoch 00091: val_accuracy did not improve from 0.90374\n","Epoch 92/100\n","77/77 [==============================] - 4s 57ms/step - loss: 0.1329 - accuracy: 0.9075 - val_loss: 0.8875 - val_accuracy: 0.8556\n","\n","Epoch 00092: val_accuracy did not improve from 0.90374\n","Epoch 93/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1080 - accuracy: 0.9556 - val_loss: 0.6614 - val_accuracy: 0.8850\n","\n","Epoch 00093: val_accuracy did not improve from 0.90374\n","Epoch 94/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1820 - accuracy: 0.9252 - val_loss: 0.8328 - val_accuracy: 0.8797\n","\n","Epoch 00094: val_accuracy did not improve from 0.90374\n","Epoch 95/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1119 - accuracy: 0.9420 - val_loss: 1.2098 - val_accuracy: 0.8449\n","\n","Epoch 00095: val_accuracy did not improve from 0.90374\n","Epoch 96/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1431 - accuracy: 0.9447 - val_loss: 0.9684 - val_accuracy: 0.8476\n","\n","Epoch 00096: val_accuracy did not improve from 0.90374\n","Epoch 97/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1589 - accuracy: 0.9364 - val_loss: 1.2167 - val_accuracy: 0.8503\n","\n","Epoch 00097: val_accuracy did not improve from 0.90374\n","Epoch 98/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.1162 - accuracy: 0.9529 - val_loss: 0.9168 - val_accuracy: 0.8636\n","\n","Epoch 00098: val_accuracy did not improve from 0.90374\n","Epoch 99/100\n","77/77 [==============================] - 4s 55ms/step - loss: 0.2488 - accuracy: 0.8414 - val_loss: 1.2554 - val_accuracy: 0.8556\n","\n","Epoch 00099: val_accuracy did not improve from 0.90374\n","Epoch 100/100\n","77/77 [==============================] - 4s 56ms/step - loss: 0.1520 - accuracy: 0.9288 - val_loss: 1.2076 - val_accuracy: 0.8503\n","\n","Epoch 00100: val_accuracy did not improve from 0.90374\n","ResNet50 XFR Train Time = 446.35871052742004s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JZKQyoCBDlw-","executionInfo":{"status":"ok","timestamp":1611776827676,"user_tz":-330,"elapsed":1509363,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# test model\r\n","#test_loss, test_acc = model.evaluate(test_images, test_labels)"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"-F_cgENQ-0nv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611776843121,"user_tz":-330,"elapsed":1524800,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"1c20cde5-84d7-4cf0-aba2-befee99a47db"},"source":["# test with best model\r\n","model.load_weights(path_to_resnet50_xfr_parameters_file)\r\n","start_time = time.time()\r\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\r\n","duration = time.time() - start_time\r\n","print(f'ResNet50 XFR Test Time = {duration}s')\r\n","print(f'ResNet50 XFR Test Time / sample = {duration/1155}s')"],"execution_count":82,"outputs":[{"output_type":"stream","text":["37/37 [==============================] - 4s 101ms/step - loss: 1.2070 - accuracy: 0.8260\n","ResNet50 XFR Test Time = 4.191006660461426s\n","ResNet50 XFR Test Time / sample = 0.0036285771952046975s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hbuwrd24nTwa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611779487533,"user_tz":-330,"elapsed":4169206,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"80b31c23-5ba9-4fa3-a8da-29b1c9885fad"},"source":["# perform cross validation\r\n","start_time = time.time()\r\n","if (CROSS_VALIDATE == True):\r\n","  # import libraries\r\n","  from sklearn.model_selection import StratifiedKFold\r\n","  # using stratifiedkfold so that we have balanced classes in each split\r\n","  cvfold = StratifiedKFold(n_splits = CROSS_VALIDATION_FOLDS, shuffle = True)\r\n","  # we will use below to store all individual validation scores\r\n","  cvscores = []\r\n","  # based on the class value, get the split done and respective train and test index\r\n","  for train_index, val_index in cvfold.split(all_images, all_labels_before_categorical):\r\n","    # model definition as is from top - starts\r\n","    resnet50 = ResNet50(include_top=False, weights='imagenet')\r\n","    prediction = resnet50.output\r\n","    prediction = GlobalAveragePooling2D()(prediction)\r\n","    prediction = Dense(DENSE_LAYER_NEURONS)(prediction)\r\n","    prediction = Activation('relu')(prediction)\r\n","    prediction = Dropout(DENSE_LAYER_DROPOUT)(prediction)\r\n","    prediction = Dense(2, activation = 'softmax')(prediction)\r\n","    model = Model(inputs = resnet50.input, outputs = prediction)\r\n","    for layer in resnet50.layers:\r\n","      layer.trainable = False\r\n","    model.compile(optimizer = Adam(lr=LEARNING_RATE), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n","    # model definition as is from top - ends\r\n","    # train based on train index elements\r\n","    model.fit(all_images[train_index], all_labels[train_index], epochs = EPOCHS, batch_size = BATCH_SIZE) \r\n","    # validate based on validation index elements\r\n","    cv_score = model.evaluate(all_images[val_index], all_labels[val_index])\r\n","    print(\"Validation Accuracy: %0.2f%%\" % (cv_score[1]*100))\r\n","    # append each iteration validation accuracy score\r\n","    cvscores.append(cv_score[1]*100)\r\n","  # print mean and std deviation of the validation accuracy for the complete cross validation i.e. for all iterations\r\n","  print(\"Validation Accuracy Mean (+/- Std Deviation): %0.2f%% (+/- %0.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\r\n","duration = time.time() - start_time\r\n","print(f'ResNet50 XFR Cross Validation Time = {duration}s')"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","173/173 [==============================] - 9s 37ms/step - loss: 3.8654 - accuracy: 0.6557\n","Epoch 2/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.4514 - accuracy: 0.7936\n","Epoch 3/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4491 - accuracy: 0.7706\n","Epoch 4/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4322 - accuracy: 0.8128\n","Epoch 5/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4152 - accuracy: 0.8005\n","Epoch 6/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4150 - accuracy: 0.8073\n","Epoch 7/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3628 - accuracy: 0.8285\n","Epoch 8/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3777 - accuracy: 0.8388\n","Epoch 9/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.4083 - accuracy: 0.7943\n","Epoch 10/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3853 - accuracy: 0.8032\n","Epoch 11/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3943 - accuracy: 0.7933\n","Epoch 12/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3252 - accuracy: 0.8578\n","Epoch 13/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3818 - accuracy: 0.7727\n","Epoch 14/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3951 - accuracy: 0.7933\n","Epoch 15/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3857 - accuracy: 0.8121\n","Epoch 16/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3394 - accuracy: 0.8057\n","Epoch 17/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3340 - accuracy: 0.8176\n","Epoch 18/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3270 - accuracy: 0.8566\n","Epoch 19/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3262 - accuracy: 0.8474\n","Epoch 20/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3077 - accuracy: 0.8626\n","Epoch 21/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2481 - accuracy: 0.8637\n","Epoch 22/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2722 - accuracy: 0.8641\n","Epoch 23/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3530 - accuracy: 0.7992\n","Epoch 24/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3123 - accuracy: 0.7941\n","Epoch 25/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3139 - accuracy: 0.8154\n","Epoch 26/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3202 - accuracy: 0.8195\n","Epoch 27/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3203 - accuracy: 0.8334\n","Epoch 28/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3595 - accuracy: 0.8117\n","Epoch 29/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2469 - accuracy: 0.8598\n","Epoch 30/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3059 - accuracy: 0.8177\n","Epoch 31/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3255 - accuracy: 0.8539\n","Epoch 32/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3042 - accuracy: 0.8368\n","Epoch 33/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2377 - accuracy: 0.8843\n","Epoch 34/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2952 - accuracy: 0.8352\n","Epoch 35/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2721 - accuracy: 0.8447\n","Epoch 36/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2476 - accuracy: 0.8718\n","Epoch 37/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2312 - accuracy: 0.8693\n","Epoch 38/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2352 - accuracy: 0.8574\n","Epoch 39/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2595 - accuracy: 0.8548\n","Epoch 40/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2443 - accuracy: 0.8505\n","Epoch 41/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2196 - accuracy: 0.8736\n","Epoch 42/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2113 - accuracy: 0.8753\n","Epoch 43/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3091 - accuracy: 0.8679\n","Epoch 44/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2450 - accuracy: 0.8552\n","Epoch 45/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2405 - accuracy: 0.8583\n","Epoch 46/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2274 - accuracy: 0.8490\n","Epoch 47/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2799 - accuracy: 0.8078\n","Epoch 48/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2178 - accuracy: 0.8937\n","Epoch 49/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2499 - accuracy: 0.8498\n","Epoch 50/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3080 - accuracy: 0.8120\n","Epoch 51/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2417 - accuracy: 0.8592\n","Epoch 52/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2152 - accuracy: 0.8672\n","Epoch 53/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2625 - accuracy: 0.8417\n","Epoch 54/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2609 - accuracy: 0.8566\n","Epoch 55/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2146 - accuracy: 0.8666\n","Epoch 56/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2073 - accuracy: 0.8977\n","Epoch 57/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2277 - accuracy: 0.8626\n","Epoch 58/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3007 - accuracy: 0.8442\n","Epoch 59/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3114 - accuracy: 0.8299\n","Epoch 60/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2291 - accuracy: 0.8623\n","Epoch 61/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2322 - accuracy: 0.8537\n","Epoch 62/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2086 - accuracy: 0.8712\n","Epoch 63/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2180 - accuracy: 0.8864\n","Epoch 64/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1962 - accuracy: 0.8753\n","Epoch 65/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2111 - accuracy: 0.8876\n","Epoch 66/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2211 - accuracy: 0.8710\n","Epoch 67/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2639 - accuracy: 0.8552\n","Epoch 68/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2403 - accuracy: 0.8449\n","Epoch 69/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2555 - accuracy: 0.8673\n","Epoch 70/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3218 - accuracy: 0.8168\n","Epoch 71/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2209 - accuracy: 0.8686\n","Epoch 72/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2071 - accuracy: 0.8799\n","Epoch 73/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2066 - accuracy: 0.8748\n","Epoch 74/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2838 - accuracy: 0.8511\n","Epoch 75/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2663 - accuracy: 0.8438\n","Epoch 76/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2240 - accuracy: 0.8681\n","Epoch 77/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2106 - accuracy: 0.8726\n","Epoch 78/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2110 - accuracy: 0.8605\n","Epoch 79/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2031 - accuracy: 0.8585\n","Epoch 80/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1925 - accuracy: 0.8608\n","Epoch 81/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2121 - accuracy: 0.8667\n","Epoch 82/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2763 - accuracy: 0.8320\n","Epoch 83/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2642 - accuracy: 0.8494\n","Epoch 84/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2478 - accuracy: 0.8727\n","Epoch 85/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2620 - accuracy: 0.8849\n","Epoch 86/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2628 - accuracy: 0.8523\n","Epoch 87/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2592 - accuracy: 0.8728\n","Epoch 88/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2423 - accuracy: 0.8743\n","Epoch 89/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1729 - accuracy: 0.9010\n","Epoch 90/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2275 - accuracy: 0.8915\n","Epoch 91/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2034 - accuracy: 0.8883\n","Epoch 92/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2087 - accuracy: 0.8828\n","Epoch 93/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1765 - accuracy: 0.8865\n","Epoch 94/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1937 - accuracy: 0.8853\n","Epoch 95/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2104 - accuracy: 0.8518\n","Epoch 96/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2296 - accuracy: 0.8728\n","Epoch 97/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1658 - accuracy: 0.9060\n","Epoch 98/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2144 - accuracy: 0.8880\n","Epoch 99/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2129 - accuracy: 0.8488\n","Epoch 100/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2084 - accuracy: 0.8694\n","18/18 [==============================] - 3s 122ms/step - loss: 0.6976 - accuracy: 0.8939\n","Validation Accuracy: 89.39%\n","Epoch 1/100\n","173/173 [==============================] - 9s 37ms/step - loss: 4.4331 - accuracy: 0.6560\n","Epoch 2/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.4487 - accuracy: 0.7970\n","Epoch 3/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.4311 - accuracy: 0.8003\n","Epoch 4/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.4488 - accuracy: 0.8042\n","Epoch 5/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3778 - accuracy: 0.8371\n","Epoch 6/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3873 - accuracy: 0.8178\n","Epoch 7/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.4704 - accuracy: 0.7769\n","Epoch 8/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3810 - accuracy: 0.8286\n","Epoch 9/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3944 - accuracy: 0.8066\n","Epoch 10/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3340 - accuracy: 0.8628\n","Epoch 11/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3261 - accuracy: 0.8599\n","Epoch 12/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3715 - accuracy: 0.8356\n","Epoch 13/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3049 - accuracy: 0.8782\n","Epoch 14/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3304 - accuracy: 0.8663\n","Epoch 15/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2796 - accuracy: 0.8878\n","Epoch 16/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2765 - accuracy: 0.8913\n","Epoch 17/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3255 - accuracy: 0.8397\n","Epoch 18/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3482 - accuracy: 0.8652\n","Epoch 19/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3060 - accuracy: 0.8676\n","Epoch 20/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3610 - accuracy: 0.8477\n","Epoch 21/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3043 - accuracy: 0.8697\n","Epoch 22/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2469 - accuracy: 0.9068\n","Epoch 23/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3432 - accuracy: 0.8328\n","Epoch 24/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3114 - accuracy: 0.8696\n","Epoch 25/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3085 - accuracy: 0.8686\n","Epoch 26/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2699 - accuracy: 0.8937\n","Epoch 27/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2458 - accuracy: 0.9042\n","Epoch 28/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2105 - accuracy: 0.9053\n","Epoch 29/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2586 - accuracy: 0.8963\n","Epoch 30/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2147 - accuracy: 0.9113\n","Epoch 31/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2080 - accuracy: 0.9231\n","Epoch 32/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2265 - accuracy: 0.9147\n","Epoch 33/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2497 - accuracy: 0.8970\n","Epoch 34/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1978 - accuracy: 0.9263\n","Epoch 35/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1967 - accuracy: 0.9237\n","Epoch 36/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.3139 - accuracy: 0.8552\n","Epoch 37/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1964 - accuracy: 0.9155\n","Epoch 38/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1934 - accuracy: 0.9269\n","Epoch 39/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2735 - accuracy: 0.8752\n","Epoch 40/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2135 - accuracy: 0.9254\n","Epoch 41/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2032 - accuracy: 0.9164\n","Epoch 42/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1745 - accuracy: 0.9344\n","Epoch 43/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2567 - accuracy: 0.9090\n","Epoch 44/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2316 - accuracy: 0.9019\n","Epoch 45/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2356 - accuracy: 0.9044\n","Epoch 46/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2470 - accuracy: 0.9075\n","Epoch 47/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2701 - accuracy: 0.8954\n","Epoch 48/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1810 - accuracy: 0.9338\n","Epoch 49/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2659 - accuracy: 0.8878\n","Epoch 50/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2280 - accuracy: 0.9035\n","Epoch 51/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2004 - accuracy: 0.9232\n","Epoch 52/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2635 - accuracy: 0.8924\n","Epoch 53/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2737 - accuracy: 0.8811\n","Epoch 54/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1648 - accuracy: 0.9400\n","Epoch 55/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1781 - accuracy: 0.9308\n","Epoch 56/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1770 - accuracy: 0.9306\n","Epoch 57/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1884 - accuracy: 0.9289\n","Epoch 58/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1819 - accuracy: 0.9314\n","Epoch 59/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2228 - accuracy: 0.9405\n","Epoch 60/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2253 - accuracy: 0.9145\n","Epoch 61/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2341 - accuracy: 0.8979\n","Epoch 62/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1792 - accuracy: 0.9380\n","Epoch 63/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1794 - accuracy: 0.9354\n","Epoch 64/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1463 - accuracy: 0.9501\n","Epoch 65/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1497 - accuracy: 0.9483\n","Epoch 66/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2197 - accuracy: 0.9145\n","Epoch 67/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1718 - accuracy: 0.9399\n","Epoch 68/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1483 - accuracy: 0.9476\n","Epoch 69/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1821 - accuracy: 0.9304\n","Epoch 70/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2424 - accuracy: 0.8990\n","Epoch 71/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1592 - accuracy: 0.9520\n","Epoch 72/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1642 - accuracy: 0.9392\n","Epoch 73/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1403 - accuracy: 0.9506\n","Epoch 74/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1707 - accuracy: 0.9398\n","Epoch 75/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1445 - accuracy: 0.9481\n","Epoch 76/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1686 - accuracy: 0.9382\n","Epoch 77/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1659 - accuracy: 0.9437\n","Epoch 78/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1868 - accuracy: 0.9372\n","Epoch 79/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1617 - accuracy: 0.9397\n","Epoch 80/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1804 - accuracy: 0.9327\n","Epoch 81/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1804 - accuracy: 0.9252\n","Epoch 82/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1401 - accuracy: 0.9489\n","Epoch 83/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1748 - accuracy: 0.9390\n","Epoch 84/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1521 - accuracy: 0.9455\n","Epoch 85/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2135 - accuracy: 0.9174\n","Epoch 86/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2272 - accuracy: 0.9060\n","Epoch 87/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1490 - accuracy: 0.9496\n","Epoch 88/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1915 - accuracy: 0.9215\n","Epoch 89/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2029 - accuracy: 0.9324\n","Epoch 90/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1934 - accuracy: 0.9281\n","Epoch 91/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.2161 - accuracy: 0.9129\n","Epoch 92/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1699 - accuracy: 0.9387\n","Epoch 93/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1747 - accuracy: 0.9399\n","Epoch 94/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1585 - accuracy: 0.9493\n","Epoch 95/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.1911 - accuracy: 0.9292\n","Epoch 96/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1585 - accuracy: 0.9425\n","Epoch 97/100\n","173/173 [==============================] - 6s 37ms/step - loss: 0.1551 - accuracy: 0.9451\n","Epoch 98/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1457 - accuracy: 0.9497\n","Epoch 99/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1594 - accuracy: 0.9415\n","Epoch 100/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2233 - accuracy: 0.9130\n","18/18 [==============================] - 3s 102ms/step - loss: 0.5998 - accuracy: 0.8713\n","Validation Accuracy: 87.13%\n","Epoch 1/100\n","173/173 [==============================] - 9s 38ms/step - loss: 3.9699 - accuracy: 0.6596\n","Epoch 2/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.4321 - accuracy: 0.7965\n","Epoch 3/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4532 - accuracy: 0.7715\n","Epoch 4/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4373 - accuracy: 0.7856\n","Epoch 5/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4475 - accuracy: 0.7963\n","Epoch 6/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4549 - accuracy: 0.7751\n","Epoch 7/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4168 - accuracy: 0.7941\n","Epoch 8/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4424 - accuracy: 0.7866\n","Epoch 9/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4198 - accuracy: 0.7758\n","Epoch 10/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3774 - accuracy: 0.7997\n","Epoch 11/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.3367 - accuracy: 0.8337\n","Epoch 12/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3826 - accuracy: 0.8122\n","Epoch 13/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3711 - accuracy: 0.8167\n","Epoch 14/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4043 - accuracy: 0.7974\n","Epoch 15/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3601 - accuracy: 0.7897\n","Epoch 16/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3062 - accuracy: 0.8464\n","Epoch 17/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3381 - accuracy: 0.8089\n","Epoch 18/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3053 - accuracy: 0.8330\n","Epoch 19/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2893 - accuracy: 0.8256\n","Epoch 20/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2984 - accuracy: 0.8203\n","Epoch 21/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2729 - accuracy: 0.8373\n","Epoch 22/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3124 - accuracy: 0.8229\n","Epoch 23/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2300 - accuracy: 0.8694\n","Epoch 24/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2979 - accuracy: 0.8290\n","Epoch 25/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2491 - accuracy: 0.8591\n","Epoch 26/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2504 - accuracy: 0.8365\n","Epoch 27/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2884 - accuracy: 0.8465\n","Epoch 28/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2545 - accuracy: 0.8537\n","Epoch 29/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2281 - accuracy: 0.8693\n","Epoch 30/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2272 - accuracy: 0.8672\n","Epoch 31/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2878 - accuracy: 0.8183\n","Epoch 32/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3085 - accuracy: 0.8219\n","Epoch 33/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3048 - accuracy: 0.8481\n","Epoch 34/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2295 - accuracy: 0.8563\n","Epoch 35/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2668 - accuracy: 0.8456\n","Epoch 36/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2410 - accuracy: 0.8468\n","Epoch 37/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2322 - accuracy: 0.8615\n","Epoch 38/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2542 - accuracy: 0.8678\n","Epoch 39/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2573 - accuracy: 0.8750\n","Epoch 40/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2195 - accuracy: 0.8709\n","Epoch 41/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2462 - accuracy: 0.8376\n","Epoch 42/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2279 - accuracy: 0.8625\n","Epoch 43/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2140 - accuracy: 0.8610\n","Epoch 44/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2093 - accuracy: 0.8699\n","Epoch 45/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2255 - accuracy: 0.8479\n","Epoch 46/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1931 - accuracy: 0.8711\n","Epoch 47/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2272 - accuracy: 0.8636\n","Epoch 48/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2851 - accuracy: 0.8342\n","Epoch 49/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2255 - accuracy: 0.8676\n","Epoch 50/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2131 - accuracy: 0.8739\n","Epoch 51/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2255 - accuracy: 0.8534\n","Epoch 52/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2248 - accuracy: 0.8877\n","Epoch 53/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2279 - accuracy: 0.8842\n","Epoch 54/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2236 - accuracy: 0.8926\n","Epoch 55/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2235 - accuracy: 0.8510\n","Epoch 56/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2004 - accuracy: 0.8924\n","Epoch 57/100\n","173/173 [==============================] - 6s 38ms/step - loss: 0.2058 - accuracy: 0.8757\n","Epoch 58/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1649 - accuracy: 0.8892\n","Epoch 59/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1939 - accuracy: 0.8818\n","Epoch 60/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2224 - accuracy: 0.8873\n","Epoch 61/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2205 - accuracy: 0.8738\n","Epoch 62/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2318 - accuracy: 0.8615\n","Epoch 63/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1841 - accuracy: 0.8893\n","Epoch 64/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2058 - accuracy: 0.8704\n","Epoch 65/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1858 - accuracy: 0.8766\n","Epoch 66/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1874 - accuracy: 0.8940\n","Epoch 67/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2094 - accuracy: 0.8750\n","Epoch 68/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2043 - accuracy: 0.8990\n","Epoch 69/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.2027 - accuracy: 0.8742\n","Epoch 70/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.1816 - accuracy: 0.9004\n","Epoch 71/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1502 - accuracy: 0.9076\n","Epoch 72/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1774 - accuracy: 0.8935\n","Epoch 73/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1741 - accuracy: 0.8805\n","Epoch 74/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2348 - accuracy: 0.8513\n","Epoch 75/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2048 - accuracy: 0.8797\n","Epoch 76/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2407 - accuracy: 0.8499\n","Epoch 77/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1922 - accuracy: 0.8795\n","Epoch 78/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2380 - accuracy: 0.8888\n","Epoch 79/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1756 - accuracy: 0.8692\n","Epoch 80/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1933 - accuracy: 0.8952\n","Epoch 81/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1692 - accuracy: 0.8966\n","Epoch 82/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1785 - accuracy: 0.8999\n","Epoch 83/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.2039 - accuracy: 0.8870\n","Epoch 84/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.1674 - accuracy: 0.8939\n","Epoch 85/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1640 - accuracy: 0.8906\n","Epoch 86/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.1763 - accuracy: 0.8980\n","Epoch 87/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2269 - accuracy: 0.8799\n","Epoch 88/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1601 - accuracy: 0.9051\n","Epoch 89/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2061 - accuracy: 0.8829\n","Epoch 90/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1959 - accuracy: 0.8729\n","Epoch 91/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1933 - accuracy: 0.8864\n","Epoch 92/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1842 - accuracy: 0.8925\n","Epoch 93/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2334 - accuracy: 0.8654\n","Epoch 94/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2060 - accuracy: 0.8723\n","Epoch 95/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1922 - accuracy: 0.8891\n","Epoch 96/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1984 - accuracy: 0.8810\n","Epoch 97/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1947 - accuracy: 0.8910\n","Epoch 98/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2086 - accuracy: 0.8690\n","Epoch 99/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1827 - accuracy: 0.8908\n","Epoch 100/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.1563 - accuracy: 0.9058\n","18/18 [==============================] - 3s 101ms/step - loss: 0.4717 - accuracy: 0.8835\n","Validation Accuracy: 88.35%\n","Epoch 1/100\n","173/173 [==============================] - 9s 39ms/step - loss: 3.6745 - accuracy: 0.6705\n","Epoch 2/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4443 - accuracy: 0.7946\n","Epoch 3/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.4148 - accuracy: 0.8136\n","Epoch 4/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.4319 - accuracy: 0.8034\n","Epoch 5/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.4401 - accuracy: 0.7959\n","Epoch 6/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.4030 - accuracy: 0.8226\n","Epoch 7/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.4237 - accuracy: 0.7873\n","Epoch 8/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4299 - accuracy: 0.7820\n","Epoch 9/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.4119 - accuracy: 0.7842\n","Epoch 10/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3352 - accuracy: 0.8150\n","Epoch 11/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.5371 - accuracy: 0.7670\n","Epoch 12/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3846 - accuracy: 0.7883\n","Epoch 13/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3407 - accuracy: 0.8319\n","Epoch 14/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3272 - accuracy: 0.8060\n","Epoch 15/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3607 - accuracy: 0.8053\n","Epoch 16/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3274 - accuracy: 0.8324\n","Epoch 17/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3413 - accuracy: 0.8262\n","Epoch 18/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3076 - accuracy: 0.8424\n","Epoch 19/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2995 - accuracy: 0.8420\n","Epoch 20/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3300 - accuracy: 0.8332\n","Epoch 21/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3183 - accuracy: 0.8601\n","Epoch 22/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3233 - accuracy: 0.8133\n","Epoch 23/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3145 - accuracy: 0.8392\n","Epoch 24/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2833 - accuracy: 0.8656\n","Epoch 25/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2723 - accuracy: 0.8472\n","Epoch 26/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3567 - accuracy: 0.7973\n","Epoch 27/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2930 - accuracy: 0.8466\n","Epoch 28/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3031 - accuracy: 0.8489\n","Epoch 29/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3256 - accuracy: 0.8174\n","Epoch 30/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2803 - accuracy: 0.8700\n","Epoch 31/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2554 - accuracy: 0.8708\n","Epoch 32/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2426 - accuracy: 0.8787\n","Epoch 33/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2903 - accuracy: 0.8549\n","Epoch 34/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3001 - accuracy: 0.8357\n","Epoch 35/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2759 - accuracy: 0.8545\n","Epoch 36/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2372 - accuracy: 0.8765\n","Epoch 37/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2742 - accuracy: 0.8483\n","Epoch 38/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2844 - accuracy: 0.8610\n","Epoch 39/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2352 - accuracy: 0.8956\n","Epoch 40/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2575 - accuracy: 0.8672\n","Epoch 41/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2724 - accuracy: 0.8568\n","Epoch 42/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2508 - accuracy: 0.8680\n","Epoch 43/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2719 - accuracy: 0.8671\n","Epoch 44/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2569 - accuracy: 0.8605\n","Epoch 45/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2313 - accuracy: 0.8741\n","Epoch 46/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2923 - accuracy: 0.8268\n","Epoch 47/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2764 - accuracy: 0.8941\n","Epoch 48/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2841 - accuracy: 0.8538\n","Epoch 49/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2440 - accuracy: 0.8716\n","Epoch 50/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2531 - accuracy: 0.8888\n","Epoch 51/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2341 - accuracy: 0.8801\n","Epoch 52/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2696 - accuracy: 0.8536\n","Epoch 53/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2551 - accuracy: 0.8788\n","Epoch 54/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2078 - accuracy: 0.8974\n","Epoch 55/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2526 - accuracy: 0.8707\n","Epoch 56/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2619 - accuracy: 0.8552\n","Epoch 57/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3411 - accuracy: 0.7854\n","Epoch 58/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3459 - accuracy: 0.7757\n","Epoch 59/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2996 - accuracy: 0.8106\n","Epoch 60/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2859 - accuracy: 0.8499\n","Epoch 61/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2477 - accuracy: 0.8590\n","Epoch 62/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.3032 - accuracy: 0.8376\n","Epoch 63/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2490 - accuracy: 0.8663\n","Epoch 64/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.2368 - accuracy: 0.8751\n","Epoch 65/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.2579 - accuracy: 0.8652\n","Epoch 66/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2627 - accuracy: 0.8605\n","Epoch 67/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2490 - accuracy: 0.8432\n","Epoch 68/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2415 - accuracy: 0.8771\n","Epoch 69/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2086 - accuracy: 0.8864\n","Epoch 70/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2204 - accuracy: 0.8772\n","Epoch 71/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2699 - accuracy: 0.8532\n","Epoch 72/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2456 - accuracy: 0.8636\n","Epoch 73/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2209 - accuracy: 0.8790\n","Epoch 74/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2506 - accuracy: 0.8789\n","Epoch 75/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2631 - accuracy: 0.8689\n","Epoch 76/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2507 - accuracy: 0.8737\n","Epoch 77/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2409 - accuracy: 0.8692\n","Epoch 78/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2244 - accuracy: 0.8822\n","Epoch 79/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2462 - accuracy: 0.8730\n","Epoch 80/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2276 - accuracy: 0.8894\n","Epoch 81/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.2306 - accuracy: 0.8912\n","Epoch 82/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2235 - accuracy: 0.8797\n","Epoch 83/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2480 - accuracy: 0.8714\n","Epoch 84/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2499 - accuracy: 0.8563\n","Epoch 85/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2424 - accuracy: 0.8723\n","Epoch 86/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2171 - accuracy: 0.8955\n","Epoch 87/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2541 - accuracy: 0.8721\n","Epoch 88/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2251 - accuracy: 0.8781\n","Epoch 89/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2847 - accuracy: 0.8510\n","Epoch 90/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2404 - accuracy: 0.8781\n","Epoch 91/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.2184 - accuracy: 0.8938\n","Epoch 92/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2416 - accuracy: 0.8800\n","Epoch 93/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2428 - accuracy: 0.8812\n","Epoch 94/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2301 - accuracy: 0.8769\n","Epoch 95/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2350 - accuracy: 0.8860\n","Epoch 96/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2743 - accuracy: 0.8541\n","Epoch 97/100\n","173/173 [==============================] - 7s 39ms/step - loss: 0.2264 - accuracy: 0.8811\n","Epoch 98/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2287 - accuracy: 0.8802\n","Epoch 99/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2561 - accuracy: 0.8564\n","Epoch 100/100\n","173/173 [==============================] - 7s 38ms/step - loss: 0.2492 - accuracy: 0.8590\n","18/18 [==============================] - 3s 123ms/step - loss: 0.7498 - accuracy: 0.8833\n","Validation Accuracy: 88.33%\n","Validation Accuracy Mean (+/- Std Deviation): 88.30% (+/- 0.80%)\n","ResNet50 XFR Cross Validation Time = 2644.3752892017365s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g9zNP4ygcivC"},"source":["### MobileNet"]},{"cell_type":"markdown","metadata":{"id":"vuUY4kH2q8Lc"},"source":["We will first perform transfer learning. This will help get the parameter values initialized for the last layers before we engage few convolution layers of MobileNet in learning (Fine Tuning).  "]},{"cell_type":"markdown","metadata":{"id":"jShqNBv7qsby"},"source":["#### Transfer Learning"]},{"cell_type":"code","metadata":{"id":"NJyiKnXiclem","executionInfo":{"status":"ok","timestamp":1611779487535,"user_tz":-330,"elapsed":4169203,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# import libraries\r\n","import tensorflow as tf\r\n","from keras.models import Model\r\n","#from keras.optimizers import SGD\r\n","from keras.optimizers import Adam\r\n","#from keras.layers.normalization import BatchNormalization\r\n","from keras.layers.core import Dense, Dropout, Activation\r\n","#from keras.preprocessing.image import ImageDataGenerator\r\n","from tensorflow.keras import regularizers"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3sgLWPjcume","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611779488631,"user_tz":-330,"elapsed":4170294,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"3bb76712-84f1-4080-d67f-01a575622595"},"source":["# load MobileNet with pre-trained parameters for 'imagenet' challenge\r\n","# mobilenet = tf.keras.applications.mobilenet.MobileNet()\r\n","mobilenet = tf.keras.applications.MobileNet()\r\n","# mobilenet.summary()\r\n","\r\n","# define the last layers\r\n","# get the output of the last layer of the MobileNet\r\n","prediction_mn = mobilenet.output\r\n","\r\n","# mobilenet already has a GAP layer, hence we need to only add a Dense layer\r\n","\r\n","# add a FCN with 512 output neurons\r\n","prediction_mn = Dense(DENSE_LAYER_NEURONS, activation = 'relu')(prediction_mn)\r\n","# with regularizer\r\n","# prediction_mn = Dense(1024, activation = 'relu', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4), activity_regularizer = regularizers.l2(1e-5))(prediction_mn)\r\n","\r\n","# we will split the actions to have the Batch Normalization done befor relu\r\n","# prediction_mn = Dense(1024)(prediction_mn)\r\n","# prediction_mn = BatchNormalization()(prediction_mn)\r\n","# prediction_mn = Activation('relu')(prediction_mn)\r\n","\r\n","# add a dropout to avoid overfitting\r\n","prediction_mn = Dropout(DENSE_LAYER_DROPOUT)(prediction_mn)\r\n","\r\n","# add a FCN with 2 output neurons corresponding to the 2 classes we want to predict\r\n","prediction_mn = Dense(2, activation = 'softmax')(prediction_mn)\r\n","# with regularizer\r\n","# prediction_mn = Dense(2, activation = 'softmax', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4), activity_regularizer = regularizers.l2(1e-5))(prediction_mn)\r\n","\r\n","# connect the last layer with MobileNet layer to define the model\r\n","model_mn = Model(inputs = mobilenet.input, outputs = prediction_mn)\r\n","\r\n","# we wish use the pretrained MobileNet model as is i.e. do not want it's parameters to get updated during training\r\n","for layer in mobilenet.layers:\r\n","   layer.trainable = False\r\n","\r\n","# define the optimizer, loss function, metrics we will use\r\n","#model_mn.compile(optimizer = SGD(lr=0.0001, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n","#model_mn.compile(optimizer = Adam(lr=0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n","# we want to monitor validation accuracy and save the best validation accuracy, hence changing the metrics to 'val_accuracy'\r\n","model_mn.compile(optimizer = Adam(lr=LEARNING_RATE), loss = 'categorical_crossentropy', metrics = ['accuracy'])"],"execution_count":85,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n","17227776/17225924 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o1PDyOKhymEB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611779488632,"user_tz":-330,"elapsed":4170291,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"bad2e19d-6eff-47a5-ceaf-e58256355e40"},"source":["model_mn.summary()"],"execution_count":86,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 112, 112, 32)      864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n","_________________________________________________________________\n","conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n","_________________________________________________________________\n","conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n","_________________________________________________________________\n","conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n","_________________________________________________________________\n","conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n","_________________________________________________________________\n","conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n","_________________________________________________________________\n","conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n","_________________________________________________________________\n","conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n","_________________________________________________________________\n","conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n","_________________________________________________________________\n","conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n","_________________________________________________________________\n","conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n","_________________________________________________________________\n","conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","global_average_pooling2d_5 ( (None, 1024)              0         \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n","_________________________________________________________________\n","reshape_2 (Reshape)          (None, 1000)              0         \n","_________________________________________________________________\n","predictions (Activation)     (None, 1000)              0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 512)               512512    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 2)                 1026      \n","=================================================================\n","Total params: 4,767,402\n","Trainable params: 513,538\n","Non-trainable params: 4,253,864\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VDHrhM3UJzj6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611779489828,"user_tz":-330,"elapsed":4171480,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"1ea832b1-f04f-408f-aced-8836901b6a1e"},"source":["# calculate FLOPS for the model\r\n","flops_mobilenet_xfr = get_flops(model_mn, batch_size = 1)\r\n","print(f\"MobileNet Transfer FLOPS: {flops_mobilenet_xfr / 10 ** 9:.03} G\")"],"execution_count":87,"outputs":[{"output_type":"stream","text":["MobileNet Transfer FLOPS: 1.15 G\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wymMq6CP_viD","executionInfo":{"status":"ok","timestamp":1611779489830,"user_tz":-330,"elapsed":4171477,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# let us check the layers in the model \r\n","# for i,layer in enumerate(model_mn.layers):\r\n","#  print(i,layer.name)"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oipav9r0dJ6I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611779652676,"user_tz":-330,"elapsed":4334318,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"6851ad1c-71a8-45e6-cf9b-02f89b8ef668"},"source":["# train and validate model\r\n","path_to_mobilenet_xfr_parameters_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5'\r\n","start_time = time.time()\r\n","hist = model_mn.fit(train_images, train_labels, epochs = EPOCHS, batch_size = BATCH_SIZE, validation_data = (validation_images, validation_labels), callbacks=[checkpoint(path_to_mobilenet_xfr_parameters_file)])\r\n","duration = time.time() - start_time\r\n","print(f'MobileNet XFR Train Time = {duration}s')"],"execution_count":89,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","77/77 [==============================] - 4s 29ms/step - loss: 0.6173 - accuracy: 0.7006 - val_loss: 0.5196 - val_accuracy: 0.7513\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.75134, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 2/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.5235 - accuracy: 0.7678 - val_loss: 0.5052 - val_accuracy: 0.7567\n","\n","Epoch 00002: val_accuracy improved from 0.75134 to 0.75668, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 3/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.5306 - accuracy: 0.7379 - val_loss: 0.4734 - val_accuracy: 0.7807\n","\n","Epoch 00003: val_accuracy improved from 0.75668 to 0.78075, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 4/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.5285 - accuracy: 0.7431 - val_loss: 0.4615 - val_accuracy: 0.8102\n","\n","Epoch 00004: val_accuracy improved from 0.78075 to 0.81016, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 5/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.5070 - accuracy: 0.7657 - val_loss: 0.4391 - val_accuracy: 0.8155\n","\n","Epoch 00005: val_accuracy improved from 0.81016 to 0.81551, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 6/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.4790 - accuracy: 0.7624 - val_loss: 0.4593 - val_accuracy: 0.7861\n","\n","Epoch 00006: val_accuracy did not improve from 0.81551\n","Epoch 7/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.5142 - accuracy: 0.7644 - val_loss: 0.4296 - val_accuracy: 0.8316\n","\n","Epoch 00007: val_accuracy improved from 0.81551 to 0.83155, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 8/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4814 - accuracy: 0.7823 - val_loss: 0.4596 - val_accuracy: 0.7995\n","\n","Epoch 00008: val_accuracy did not improve from 0.83155\n","Epoch 9/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.5255 - accuracy: 0.7622 - val_loss: 0.4228 - val_accuracy: 0.8075\n","\n","Epoch 00009: val_accuracy did not improve from 0.83155\n","Epoch 10/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4724 - accuracy: 0.7742 - val_loss: 0.4305 - val_accuracy: 0.8048\n","\n","Epoch 00010: val_accuracy did not improve from 0.83155\n","Epoch 11/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4409 - accuracy: 0.7967 - val_loss: 0.4187 - val_accuracy: 0.8102\n","\n","Epoch 00011: val_accuracy did not improve from 0.83155\n","Epoch 12/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4569 - accuracy: 0.7931 - val_loss: 0.4513 - val_accuracy: 0.7888\n","\n","Epoch 00012: val_accuracy did not improve from 0.83155\n","Epoch 13/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4678 - accuracy: 0.7771 - val_loss: 0.3911 - val_accuracy: 0.8235\n","\n","Epoch 00013: val_accuracy did not improve from 0.83155\n","Epoch 14/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4556 - accuracy: 0.7919 - val_loss: 0.4345 - val_accuracy: 0.8048\n","\n","Epoch 00014: val_accuracy did not improve from 0.83155\n","Epoch 15/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4368 - accuracy: 0.7841 - val_loss: 0.4146 - val_accuracy: 0.8075\n","\n","Epoch 00015: val_accuracy did not improve from 0.83155\n","Epoch 16/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4766 - accuracy: 0.7850 - val_loss: 0.3806 - val_accuracy: 0.8209\n","\n","Epoch 00016: val_accuracy did not improve from 0.83155\n","Epoch 17/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4837 - accuracy: 0.7871 - val_loss: 0.4491 - val_accuracy: 0.7807\n","\n","Epoch 00017: val_accuracy did not improve from 0.83155\n","Epoch 18/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4182 - accuracy: 0.8209 - val_loss: 0.4259 - val_accuracy: 0.7914\n","\n","Epoch 00018: val_accuracy did not improve from 0.83155\n","Epoch 19/100\n","77/77 [==============================] - 2s 22ms/step - loss: 0.4294 - accuracy: 0.8172 - val_loss: 0.4379 - val_accuracy: 0.7888\n","\n","Epoch 00019: val_accuracy did not improve from 0.83155\n","Epoch 20/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4257 - accuracy: 0.8185 - val_loss: 0.4538 - val_accuracy: 0.8155\n","\n","Epoch 00020: val_accuracy did not improve from 0.83155\n","Epoch 21/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4614 - accuracy: 0.7946 - val_loss: 0.4178 - val_accuracy: 0.8075\n","\n","Epoch 00021: val_accuracy did not improve from 0.83155\n","Epoch 22/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4605 - accuracy: 0.7931 - val_loss: 0.4165 - val_accuracy: 0.8182\n","\n","Epoch 00022: val_accuracy did not improve from 0.83155\n","Epoch 23/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4071 - accuracy: 0.8340 - val_loss: 0.4138 - val_accuracy: 0.8316\n","\n","Epoch 00023: val_accuracy did not improve from 0.83155\n","Epoch 24/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3946 - accuracy: 0.8241 - val_loss: 0.4215 - val_accuracy: 0.7968\n","\n","Epoch 00024: val_accuracy did not improve from 0.83155\n","Epoch 25/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4112 - accuracy: 0.8092 - val_loss: 0.4576 - val_accuracy: 0.7674\n","\n","Epoch 00025: val_accuracy did not improve from 0.83155\n","Epoch 26/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4010 - accuracy: 0.8330 - val_loss: 0.4075 - val_accuracy: 0.8396\n","\n","Epoch 00026: val_accuracy improved from 0.83155 to 0.83957, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 27/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4006 - accuracy: 0.8271 - val_loss: 0.4163 - val_accuracy: 0.7941\n","\n","Epoch 00027: val_accuracy did not improve from 0.83957\n","Epoch 28/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4057 - accuracy: 0.8168 - val_loss: 0.4191 - val_accuracy: 0.8102\n","\n","Epoch 00028: val_accuracy did not improve from 0.83957\n","Epoch 29/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4013 - accuracy: 0.8276 - val_loss: 0.4225 - val_accuracy: 0.8021\n","\n","Epoch 00029: val_accuracy did not improve from 0.83957\n","Epoch 30/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3925 - accuracy: 0.8308 - val_loss: 0.4501 - val_accuracy: 0.7834\n","\n","Epoch 00030: val_accuracy did not improve from 0.83957\n","Epoch 31/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4097 - accuracy: 0.8049 - val_loss: 0.3941 - val_accuracy: 0.8316\n","\n","Epoch 00031: val_accuracy did not improve from 0.83957\n","Epoch 32/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3844 - accuracy: 0.8341 - val_loss: 0.3797 - val_accuracy: 0.8369\n","\n","Epoch 00032: val_accuracy did not improve from 0.83957\n","Epoch 33/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3779 - accuracy: 0.8336 - val_loss: 0.4425 - val_accuracy: 0.7995\n","\n","Epoch 00033: val_accuracy did not improve from 0.83957\n","Epoch 34/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4141 - accuracy: 0.8000 - val_loss: 0.4885 - val_accuracy: 0.7620\n","\n","Epoch 00034: val_accuracy did not improve from 0.83957\n","Epoch 35/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.4278 - accuracy: 0.8047 - val_loss: 0.4391 - val_accuracy: 0.8102\n","\n","Epoch 00035: val_accuracy did not improve from 0.83957\n","Epoch 36/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4086 - accuracy: 0.8309 - val_loss: 0.3937 - val_accuracy: 0.8262\n","\n","Epoch 00036: val_accuracy did not improve from 0.83957\n","Epoch 37/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3955 - accuracy: 0.8373 - val_loss: 0.3874 - val_accuracy: 0.8369\n","\n","Epoch 00037: val_accuracy did not improve from 0.83957\n","Epoch 38/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3681 - accuracy: 0.8494 - val_loss: 0.4637 - val_accuracy: 0.7834\n","\n","Epoch 00038: val_accuracy did not improve from 0.83957\n","Epoch 39/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.4139 - accuracy: 0.8069 - val_loss: 0.4356 - val_accuracy: 0.8075\n","\n","Epoch 00039: val_accuracy did not improve from 0.83957\n","Epoch 40/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3534 - accuracy: 0.8352 - val_loss: 0.4647 - val_accuracy: 0.7941\n","\n","Epoch 00040: val_accuracy did not improve from 0.83957\n","Epoch 41/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3880 - accuracy: 0.8504 - val_loss: 0.4174 - val_accuracy: 0.8048\n","\n","Epoch 00041: val_accuracy did not improve from 0.83957\n","Epoch 42/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3735 - accuracy: 0.8253 - val_loss: 0.3920 - val_accuracy: 0.8289\n","\n","Epoch 00042: val_accuracy did not improve from 0.83957\n","Epoch 43/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3705 - accuracy: 0.8361 - val_loss: 0.4186 - val_accuracy: 0.8155\n","\n","Epoch 00043: val_accuracy did not improve from 0.83957\n","Epoch 44/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.4167 - accuracy: 0.8034 - val_loss: 0.3983 - val_accuracy: 0.8422\n","\n","Epoch 00044: val_accuracy improved from 0.83957 to 0.84225, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 45/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3333 - accuracy: 0.8544 - val_loss: 0.4490 - val_accuracy: 0.8209\n","\n","Epoch 00045: val_accuracy did not improve from 0.84225\n","Epoch 46/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3667 - accuracy: 0.8438 - val_loss: 0.4838 - val_accuracy: 0.7727\n","\n","Epoch 00046: val_accuracy did not improve from 0.84225\n","Epoch 47/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3575 - accuracy: 0.8480 - val_loss: 0.4152 - val_accuracy: 0.8155\n","\n","Epoch 00047: val_accuracy did not improve from 0.84225\n","Epoch 48/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3550 - accuracy: 0.8340 - val_loss: 0.4152 - val_accuracy: 0.8396\n","\n","Epoch 00048: val_accuracy did not improve from 0.84225\n","Epoch 49/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3500 - accuracy: 0.8468 - val_loss: 0.4652 - val_accuracy: 0.7968\n","\n","Epoch 00049: val_accuracy did not improve from 0.84225\n","Epoch 50/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3542 - accuracy: 0.8547 - val_loss: 0.4818 - val_accuracy: 0.7807\n","\n","Epoch 00050: val_accuracy did not improve from 0.84225\n","Epoch 51/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3519 - accuracy: 0.8577 - val_loss: 0.4328 - val_accuracy: 0.8048\n","\n","Epoch 00051: val_accuracy did not improve from 0.84225\n","Epoch 52/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3783 - accuracy: 0.8316 - val_loss: 0.4098 - val_accuracy: 0.8503\n","\n","Epoch 00052: val_accuracy improved from 0.84225 to 0.85027, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_xfr.hdf5\n","Epoch 53/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3925 - accuracy: 0.8469 - val_loss: 0.4701 - val_accuracy: 0.7861\n","\n","Epoch 00053: val_accuracy did not improve from 0.85027\n","Epoch 54/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3575 - accuracy: 0.8438 - val_loss: 0.4283 - val_accuracy: 0.8209\n","\n","Epoch 00054: val_accuracy did not improve from 0.85027\n","Epoch 55/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3351 - accuracy: 0.8570 - val_loss: 0.5226 - val_accuracy: 0.7701\n","\n","Epoch 00055: val_accuracy did not improve from 0.85027\n","Epoch 56/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3527 - accuracy: 0.8464 - val_loss: 0.4585 - val_accuracy: 0.8021\n","\n","Epoch 00056: val_accuracy did not improve from 0.85027\n","Epoch 57/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3269 - accuracy: 0.8665 - val_loss: 0.4156 - val_accuracy: 0.8262\n","\n","Epoch 00057: val_accuracy did not improve from 0.85027\n","Epoch 58/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3313 - accuracy: 0.8527 - val_loss: 0.4456 - val_accuracy: 0.8155\n","\n","Epoch 00058: val_accuracy did not improve from 0.85027\n","Epoch 59/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3750 - accuracy: 0.8373 - val_loss: 0.4434 - val_accuracy: 0.8289\n","\n","Epoch 00059: val_accuracy did not improve from 0.85027\n","Epoch 60/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3295 - accuracy: 0.8553 - val_loss: 0.4486 - val_accuracy: 0.8102\n","\n","Epoch 00060: val_accuracy did not improve from 0.85027\n","Epoch 61/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3640 - accuracy: 0.8437 - val_loss: 0.4588 - val_accuracy: 0.8075\n","\n","Epoch 00061: val_accuracy did not improve from 0.85027\n","Epoch 62/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3289 - accuracy: 0.8504 - val_loss: 0.4501 - val_accuracy: 0.8128\n","\n","Epoch 00062: val_accuracy did not improve from 0.85027\n","Epoch 63/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3150 - accuracy: 0.8600 - val_loss: 0.4962 - val_accuracy: 0.7781\n","\n","Epoch 00063: val_accuracy did not improve from 0.85027\n","Epoch 64/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3314 - accuracy: 0.8513 - val_loss: 0.4805 - val_accuracy: 0.7968\n","\n","Epoch 00064: val_accuracy did not improve from 0.85027\n","Epoch 65/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3294 - accuracy: 0.8669 - val_loss: 0.4458 - val_accuracy: 0.8182\n","\n","Epoch 00065: val_accuracy did not improve from 0.85027\n","Epoch 66/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3501 - accuracy: 0.8459 - val_loss: 0.4963 - val_accuracy: 0.7914\n","\n","Epoch 00066: val_accuracy did not improve from 0.85027\n","Epoch 67/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3198 - accuracy: 0.8687 - val_loss: 0.4677 - val_accuracy: 0.8209\n","\n","Epoch 00067: val_accuracy did not improve from 0.85027\n","Epoch 68/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3071 - accuracy: 0.8736 - val_loss: 0.5308 - val_accuracy: 0.7807\n","\n","Epoch 00068: val_accuracy did not improve from 0.85027\n","Epoch 69/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3705 - accuracy: 0.8192 - val_loss: 0.4632 - val_accuracy: 0.8048\n","\n","Epoch 00069: val_accuracy did not improve from 0.85027\n","Epoch 70/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2711 - accuracy: 0.8925 - val_loss: 0.4812 - val_accuracy: 0.7968\n","\n","Epoch 00070: val_accuracy did not improve from 0.85027\n","Epoch 71/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3229 - accuracy: 0.8638 - val_loss: 0.4690 - val_accuracy: 0.8128\n","\n","Epoch 00071: val_accuracy did not improve from 0.85027\n","Epoch 72/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3203 - accuracy: 0.8712 - val_loss: 0.4192 - val_accuracy: 0.8342\n","\n","Epoch 00072: val_accuracy did not improve from 0.85027\n","Epoch 73/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3163 - accuracy: 0.8674 - val_loss: 0.4526 - val_accuracy: 0.8102\n","\n","Epoch 00073: val_accuracy did not improve from 0.85027\n","Epoch 74/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3290 - accuracy: 0.8570 - val_loss: 0.4642 - val_accuracy: 0.8182\n","\n","Epoch 00074: val_accuracy did not improve from 0.85027\n","Epoch 75/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3537 - accuracy: 0.8478 - val_loss: 0.4640 - val_accuracy: 0.8209\n","\n","Epoch 00075: val_accuracy did not improve from 0.85027\n","Epoch 76/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3063 - accuracy: 0.8782 - val_loss: 0.4884 - val_accuracy: 0.7834\n","\n","Epoch 00076: val_accuracy did not improve from 0.85027\n","Epoch 77/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3206 - accuracy: 0.8582 - val_loss: 0.4733 - val_accuracy: 0.8102\n","\n","Epoch 00077: val_accuracy did not improve from 0.85027\n","Epoch 78/100\n","77/77 [==============================] - 2s 22ms/step - loss: 0.2951 - accuracy: 0.8715 - val_loss: 0.4452 - val_accuracy: 0.8476\n","\n","Epoch 00078: val_accuracy did not improve from 0.85027\n","Epoch 79/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3301 - accuracy: 0.8628 - val_loss: 0.4465 - val_accuracy: 0.8262\n","\n","Epoch 00079: val_accuracy did not improve from 0.85027\n","Epoch 80/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3142 - accuracy: 0.8557 - val_loss: 0.4437 - val_accuracy: 0.8102\n","\n","Epoch 00080: val_accuracy did not improve from 0.85027\n","Epoch 81/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3046 - accuracy: 0.8881 - val_loss: 0.4949 - val_accuracy: 0.8102\n","\n","Epoch 00081: val_accuracy did not improve from 0.85027\n","Epoch 82/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3182 - accuracy: 0.8638 - val_loss: 0.4838 - val_accuracy: 0.7914\n","\n","Epoch 00082: val_accuracy did not improve from 0.85027\n","Epoch 83/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2961 - accuracy: 0.8742 - val_loss: 0.6210 - val_accuracy: 0.7460\n","\n","Epoch 00083: val_accuracy did not improve from 0.85027\n","Epoch 84/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3228 - accuracy: 0.8751 - val_loss: 0.4534 - val_accuracy: 0.8155\n","\n","Epoch 00084: val_accuracy did not improve from 0.85027\n","Epoch 85/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2905 - accuracy: 0.8837 - val_loss: 0.4797 - val_accuracy: 0.8128\n","\n","Epoch 00085: val_accuracy did not improve from 0.85027\n","Epoch 86/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2734 - accuracy: 0.8883 - val_loss: 0.4671 - val_accuracy: 0.8209\n","\n","Epoch 00086: val_accuracy did not improve from 0.85027\n","Epoch 87/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3079 - accuracy: 0.8592 - val_loss: 0.5205 - val_accuracy: 0.8021\n","\n","Epoch 00087: val_accuracy did not improve from 0.85027\n","Epoch 88/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2896 - accuracy: 0.8722 - val_loss: 0.4937 - val_accuracy: 0.8235\n","\n","Epoch 00088: val_accuracy did not improve from 0.85027\n","Epoch 89/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2731 - accuracy: 0.8735 - val_loss: 0.4866 - val_accuracy: 0.8128\n","\n","Epoch 00089: val_accuracy did not improve from 0.85027\n","Epoch 90/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2477 - accuracy: 0.9040 - val_loss: 0.4684 - val_accuracy: 0.8342\n","\n","Epoch 00090: val_accuracy did not improve from 0.85027\n","Epoch 91/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2768 - accuracy: 0.8828 - val_loss: 0.4868 - val_accuracy: 0.8155\n","\n","Epoch 00091: val_accuracy did not improve from 0.85027\n","Epoch 92/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2806 - accuracy: 0.8693 - val_loss: 0.4719 - val_accuracy: 0.8289\n","\n","Epoch 00092: val_accuracy did not improve from 0.85027\n","Epoch 93/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2796 - accuracy: 0.8770 - val_loss: 0.5060 - val_accuracy: 0.8128\n","\n","Epoch 00093: val_accuracy did not improve from 0.85027\n","Epoch 94/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2562 - accuracy: 0.8788 - val_loss: 0.5471 - val_accuracy: 0.7914\n","\n","Epoch 00094: val_accuracy did not improve from 0.85027\n","Epoch 95/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2706 - accuracy: 0.8792 - val_loss: 0.4970 - val_accuracy: 0.8102\n","\n","Epoch 00095: val_accuracy did not improve from 0.85027\n","Epoch 96/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2961 - accuracy: 0.8803 - val_loss: 0.5585 - val_accuracy: 0.7754\n","\n","Epoch 00096: val_accuracy did not improve from 0.85027\n","Epoch 97/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2584 - accuracy: 0.8847 - val_loss: 0.4829 - val_accuracy: 0.8182\n","\n","Epoch 00097: val_accuracy did not improve from 0.85027\n","Epoch 98/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3051 - accuracy: 0.8609 - val_loss: 0.4756 - val_accuracy: 0.8102\n","\n","Epoch 00098: val_accuracy did not improve from 0.85027\n","Epoch 99/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2845 - accuracy: 0.8838 - val_loss: 0.4830 - val_accuracy: 0.8048\n","\n","Epoch 00099: val_accuracy did not improve from 0.85027\n","Epoch 100/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2976 - accuracy: 0.8743 - val_loss: 0.5059 - val_accuracy: 0.8235\n","\n","Epoch 00100: val_accuracy did not improve from 0.85027\n","MobileNet XFR Train Time = 162.90089511871338s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-odzOoQSpTH9","executionInfo":{"status":"ok","timestamp":1611779652678,"user_tz":-330,"elapsed":4334315,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# how to get the keys in your model\r\n","# for key in hist.history:\r\n","#   print(key)"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBs3b9OLgDmQ","executionInfo":{"status":"ok","timestamp":1611779652679,"user_tz":-330,"elapsed":4334312,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# test model\r\n","#test_loss_mn, test_acc_mn = model_mn.evaluate(test_images, test_labels)"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"vj15Hz5iuRbS","executionInfo":{"status":"ok","timestamp":1611779652679,"user_tz":-330,"elapsed":4334308,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["#len(test_predict)"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlPJdM2Eud6R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611779658575,"user_tz":-330,"elapsed":4340199,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"63de14d3-329c-44df-e8a6-191a0ebd9ad9"},"source":["# test with best model\r\n","#model_mn.load_weights('/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_model.hdf5')\r\n","model_mn.load_weights(path_to_mobilenet_xfr_parameters_file)\r\n","# test_predict = model_mn.predict(test_images, batch_size=10, verbose=0)\r\n","start_time = time.time()\r\n","test_loss_mn, test_acc_mn = model_mn.evaluate(test_images, test_labels)\r\n","duration = time.time() - start_time\r\n","print(f'MobileNet XFR Test Time = {duration}s')\r\n","print(f'MobileNet XFR Test Time / sample = {duration/1155}s')"],"execution_count":93,"outputs":[{"output_type":"stream","text":["37/37 [==============================] - 2s 41ms/step - loss: 0.5840 - accuracy: 0.7835\n","MobileNet XFR Test Time = 1.819808006286621s\n","MobileNet XFR Test Time / sample = 0.001575591347434304s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpMzA6QeoP5S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611780646756,"user_tz":-330,"elapsed":5328377,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"7b848811-286e-49e8-d10a-5e5722737ccd"},"source":["start_time = time.time()\r\n","# perform cross validation\r\n","if (CROSS_VALIDATE == True):\r\n","  # import libraries\r\n","  from sklearn.model_selection import StratifiedKFold\r\n","  # using stratifiedkfold so that we have balanced classes in each split\r\n","  cvfold = StratifiedKFold(n_splits = CROSS_VALIDATION_FOLDS, shuffle = True)\r\n","  # we will use below to store all individual validation scores\r\n","  cvscores = []\r\n","  # based on the class value, get the split done and respective train and test index\r\n","  for train_index, val_index in cvfold.split(all_images, all_labels_before_categorical):\r\n","    # model definition as is from top - starts\r\n","    # mobilenet = tf.keras.applications.mobilenet.MobileNet()\r\n","    mobilenet = tf.keras.applications.MobileNet()\r\n","    prediction_mn = mobilenet.output\r\n","    prediction_mn = Dense(DENSE_LAYER_NEURONS, activation = 'relu')(prediction_mn)\r\n","    prediction_mn = Dropout(DENSE_LAYER_DROPOUT)(prediction_mn)\r\n","    prediction_mn = Dense(2, activation = 'softmax')(prediction_mn)\r\n","    model_mn = Model(inputs = mobilenet.input, outputs = prediction_mn)\r\n","    for layer in mobilenet.layers:\r\n","      layer.trainable = False\r\n","    model_mn.compile(optimizer = Adam(lr=LEARNING_RATE), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n","    # model definition as is from top - ends\r\n","    # train based on train index elements\r\n","    model_mn.fit(all_images[train_index], all_labels[train_index], epochs = EPOCHS, batch_size = BATCH_SIZE) \r\n","    # validate based on validation index elements\r\n","    cv_score = model_mn.evaluate(all_images[val_index], all_labels[val_index])\r\n","    print(\"Validation Accuracy: %0.2f%%\" % (cv_score[1]*100))\r\n","    # append each iteration validation accuracy score\r\n","    cvscores.append(cv_score[1]*100)\r\n","  # print mean and std deviation of the validation accuracy for the complete cross validation i.e. for all iterations\r\n","  print(\"Validation Accuracy Mean (+/- Std Deviation): %0.2f%% (+/- %0.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\r\n","duration = time.time() - start_time\r\n","print(f'MobileNet XFR Cross Validation Time = {duration}s')"],"execution_count":94,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","173/173 [==============================] - 4s 14ms/step - loss: 0.5623 - accuracy: 0.7163\n","Epoch 2/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.5024 - accuracy: 0.7468\n","Epoch 3/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4630 - accuracy: 0.7911\n","Epoch 4/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4741 - accuracy: 0.7977\n","Epoch 5/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4449 - accuracy: 0.8080\n","Epoch 6/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4591 - accuracy: 0.7959\n","Epoch 7/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4759 - accuracy: 0.7825\n","Epoch 8/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4618 - accuracy: 0.7952\n","Epoch 9/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4615 - accuracy: 0.7957\n","Epoch 10/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4688 - accuracy: 0.7937\n","Epoch 11/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4427 - accuracy: 0.7973\n","Epoch 12/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4854 - accuracy: 0.7755\n","Epoch 13/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4742 - accuracy: 0.7693\n","Epoch 14/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4172 - accuracy: 0.8195\n","Epoch 15/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4488 - accuracy: 0.8013\n","Epoch 16/100\n","173/173 [==============================] - 2s 13ms/step - loss: 0.4211 - accuracy: 0.8213\n","Epoch 17/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4272 - accuracy: 0.7977\n","Epoch 18/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4494 - accuracy: 0.8150\n","Epoch 19/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4184 - accuracy: 0.8001\n","Epoch 20/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4243 - accuracy: 0.8142\n","Epoch 21/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4212 - accuracy: 0.8073\n","Epoch 22/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4278 - accuracy: 0.8163\n","Epoch 23/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4250 - accuracy: 0.8079\n","Epoch 24/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4162 - accuracy: 0.8144\n","Epoch 25/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4030 - accuracy: 0.8302\n","Epoch 26/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3954 - accuracy: 0.8344\n","Epoch 27/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4053 - accuracy: 0.8231\n","Epoch 28/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4256 - accuracy: 0.8155\n","Epoch 29/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4181 - accuracy: 0.8311\n","Epoch 30/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4168 - accuracy: 0.8145\n","Epoch 31/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3896 - accuracy: 0.8155\n","Epoch 32/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4135 - accuracy: 0.8155\n","Epoch 33/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4004 - accuracy: 0.8212\n","Epoch 34/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4073 - accuracy: 0.8101\n","Epoch 35/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3888 - accuracy: 0.8312\n","Epoch 36/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4243 - accuracy: 0.8051\n","Epoch 37/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3844 - accuracy: 0.8274\n","Epoch 38/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3947 - accuracy: 0.8108\n","Epoch 39/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3947 - accuracy: 0.8284\n","Epoch 40/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4156 - accuracy: 0.8066\n","Epoch 41/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3714 - accuracy: 0.8291\n","Epoch 42/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3902 - accuracy: 0.8305\n","Epoch 43/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3840 - accuracy: 0.8199\n","Epoch 44/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3919 - accuracy: 0.8231\n","Epoch 45/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3872 - accuracy: 0.8278\n","Epoch 46/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3720 - accuracy: 0.8316\n","Epoch 47/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4083 - accuracy: 0.8272\n","Epoch 48/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3748 - accuracy: 0.8361\n","Epoch 49/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3740 - accuracy: 0.8350\n","Epoch 50/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3734 - accuracy: 0.8366\n","Epoch 51/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3952 - accuracy: 0.8236\n","Epoch 52/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3602 - accuracy: 0.8359\n","Epoch 53/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3732 - accuracy: 0.8248\n","Epoch 54/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3686 - accuracy: 0.8332\n","Epoch 55/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3511 - accuracy: 0.8458\n","Epoch 56/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3731 - accuracy: 0.8170\n","Epoch 57/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3608 - accuracy: 0.8363\n","Epoch 58/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3609 - accuracy: 0.8345\n","Epoch 59/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3746 - accuracy: 0.8251\n","Epoch 60/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3557 - accuracy: 0.8350\n","Epoch 61/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3429 - accuracy: 0.8558\n","Epoch 62/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3485 - accuracy: 0.8368\n","Epoch 63/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3562 - accuracy: 0.8216\n","Epoch 64/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3485 - accuracy: 0.8341\n","Epoch 65/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3494 - accuracy: 0.8459\n","Epoch 66/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3571 - accuracy: 0.8410\n","Epoch 67/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3569 - accuracy: 0.8466\n","Epoch 68/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3515 - accuracy: 0.8391\n","Epoch 69/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3639 - accuracy: 0.8393\n","Epoch 70/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3756 - accuracy: 0.8404\n","Epoch 71/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3515 - accuracy: 0.8617\n","Epoch 72/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3530 - accuracy: 0.8398\n","Epoch 73/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3447 - accuracy: 0.8319\n","Epoch 74/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3272 - accuracy: 0.8484\n","Epoch 75/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3662 - accuracy: 0.8466\n","Epoch 76/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3492 - accuracy: 0.8436\n","Epoch 77/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3492 - accuracy: 0.8550\n","Epoch 78/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3254 - accuracy: 0.8436\n","Epoch 79/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3491 - accuracy: 0.8498\n","Epoch 80/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3455 - accuracy: 0.8368\n","Epoch 81/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3270 - accuracy: 0.8514\n","Epoch 82/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3457 - accuracy: 0.8450\n","Epoch 83/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3458 - accuracy: 0.8502\n","Epoch 84/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3285 - accuracy: 0.8559\n","Epoch 85/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3482 - accuracy: 0.8397\n","Epoch 86/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3360 - accuracy: 0.8528\n","Epoch 87/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3292 - accuracy: 0.8584\n","Epoch 88/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3413 - accuracy: 0.8535\n","Epoch 89/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3032 - accuracy: 0.8741\n","Epoch 90/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3443 - accuracy: 0.8437\n","Epoch 91/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3197 - accuracy: 0.8583\n","Epoch 92/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3116 - accuracy: 0.8649\n","Epoch 93/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3106 - accuracy: 0.8748\n","Epoch 94/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3306 - accuracy: 0.8587\n","Epoch 95/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3097 - accuracy: 0.8589\n","Epoch 96/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3124 - accuracy: 0.8593\n","Epoch 97/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3279 - accuracy: 0.8593\n","Epoch 98/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3150 - accuracy: 0.8578\n","Epoch 99/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3085 - accuracy: 0.8601\n","Epoch 100/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3369 - accuracy: 0.8464\n","18/18 [==============================] - 1s 50ms/step - loss: 0.5782 - accuracy: 0.7791\n","Validation Accuracy: 77.91%\n","Epoch 1/100\n","173/173 [==============================] - 4s 14ms/step - loss: 0.5708 - accuracy: 0.7123\n","Epoch 2/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.5040 - accuracy: 0.7672\n","Epoch 3/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4854 - accuracy: 0.7656\n","Epoch 4/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4854 - accuracy: 0.7659\n","Epoch 5/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4922 - accuracy: 0.7824\n","Epoch 6/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4790 - accuracy: 0.7800\n","Epoch 7/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4388 - accuracy: 0.8003\n","Epoch 8/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4615 - accuracy: 0.7862\n","Epoch 9/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4515 - accuracy: 0.8012\n","Epoch 10/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4511 - accuracy: 0.7841\n","Epoch 11/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4566 - accuracy: 0.7852\n","Epoch 12/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4569 - accuracy: 0.7883\n","Epoch 13/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4350 - accuracy: 0.7834\n","Epoch 14/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4493 - accuracy: 0.7901\n","Epoch 15/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4561 - accuracy: 0.7783\n","Epoch 16/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4221 - accuracy: 0.8124\n","Epoch 17/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4498 - accuracy: 0.7794\n","Epoch 18/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4511 - accuracy: 0.7816\n","Epoch 19/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4164 - accuracy: 0.8134\n","Epoch 20/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4028 - accuracy: 0.8262\n","Epoch 21/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4478 - accuracy: 0.7927\n","Epoch 22/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4241 - accuracy: 0.8079\n","Epoch 23/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4578 - accuracy: 0.7802\n","Epoch 24/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4342 - accuracy: 0.7873\n","Epoch 25/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4308 - accuracy: 0.7837\n","Epoch 26/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4357 - accuracy: 0.7809\n","Epoch 27/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3944 - accuracy: 0.8152\n","Epoch 28/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4181 - accuracy: 0.7965\n","Epoch 29/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4259 - accuracy: 0.7969\n","Epoch 30/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4060 - accuracy: 0.8062\n","Epoch 31/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4175 - accuracy: 0.7985\n","Epoch 32/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4332 - accuracy: 0.7942\n","Epoch 33/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3952 - accuracy: 0.8196\n","Epoch 34/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4066 - accuracy: 0.8158\n","Epoch 35/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4131 - accuracy: 0.8119\n","Epoch 36/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4134 - accuracy: 0.8116\n","Epoch 37/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3921 - accuracy: 0.8126\n","Epoch 38/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4109 - accuracy: 0.8123\n","Epoch 39/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3973 - accuracy: 0.8212\n","Epoch 40/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3921 - accuracy: 0.8216\n","Epoch 41/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3941 - accuracy: 0.8247\n","Epoch 42/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3665 - accuracy: 0.8340\n","Epoch 43/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4030 - accuracy: 0.8113\n","Epoch 44/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3827 - accuracy: 0.8257\n","Epoch 45/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3912 - accuracy: 0.8198\n","Epoch 46/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3705 - accuracy: 0.8315\n","Epoch 47/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3768 - accuracy: 0.8236\n","Epoch 48/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3627 - accuracy: 0.8328\n","Epoch 49/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3523 - accuracy: 0.8422\n","Epoch 50/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3818 - accuracy: 0.8174\n","Epoch 51/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3924 - accuracy: 0.8358\n","Epoch 52/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3881 - accuracy: 0.8425\n","Epoch 53/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3707 - accuracy: 0.8420\n","Epoch 54/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3609 - accuracy: 0.8269\n","Epoch 55/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3750 - accuracy: 0.8367\n","Epoch 56/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3743 - accuracy: 0.8280\n","Epoch 57/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3864 - accuracy: 0.8254\n","Epoch 58/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3596 - accuracy: 0.8317\n","Epoch 59/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3707 - accuracy: 0.8335\n","Epoch 60/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3377 - accuracy: 0.8387\n","Epoch 61/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3689 - accuracy: 0.8264\n","Epoch 62/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3807 - accuracy: 0.8214\n","Epoch 63/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3787 - accuracy: 0.8170\n","Epoch 64/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3609 - accuracy: 0.8403\n","Epoch 65/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3583 - accuracy: 0.8450\n","Epoch 66/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3685 - accuracy: 0.8369\n","Epoch 67/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3658 - accuracy: 0.8306\n","Epoch 68/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3679 - accuracy: 0.8333\n","Epoch 69/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3640 - accuracy: 0.8285\n","Epoch 70/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3684 - accuracy: 0.8288\n","Epoch 71/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3456 - accuracy: 0.8317\n","Epoch 72/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3822 - accuracy: 0.8292\n","Epoch 73/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4107 - accuracy: 0.8357\n","Epoch 74/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3454 - accuracy: 0.8545\n","Epoch 75/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3499 - accuracy: 0.8547\n","Epoch 76/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3368 - accuracy: 0.8585\n","Epoch 77/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3521 - accuracy: 0.8445\n","Epoch 78/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3532 - accuracy: 0.8372\n","Epoch 79/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3409 - accuracy: 0.8517\n","Epoch 80/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3751 - accuracy: 0.8174\n","Epoch 81/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3508 - accuracy: 0.8497\n","Epoch 82/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3355 - accuracy: 0.8479\n","Epoch 83/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3796 - accuracy: 0.8239\n","Epoch 84/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3626 - accuracy: 0.8307\n","Epoch 85/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3381 - accuracy: 0.8486\n","Epoch 86/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3256 - accuracy: 0.8479\n","Epoch 87/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3656 - accuracy: 0.8337\n","Epoch 88/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3262 - accuracy: 0.8530\n","Epoch 89/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3129 - accuracy: 0.8640\n","Epoch 90/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3193 - accuracy: 0.8601\n","Epoch 91/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3456 - accuracy: 0.8535\n","Epoch 92/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3235 - accuracy: 0.8552\n","Epoch 93/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3102 - accuracy: 0.8567\n","Epoch 94/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3368 - accuracy: 0.8489\n","Epoch 95/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3284 - accuracy: 0.8488\n","Epoch 96/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3284 - accuracy: 0.8635\n","Epoch 97/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3625 - accuracy: 0.8316\n","Epoch 98/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3224 - accuracy: 0.8548\n","Epoch 99/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3511 - accuracy: 0.8503\n","Epoch 100/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3188 - accuracy: 0.8675\n","18/18 [==============================] - 1s 38ms/step - loss: 0.9529 - accuracy: 0.7930\n","Validation Accuracy: 79.30%\n","Epoch 1/100\n","173/173 [==============================] - 4s 14ms/step - loss: 0.5594 - accuracy: 0.7336\n","Epoch 2/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.5233 - accuracy: 0.7553\n","Epoch 3/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4815 - accuracy: 0.7881\n","Epoch 4/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4792 - accuracy: 0.7936\n","Epoch 5/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4829 - accuracy: 0.7885\n","Epoch 6/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4898 - accuracy: 0.7745\n","Epoch 7/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4459 - accuracy: 0.8046\n","Epoch 8/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4436 - accuracy: 0.7990\n","Epoch 9/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4601 - accuracy: 0.7993\n","Epoch 10/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4302 - accuracy: 0.8221\n","Epoch 11/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4524 - accuracy: 0.8055\n","Epoch 12/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4296 - accuracy: 0.8149\n","Epoch 13/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4418 - accuracy: 0.7913\n","Epoch 14/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4335 - accuracy: 0.8066\n","Epoch 15/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4349 - accuracy: 0.8026\n","Epoch 16/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4252 - accuracy: 0.8169\n","Epoch 17/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4213 - accuracy: 0.8045\n","Epoch 18/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4090 - accuracy: 0.8200\n","Epoch 19/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3989 - accuracy: 0.8302\n","Epoch 20/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3980 - accuracy: 0.8229\n","Epoch 21/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4219 - accuracy: 0.8111\n","Epoch 22/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3990 - accuracy: 0.8245\n","Epoch 23/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4207 - accuracy: 0.8241\n","Epoch 24/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4278 - accuracy: 0.7985\n","Epoch 25/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3865 - accuracy: 0.8263\n","Epoch 26/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4091 - accuracy: 0.8207\n","Epoch 27/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4110 - accuracy: 0.8127\n","Epoch 28/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3953 - accuracy: 0.8117\n","Epoch 29/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3984 - accuracy: 0.8203\n","Epoch 30/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3978 - accuracy: 0.8080\n","Epoch 31/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4151 - accuracy: 0.8245\n","Epoch 32/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3770 - accuracy: 0.8387\n","Epoch 33/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4012 - accuracy: 0.8253\n","Epoch 34/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3869 - accuracy: 0.8285\n","Epoch 35/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4167 - accuracy: 0.8232\n","Epoch 36/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3927 - accuracy: 0.8235\n","Epoch 37/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3842 - accuracy: 0.8253\n","Epoch 38/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3916 - accuracy: 0.8386\n","Epoch 39/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3669 - accuracy: 0.8415\n","Epoch 40/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3724 - accuracy: 0.8497\n","Epoch 41/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3666 - accuracy: 0.8400\n","Epoch 42/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3852 - accuracy: 0.8331\n","Epoch 43/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3900 - accuracy: 0.8347\n","Epoch 44/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3816 - accuracy: 0.8336\n","Epoch 45/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3822 - accuracy: 0.8162\n","Epoch 46/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3897 - accuracy: 0.8289\n","Epoch 47/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3548 - accuracy: 0.8461\n","Epoch 48/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3735 - accuracy: 0.8210\n","Epoch 49/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3893 - accuracy: 0.8187\n","Epoch 50/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3396 - accuracy: 0.8453\n","Epoch 51/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3728 - accuracy: 0.8265\n","Epoch 52/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3691 - accuracy: 0.8383\n","Epoch 53/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3469 - accuracy: 0.8490\n","Epoch 54/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3566 - accuracy: 0.8526\n","Epoch 55/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3668 - accuracy: 0.8336\n","Epoch 56/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3775 - accuracy: 0.8276\n","Epoch 57/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3357 - accuracy: 0.8497\n","Epoch 58/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3593 - accuracy: 0.8399\n","Epoch 59/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3608 - accuracy: 0.8383\n","Epoch 60/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3602 - accuracy: 0.8339\n","Epoch 61/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3772 - accuracy: 0.8385\n","Epoch 62/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3494 - accuracy: 0.8514\n","Epoch 63/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3259 - accuracy: 0.8455\n","Epoch 64/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3436 - accuracy: 0.8498\n","Epoch 65/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3578 - accuracy: 0.8364\n","Epoch 66/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3559 - accuracy: 0.8441\n","Epoch 67/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3678 - accuracy: 0.8400\n","Epoch 68/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3511 - accuracy: 0.8479\n","Epoch 69/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3305 - accuracy: 0.8586\n","Epoch 70/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3505 - accuracy: 0.8563\n","Epoch 71/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3418 - accuracy: 0.8482\n","Epoch 72/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3237 - accuracy: 0.8556\n","Epoch 73/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3344 - accuracy: 0.8620\n","Epoch 74/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3333 - accuracy: 0.8600\n","Epoch 75/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3121 - accuracy: 0.8534\n","Epoch 76/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3635 - accuracy: 0.8386\n","Epoch 77/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3299 - accuracy: 0.8500\n","Epoch 78/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3326 - accuracy: 0.8498\n","Epoch 79/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3144 - accuracy: 0.8667\n","Epoch 80/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3359 - accuracy: 0.8457\n","Epoch 81/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3154 - accuracy: 0.8684\n","Epoch 82/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3235 - accuracy: 0.8578\n","Epoch 83/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3143 - accuracy: 0.8559\n","Epoch 84/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3395 - accuracy: 0.8483\n","Epoch 85/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3183 - accuracy: 0.8752\n","Epoch 86/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3386 - accuracy: 0.8486\n","Epoch 87/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3405 - accuracy: 0.8601\n","Epoch 88/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3568 - accuracy: 0.8595\n","Epoch 89/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3400 - accuracy: 0.8549\n","Epoch 90/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2840 - accuracy: 0.8816\n","Epoch 91/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3270 - accuracy: 0.8649\n","Epoch 92/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3414 - accuracy: 0.8711\n","Epoch 93/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3402 - accuracy: 0.8648\n","Epoch 94/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3154 - accuracy: 0.8675\n","Epoch 95/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3195 - accuracy: 0.8423\n","Epoch 96/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2986 - accuracy: 0.8724\n","Epoch 97/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3123 - accuracy: 0.8627\n","Epoch 98/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3142 - accuracy: 0.8691\n","Epoch 99/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2899 - accuracy: 0.8773\n","Epoch 100/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3285 - accuracy: 0.8721\n","18/18 [==============================] - 1s 38ms/step - loss: 0.6862 - accuracy: 0.7722\n","Validation Accuracy: 77.22%\n","Epoch 1/100\n","173/173 [==============================] - 4s 15ms/step - loss: 0.5564 - accuracy: 0.7237\n","Epoch 2/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.5267 - accuracy: 0.7484\n","Epoch 3/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4959 - accuracy: 0.7711\n","Epoch 4/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4965 - accuracy: 0.7735\n","Epoch 5/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4745 - accuracy: 0.7820\n","Epoch 6/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4581 - accuracy: 0.8036\n","Epoch 7/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4658 - accuracy: 0.7957\n","Epoch 8/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4682 - accuracy: 0.7830\n","Epoch 9/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4349 - accuracy: 0.8045\n","Epoch 10/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4677 - accuracy: 0.7872\n","Epoch 11/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4362 - accuracy: 0.8092\n","Epoch 12/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4458 - accuracy: 0.7950\n","Epoch 13/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4575 - accuracy: 0.7907\n","Epoch 14/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4349 - accuracy: 0.8068\n","Epoch 15/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4491 - accuracy: 0.8030\n","Epoch 16/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4492 - accuracy: 0.7943\n","Epoch 17/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4262 - accuracy: 0.8008\n","Epoch 18/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4407 - accuracy: 0.7949\n","Epoch 19/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4309 - accuracy: 0.8063\n","Epoch 20/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4406 - accuracy: 0.8054\n","Epoch 21/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4424 - accuracy: 0.7924\n","Epoch 22/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4255 - accuracy: 0.8021\n","Epoch 23/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4484 - accuracy: 0.7988\n","Epoch 24/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3957 - accuracy: 0.8203\n","Epoch 25/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4478 - accuracy: 0.7949\n","Epoch 26/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4368 - accuracy: 0.7973\n","Epoch 27/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4059 - accuracy: 0.8112\n","Epoch 28/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4236 - accuracy: 0.8171\n","Epoch 29/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3828 - accuracy: 0.8308\n","Epoch 30/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4071 - accuracy: 0.8126\n","Epoch 31/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4180 - accuracy: 0.8189\n","Epoch 32/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4176 - accuracy: 0.8142\n","Epoch 33/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4169 - accuracy: 0.7977\n","Epoch 34/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3953 - accuracy: 0.8200\n","Epoch 35/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3952 - accuracy: 0.8226\n","Epoch 36/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4424 - accuracy: 0.7989\n","Epoch 37/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3967 - accuracy: 0.8232\n","Epoch 38/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4058 - accuracy: 0.8028\n","Epoch 39/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3963 - accuracy: 0.8265\n","Epoch 40/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4157 - accuracy: 0.8106\n","Epoch 41/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4096 - accuracy: 0.8163\n","Epoch 42/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4057 - accuracy: 0.8155\n","Epoch 43/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3878 - accuracy: 0.8230\n","Epoch 44/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3818 - accuracy: 0.8299\n","Epoch 45/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3982 - accuracy: 0.8148\n","Epoch 46/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3688 - accuracy: 0.8335\n","Epoch 47/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3889 - accuracy: 0.8131\n","Epoch 48/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3813 - accuracy: 0.8316\n","Epoch 49/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3559 - accuracy: 0.8397\n","Epoch 50/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3696 - accuracy: 0.8421\n","Epoch 51/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4073 - accuracy: 0.8172\n","Epoch 52/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3938 - accuracy: 0.8219\n","Epoch 53/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3434 - accuracy: 0.8574\n","Epoch 54/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3894 - accuracy: 0.8210\n","Epoch 55/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3862 - accuracy: 0.8251\n","Epoch 56/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3775 - accuracy: 0.8266\n","Epoch 57/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3587 - accuracy: 0.8471\n","Epoch 58/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3635 - accuracy: 0.8330\n","Epoch 59/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4031 - accuracy: 0.8203\n","Epoch 60/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3721 - accuracy: 0.8310\n","Epoch 61/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3759 - accuracy: 0.8243\n","Epoch 62/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3684 - accuracy: 0.8331\n","Epoch 63/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3654 - accuracy: 0.8301\n","Epoch 64/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3671 - accuracy: 0.8479\n","Epoch 65/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3703 - accuracy: 0.8404\n","Epoch 66/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3502 - accuracy: 0.8380\n","Epoch 67/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3663 - accuracy: 0.8279\n","Epoch 68/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3474 - accuracy: 0.8497\n","Epoch 69/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3508 - accuracy: 0.8582\n","Epoch 70/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3531 - accuracy: 0.8452\n","Epoch 71/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3469 - accuracy: 0.8480\n","Epoch 72/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3648 - accuracy: 0.8289\n","Epoch 73/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3551 - accuracy: 0.8485\n","Epoch 74/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3848 - accuracy: 0.8416\n","Epoch 75/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3539 - accuracy: 0.8415\n","Epoch 76/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3445 - accuracy: 0.8364\n","Epoch 77/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3297 - accuracy: 0.8576\n","Epoch 78/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3168 - accuracy: 0.8710\n","Epoch 79/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3399 - accuracy: 0.8596\n","Epoch 80/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3587 - accuracy: 0.8516\n","Epoch 81/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3303 - accuracy: 0.8538\n","Epoch 82/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3480 - accuracy: 0.8551\n","Epoch 83/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3203 - accuracy: 0.8569\n","Epoch 84/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3415 - accuracy: 0.8531\n","Epoch 85/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3350 - accuracy: 0.8600\n","Epoch 86/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3249 - accuracy: 0.8567\n","Epoch 87/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3668 - accuracy: 0.8325\n","Epoch 88/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3365 - accuracy: 0.8494\n","Epoch 89/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3170 - accuracy: 0.8718\n","Epoch 90/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3203 - accuracy: 0.8614\n","Epoch 91/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3267 - accuracy: 0.8666\n","Epoch 92/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3098 - accuracy: 0.8667\n","Epoch 93/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3341 - accuracy: 0.8502\n","Epoch 94/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3443 - accuracy: 0.8645\n","Epoch 95/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3083 - accuracy: 0.8636\n","Epoch 96/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3326 - accuracy: 0.8582\n","Epoch 97/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3286 - accuracy: 0.8514\n","Epoch 98/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3289 - accuracy: 0.8634\n","Epoch 99/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2930 - accuracy: 0.8809\n","Epoch 100/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3232 - accuracy: 0.8422\n","18/18 [==============================] - 1s 51ms/step - loss: 0.6045 - accuracy: 0.7770\n","Validation Accuracy: 77.70%\n","Validation Accuracy Mean (+/- Std Deviation): 78.03% (+/- 0.78%)\n","MobileNet XFR Cross Validation Time = 988.1067225933075s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NYvcJG42q0B3"},"source":["#### Fine Tuning"]},{"cell_type":"code","metadata":{"id":"G70qCuZUKG7U","executionInfo":{"status":"ok","timestamp":1611780646758,"user_tz":-330,"elapsed":5328375,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":["# 0 to 72 = Till Conv11\r\n","# 73 to 79 - Conv12\r\n","# 80 to 85 = Conv13\r\n","# 86 to 91 = Post Conv13 before Custom (GAP...)\r\n","# 92 to 94 = Custom (Dense/Dropout/Dense(2)) = Trainable \r\n","for layer in model_mn.layers[:80]:\r\n","    layer.trainable=False\r\n","for layer in model_mn.layers[80:]:\r\n","    layer.trainable=True"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OZZLihxKJWy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611780648092,"user_tz":-330,"elapsed":5329704,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"0f18d9df-cf22-46a9-c8bb-d8a00b4b1125"},"source":["# calculate FLOPS for the model\r\n","flops_mobilenet_ft = get_flops(model_mn, batch_size = 1)\r\n","print(f\"MobileNet FineTune FLOPS: {flops_mobilenet_ft / 10 ** 9:.03} G\")"],"execution_count":96,"outputs":[{"output_type":"stream","text":["MobileNet FineTune FLOPS: 1.15 G\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j9IonOU9v_qG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611780808792,"user_tz":-330,"elapsed":5490400,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"511f59eb-e4b7-4b11-bcda-17b905dd36e6"},"source":["# train and validate model\r\n","path_to_mobilenet_ft_parameters_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_ft.hdf5'\r\n","start_time = time.time()\r\n","hist = model_mn.fit(train_images, train_labels, epochs = EPOCHS, batch_size = BATCH_SIZE, validation_data = (validation_images, validation_labels), callbacks=[checkpoint(path_to_mobilenet_ft_parameters_file)])\r\n","duration = time.time() - start_time\r\n","print(f'MobileNet FT Train Time = {duration}s')"],"execution_count":97,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.4102 - accuracy: 0.8429 - val_loss: 0.3010 - val_accuracy: 0.8877\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.88770, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_ft.hdf5\n","Epoch 2/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3944 - accuracy: 0.8312 - val_loss: 0.2800 - val_accuracy: 0.8904\n","\n","Epoch 00002: val_accuracy improved from 0.88770 to 0.89037, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_ft.hdf5\n","Epoch 3/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3822 - accuracy: 0.8325 - val_loss: 0.3109 - val_accuracy: 0.8824\n","\n","Epoch 00003: val_accuracy did not improve from 0.89037\n","Epoch 4/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3300 - accuracy: 0.8584 - val_loss: 0.3323 - val_accuracy: 0.8503\n","\n","Epoch 00004: val_accuracy did not improve from 0.89037\n","Epoch 5/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3463 - accuracy: 0.8481 - val_loss: 0.2983 - val_accuracy: 0.8957\n","\n","Epoch 00005: val_accuracy improved from 0.89037 to 0.89572, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenet_ft.hdf5\n","Epoch 6/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3452 - accuracy: 0.8429 - val_loss: 0.2930 - val_accuracy: 0.8797\n","\n","Epoch 00006: val_accuracy did not improve from 0.89572\n","Epoch 7/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3175 - accuracy: 0.8584 - val_loss: 0.3193 - val_accuracy: 0.8690\n","\n","Epoch 00007: val_accuracy did not improve from 0.89572\n","Epoch 8/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3308 - accuracy: 0.8416 - val_loss: 0.2808 - val_accuracy: 0.8930\n","\n","Epoch 00008: val_accuracy did not improve from 0.89572\n","Epoch 9/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2988 - accuracy: 0.8714 - val_loss: 0.2798 - val_accuracy: 0.8770\n","\n","Epoch 00009: val_accuracy did not improve from 0.89572\n","Epoch 10/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3277 - accuracy: 0.8558 - val_loss: 0.3169 - val_accuracy: 0.8476\n","\n","Epoch 00010: val_accuracy did not improve from 0.89572\n","Epoch 11/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3385 - accuracy: 0.8468 - val_loss: 0.3018 - val_accuracy: 0.8770\n","\n","Epoch 00011: val_accuracy did not improve from 0.89572\n","Epoch 12/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3008 - accuracy: 0.8753 - val_loss: 0.3011 - val_accuracy: 0.8743\n","\n","Epoch 00012: val_accuracy did not improve from 0.89572\n","Epoch 13/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3339 - accuracy: 0.8455 - val_loss: 0.3203 - val_accuracy: 0.8610\n","\n","Epoch 00013: val_accuracy did not improve from 0.89572\n","Epoch 14/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2982 - accuracy: 0.8766 - val_loss: 0.2933 - val_accuracy: 0.8877\n","\n","Epoch 00014: val_accuracy did not improve from 0.89572\n","Epoch 15/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3213 - accuracy: 0.8571 - val_loss: 0.3082 - val_accuracy: 0.8717\n","\n","Epoch 00015: val_accuracy did not improve from 0.89572\n","Epoch 16/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3032 - accuracy: 0.8701 - val_loss: 0.2984 - val_accuracy: 0.8957\n","\n","Epoch 00016: val_accuracy did not improve from 0.89572\n","Epoch 17/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3394 - accuracy: 0.8377 - val_loss: 0.3241 - val_accuracy: 0.8583\n","\n","Epoch 00017: val_accuracy did not improve from 0.89572\n","Epoch 18/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3086 - accuracy: 0.8688 - val_loss: 0.2847 - val_accuracy: 0.8850\n","\n","Epoch 00018: val_accuracy did not improve from 0.89572\n","Epoch 19/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3058 - accuracy: 0.8727 - val_loss: 0.2912 - val_accuracy: 0.8850\n","\n","Epoch 00019: val_accuracy did not improve from 0.89572\n","Epoch 20/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3198 - accuracy: 0.8623 - val_loss: 0.3026 - val_accuracy: 0.8824\n","\n","Epoch 00020: val_accuracy did not improve from 0.89572\n","Epoch 21/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2893 - accuracy: 0.8727 - val_loss: 0.2846 - val_accuracy: 0.8717\n","\n","Epoch 00021: val_accuracy did not improve from 0.89572\n","Epoch 22/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2935 - accuracy: 0.8831 - val_loss: 0.2943 - val_accuracy: 0.8743\n","\n","Epoch 00022: val_accuracy did not improve from 0.89572\n","Epoch 23/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3058 - accuracy: 0.8662 - val_loss: 0.3188 - val_accuracy: 0.8904\n","\n","Epoch 00023: val_accuracy did not improve from 0.89572\n","Epoch 24/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2942 - accuracy: 0.8779 - val_loss: 0.3200 - val_accuracy: 0.8797\n","\n","Epoch 00024: val_accuracy did not improve from 0.89572\n","Epoch 25/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3064 - accuracy: 0.8714 - val_loss: 0.3213 - val_accuracy: 0.8610\n","\n","Epoch 00025: val_accuracy did not improve from 0.89572\n","Epoch 26/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3098 - accuracy: 0.8831 - val_loss: 0.3245 - val_accuracy: 0.8743\n","\n","Epoch 00026: val_accuracy did not improve from 0.89572\n","Epoch 27/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2964 - accuracy: 0.8753 - val_loss: 0.3080 - val_accuracy: 0.8850\n","\n","Epoch 00027: val_accuracy did not improve from 0.89572\n","Epoch 28/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2885 - accuracy: 0.8688 - val_loss: 0.3233 - val_accuracy: 0.8583\n","\n","Epoch 00028: val_accuracy did not improve from 0.89572\n","Epoch 29/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2770 - accuracy: 0.8727 - val_loss: 0.3015 - val_accuracy: 0.8770\n","\n","Epoch 00029: val_accuracy did not improve from 0.89572\n","Epoch 30/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2770 - accuracy: 0.8805 - val_loss: 0.3062 - val_accuracy: 0.8690\n","\n","Epoch 00030: val_accuracy did not improve from 0.89572\n","Epoch 31/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2891 - accuracy: 0.8740 - val_loss: 0.3149 - val_accuracy: 0.8877\n","\n","Epoch 00031: val_accuracy did not improve from 0.89572\n","Epoch 32/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2979 - accuracy: 0.8753 - val_loss: 0.3221 - val_accuracy: 0.8583\n","\n","Epoch 00032: val_accuracy did not improve from 0.89572\n","Epoch 33/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.3011 - accuracy: 0.8805 - val_loss: 0.3070 - val_accuracy: 0.8717\n","\n","Epoch 00033: val_accuracy did not improve from 0.89572\n","Epoch 34/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2732 - accuracy: 0.8974 - val_loss: 0.3116 - val_accuracy: 0.8770\n","\n","Epoch 00034: val_accuracy did not improve from 0.89572\n","Epoch 35/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2804 - accuracy: 0.8818 - val_loss: 0.3098 - val_accuracy: 0.8743\n","\n","Epoch 00035: val_accuracy did not improve from 0.89572\n","Epoch 36/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3068 - accuracy: 0.8753 - val_loss: 0.3162 - val_accuracy: 0.8717\n","\n","Epoch 00036: val_accuracy did not improve from 0.89572\n","Epoch 37/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2557 - accuracy: 0.8961 - val_loss: 0.3298 - val_accuracy: 0.8610\n","\n","Epoch 00037: val_accuracy did not improve from 0.89572\n","Epoch 38/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2650 - accuracy: 0.8961 - val_loss: 0.3364 - val_accuracy: 0.8636\n","\n","Epoch 00038: val_accuracy did not improve from 0.89572\n","Epoch 39/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2666 - accuracy: 0.8870 - val_loss: 0.3175 - val_accuracy: 0.8636\n","\n","Epoch 00039: val_accuracy did not improve from 0.89572\n","Epoch 40/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2715 - accuracy: 0.8870 - val_loss: 0.3047 - val_accuracy: 0.8770\n","\n","Epoch 00040: val_accuracy did not improve from 0.89572\n","Epoch 41/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2858 - accuracy: 0.8662 - val_loss: 0.3480 - val_accuracy: 0.8476\n","\n","Epoch 00041: val_accuracy did not improve from 0.89572\n","Epoch 42/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2669 - accuracy: 0.8857 - val_loss: 0.3313 - val_accuracy: 0.8690\n","\n","Epoch 00042: val_accuracy did not improve from 0.89572\n","Epoch 43/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2704 - accuracy: 0.8831 - val_loss: 0.3211 - val_accuracy: 0.8770\n","\n","Epoch 00043: val_accuracy did not improve from 0.89572\n","Epoch 44/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2722 - accuracy: 0.8883 - val_loss: 0.3206 - val_accuracy: 0.8663\n","\n","Epoch 00044: val_accuracy did not improve from 0.89572\n","Epoch 45/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2477 - accuracy: 0.8857 - val_loss: 0.3207 - val_accuracy: 0.8770\n","\n","Epoch 00045: val_accuracy did not improve from 0.89572\n","Epoch 46/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2523 - accuracy: 0.8870 - val_loss: 0.3230 - val_accuracy: 0.8663\n","\n","Epoch 00046: val_accuracy did not improve from 0.89572\n","Epoch 47/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2702 - accuracy: 0.8857 - val_loss: 0.3531 - val_accuracy: 0.8529\n","\n","Epoch 00047: val_accuracy did not improve from 0.89572\n","Epoch 48/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2717 - accuracy: 0.8883 - val_loss: 0.3277 - val_accuracy: 0.8663\n","\n","Epoch 00048: val_accuracy did not improve from 0.89572\n","Epoch 49/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2875 - accuracy: 0.8857 - val_loss: 0.3614 - val_accuracy: 0.8690\n","\n","Epoch 00049: val_accuracy did not improve from 0.89572\n","Epoch 50/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2334 - accuracy: 0.9052 - val_loss: 0.3358 - val_accuracy: 0.8583\n","\n","Epoch 00050: val_accuracy did not improve from 0.89572\n","Epoch 51/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2597 - accuracy: 0.8831 - val_loss: 0.3356 - val_accuracy: 0.8717\n","\n","Epoch 00051: val_accuracy did not improve from 0.89572\n","Epoch 52/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2673 - accuracy: 0.8961 - val_loss: 0.3151 - val_accuracy: 0.8770\n","\n","Epoch 00052: val_accuracy did not improve from 0.89572\n","Epoch 53/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2650 - accuracy: 0.8883 - val_loss: 0.3351 - val_accuracy: 0.8797\n","\n","Epoch 00053: val_accuracy did not improve from 0.89572\n","Epoch 54/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2600 - accuracy: 0.8883 - val_loss: 0.3540 - val_accuracy: 0.8663\n","\n","Epoch 00054: val_accuracy did not improve from 0.89572\n","Epoch 55/100\n","77/77 [==============================] - 2s 23ms/step - loss: 0.2426 - accuracy: 0.8935 - val_loss: 0.3707 - val_accuracy: 0.8476\n","\n","Epoch 00055: val_accuracy did not improve from 0.89572\n","Epoch 56/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2727 - accuracy: 0.9013 - val_loss: 0.3430 - val_accuracy: 0.8743\n","\n","Epoch 00056: val_accuracy did not improve from 0.89572\n","Epoch 57/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2638 - accuracy: 0.8831 - val_loss: 0.3580 - val_accuracy: 0.8556\n","\n","Epoch 00057: val_accuracy did not improve from 0.89572\n","Epoch 58/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2370 - accuracy: 0.9026 - val_loss: 0.3540 - val_accuracy: 0.8717\n","\n","Epoch 00058: val_accuracy did not improve from 0.89572\n","Epoch 59/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2629 - accuracy: 0.8896 - val_loss: 0.3251 - val_accuracy: 0.8850\n","\n","Epoch 00059: val_accuracy did not improve from 0.89572\n","Epoch 60/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2382 - accuracy: 0.9013 - val_loss: 0.3438 - val_accuracy: 0.8610\n","\n","Epoch 00060: val_accuracy did not improve from 0.89572\n","Epoch 61/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2517 - accuracy: 0.8883 - val_loss: 0.3620 - val_accuracy: 0.8824\n","\n","Epoch 00061: val_accuracy did not improve from 0.89572\n","Epoch 62/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2565 - accuracy: 0.8935 - val_loss: 0.3446 - val_accuracy: 0.8636\n","\n","Epoch 00062: val_accuracy did not improve from 0.89572\n","Epoch 63/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2591 - accuracy: 0.8974 - val_loss: 0.3409 - val_accuracy: 0.8610\n","\n","Epoch 00063: val_accuracy did not improve from 0.89572\n","Epoch 64/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2822 - accuracy: 0.8844 - val_loss: 0.3933 - val_accuracy: 0.8503\n","\n","Epoch 00064: val_accuracy did not improve from 0.89572\n","Epoch 65/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2504 - accuracy: 0.8935 - val_loss: 0.3927 - val_accuracy: 0.8476\n","\n","Epoch 00065: val_accuracy did not improve from 0.89572\n","Epoch 66/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2531 - accuracy: 0.8909 - val_loss: 0.3568 - val_accuracy: 0.8636\n","\n","Epoch 00066: val_accuracy did not improve from 0.89572\n","Epoch 67/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2377 - accuracy: 0.8896 - val_loss: 0.3440 - val_accuracy: 0.8770\n","\n","Epoch 00067: val_accuracy did not improve from 0.89572\n","Epoch 68/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2689 - accuracy: 0.8948 - val_loss: 0.4033 - val_accuracy: 0.8503\n","\n","Epoch 00068: val_accuracy did not improve from 0.89572\n","Epoch 69/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2501 - accuracy: 0.8896 - val_loss: 0.3591 - val_accuracy: 0.8717\n","\n","Epoch 00069: val_accuracy did not improve from 0.89572\n","Epoch 70/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2529 - accuracy: 0.8974 - val_loss: 0.3564 - val_accuracy: 0.8743\n","\n","Epoch 00070: val_accuracy did not improve from 0.89572\n","Epoch 71/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2457 - accuracy: 0.9091 - val_loss: 0.3529 - val_accuracy: 0.8529\n","\n","Epoch 00071: val_accuracy did not improve from 0.89572\n","Epoch 72/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2382 - accuracy: 0.9078 - val_loss: 0.3369 - val_accuracy: 0.8797\n","\n","Epoch 00072: val_accuracy did not improve from 0.89572\n","Epoch 73/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2539 - accuracy: 0.8896 - val_loss: 0.3390 - val_accuracy: 0.8717\n","\n","Epoch 00073: val_accuracy did not improve from 0.89572\n","Epoch 74/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2469 - accuracy: 0.8883 - val_loss: 0.3834 - val_accuracy: 0.8556\n","\n","Epoch 00074: val_accuracy did not improve from 0.89572\n","Epoch 75/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2422 - accuracy: 0.8974 - val_loss: 0.3923 - val_accuracy: 0.8476\n","\n","Epoch 00075: val_accuracy did not improve from 0.89572\n","Epoch 76/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2409 - accuracy: 0.9000 - val_loss: 0.3611 - val_accuracy: 0.8663\n","\n","Epoch 00076: val_accuracy did not improve from 0.89572\n","Epoch 77/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2270 - accuracy: 0.8909 - val_loss: 0.3451 - val_accuracy: 0.8636\n","\n","Epoch 00077: val_accuracy did not improve from 0.89572\n","Epoch 78/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2265 - accuracy: 0.9039 - val_loss: 0.3895 - val_accuracy: 0.8316\n","\n","Epoch 00078: val_accuracy did not improve from 0.89572\n","Epoch 79/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2319 - accuracy: 0.9117 - val_loss: 0.3535 - val_accuracy: 0.8529\n","\n","Epoch 00079: val_accuracy did not improve from 0.89572\n","Epoch 80/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2326 - accuracy: 0.8974 - val_loss: 0.3973 - val_accuracy: 0.8369\n","\n","Epoch 00080: val_accuracy did not improve from 0.89572\n","Epoch 81/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2216 - accuracy: 0.9104 - val_loss: 0.3736 - val_accuracy: 0.8422\n","\n","Epoch 00081: val_accuracy did not improve from 0.89572\n","Epoch 82/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2326 - accuracy: 0.8987 - val_loss: 0.3701 - val_accuracy: 0.8529\n","\n","Epoch 00082: val_accuracy did not improve from 0.89572\n","Epoch 83/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2191 - accuracy: 0.9104 - val_loss: 0.3558 - val_accuracy: 0.8610\n","\n","Epoch 00083: val_accuracy did not improve from 0.89572\n","Epoch 84/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2259 - accuracy: 0.9013 - val_loss: 0.3632 - val_accuracy: 0.8610\n","\n","Epoch 00084: val_accuracy did not improve from 0.89572\n","Epoch 85/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2619 - accuracy: 0.9065 - val_loss: 0.3648 - val_accuracy: 0.8529\n","\n","Epoch 00085: val_accuracy did not improve from 0.89572\n","Epoch 86/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2339 - accuracy: 0.9026 - val_loss: 0.3738 - val_accuracy: 0.8610\n","\n","Epoch 00086: val_accuracy did not improve from 0.89572\n","Epoch 87/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2229 - accuracy: 0.8974 - val_loss: 0.3966 - val_accuracy: 0.8636\n","\n","Epoch 00087: val_accuracy did not improve from 0.89572\n","Epoch 88/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2334 - accuracy: 0.9156 - val_loss: 0.3611 - val_accuracy: 0.8583\n","\n","Epoch 00088: val_accuracy did not improve from 0.89572\n","Epoch 89/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2443 - accuracy: 0.8987 - val_loss: 0.3795 - val_accuracy: 0.8503\n","\n","Epoch 00089: val_accuracy did not improve from 0.89572\n","Epoch 90/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2221 - accuracy: 0.9039 - val_loss: 0.3701 - val_accuracy: 0.8610\n","\n","Epoch 00090: val_accuracy did not improve from 0.89572\n","Epoch 91/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2146 - accuracy: 0.9000 - val_loss: 0.3742 - val_accuracy: 0.8610\n","\n","Epoch 00091: val_accuracy did not improve from 0.89572\n","Epoch 92/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2297 - accuracy: 0.9039 - val_loss: 0.3465 - val_accuracy: 0.8583\n","\n","Epoch 00092: val_accuracy did not improve from 0.89572\n","Epoch 93/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2313 - accuracy: 0.8961 - val_loss: 0.3654 - val_accuracy: 0.8610\n","\n","Epoch 00093: val_accuracy did not improve from 0.89572\n","Epoch 94/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.3054 - accuracy: 0.9026 - val_loss: 0.3645 - val_accuracy: 0.8583\n","\n","Epoch 00094: val_accuracy did not improve from 0.89572\n","Epoch 95/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2467 - accuracy: 0.9039 - val_loss: 0.3485 - val_accuracy: 0.8610\n","\n","Epoch 00095: val_accuracy did not improve from 0.89572\n","Epoch 96/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2142 - accuracy: 0.9182 - val_loss: 0.3625 - val_accuracy: 0.8636\n","\n","Epoch 00096: val_accuracy did not improve from 0.89572\n","Epoch 97/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2633 - accuracy: 0.8974 - val_loss: 0.3902 - val_accuracy: 0.8690\n","\n","Epoch 00097: val_accuracy did not improve from 0.89572\n","Epoch 98/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2281 - accuracy: 0.9091 - val_loss: 0.4078 - val_accuracy: 0.8449\n","\n","Epoch 00098: val_accuracy did not improve from 0.89572\n","Epoch 99/100\n","77/77 [==============================] - 2s 21ms/step - loss: 0.2061 - accuracy: 0.9130 - val_loss: 0.3544 - val_accuracy: 0.8610\n","\n","Epoch 00099: val_accuracy did not improve from 0.89572\n","Epoch 100/100\n","77/77 [==============================] - 2s 20ms/step - loss: 0.2093 - accuracy: 0.9078 - val_loss: 0.3823 - val_accuracy: 0.8476\n","\n","Epoch 00100: val_accuracy did not improve from 0.89572\n","MobileNet FT Train Time = 160.71819162368774s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"obaPSuIwGA_R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611780814156,"user_tz":-330,"elapsed":5495757,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"20477c6a-43c0-4afd-ce57-796d016071bc"},"source":["# test with best model\r\n","#model_mn.load_weights('/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_model.hdf5')\r\n","model_mn.load_weights(path_to_mobilenet_ft_parameters_file)\r\n","# test_predict = model_mn.predict(test_images, batch_size=10, verbose=0)\r\n","start_time = time.time()\r\n","test_loss_mn, test_acc_mn = model_mn.evaluate(test_images, test_labels)\r\n","duration = time.time() - start_time\r\n","print(f'MobileNet FT Test Time = {duration}s')\r\n","print(f'MobileNet FT Test Time / sample = {duration/1155}s')"],"execution_count":98,"outputs":[{"output_type":"stream","text":["37/37 [==============================] - 1s 38ms/step - loss: 0.4008 - accuracy: 0.8364\n","MobileNet FT Test Time = 1.453615665435791s\n","MobileNet FT Test Time / sample = 0.0012585417016760096s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zojdt5YN6kxP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611781806604,"user_tz":-330,"elapsed":6488201,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"5e2642f9-4b27-495e-abac-1a167f68cab4"},"source":["start_time = time.time()\r\n","# perform cross validation\r\n","if (CROSS_VALIDATE == True):\r\n","  # import libraries\r\n","  from sklearn.model_selection import StratifiedKFold\r\n","  # using stratifiedkfold so that we have balanced classes in each split\r\n","  cvfold = StratifiedKFold(n_splits = CROSS_VALIDATION_FOLDS, shuffle = True)\r\n","  # we will use below to store all individual validation scores\r\n","  cvscores = []\r\n","  # based on the class value, get the split done and respective train and test index\r\n","  for train_index, val_index in cvfold.split(all_images, all_labels_before_categorical):\r\n","    # model definition as is from top - starts\r\n","    # mobilenet = tf.keras.applications.mobilenet.MobileNet()\r\n","    mobilenet = tf.keras.applications.MobileNet()\r\n","    prediction_mn = mobilenet.output\r\n","    prediction_mn = Dense(DENSE_LAYER_NEURONS, activation = 'relu')(prediction_mn)\r\n","    prediction_mn = Dropout(DENSE_LAYER_DROPOUT)(prediction_mn)\r\n","    prediction_mn = Dense(2, activation = 'softmax')(prediction_mn)\r\n","    model_mn = Model(inputs = mobilenet.input, outputs = prediction_mn)\r\n","    for layer in mobilenet.layers:\r\n","      layer.trainable = False\r\n","    model_mn.compile(optimizer = Adam(lr=LEARNING_RATE), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n","    # note using the file from transfer and not from finetune to load the weights\r\n","    model_mn.load_weights(path_to_mobilenet_xfr_parameters_file)\r\n","    for layer in model_mn.layers[:80]:\r\n","      layer.trainable=False\r\n","    for layer in model_mn.layers[80:]:\r\n","      layer.trainable=True\r\n","    # model definition as is from top - ends\r\n","    # train based on train index elements\r\n","    model_mn.fit(all_images[train_index], all_labels[train_index], epochs = EPOCHS, batch_size = BATCH_SIZE) \r\n","    # validate based on validation index elements\r\n","    cv_score = model_mn.evaluate(all_images[val_index], all_labels[val_index])\r\n","    print(\"Validation Accuracy: %0.2f%%\" % (cv_score[1]*100))\r\n","    # append each iteration validation accuracy score\r\n","    cvscores.append(cv_score[1]*100)\r\n","  # print mean and std deviation of the validation accuracy for the complete cross validation i.e. for all iterations\r\n","  print(\"Validation Accuracy Mean (+/- Std Deviation): %0.2f%% (+/- %0.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\r\n","duration = time.time() - start_time\r\n","print(f'MobileNet FT Cross Validation Time = {duration}s')"],"execution_count":99,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","173/173 [==============================] - 4s 14ms/step - loss: 0.4600 - accuracy: 0.8029\n","Epoch 2/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.5122 - accuracy: 0.7723\n","Epoch 3/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4377 - accuracy: 0.8081\n","Epoch 4/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4385 - accuracy: 0.8028\n","Epoch 5/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4453 - accuracy: 0.8036\n","Epoch 6/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4440 - accuracy: 0.8059\n","Epoch 7/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4362 - accuracy: 0.8083\n","Epoch 8/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4230 - accuracy: 0.8259\n","Epoch 9/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4050 - accuracy: 0.8293\n","Epoch 10/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4289 - accuracy: 0.8008\n","Epoch 11/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4093 - accuracy: 0.8193\n","Epoch 12/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4289 - accuracy: 0.8037\n","Epoch 13/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4085 - accuracy: 0.8203\n","Epoch 14/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4045 - accuracy: 0.8205\n","Epoch 15/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3993 - accuracy: 0.8244\n","Epoch 16/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4129 - accuracy: 0.8119\n","Epoch 17/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4294 - accuracy: 0.8175\n","Epoch 18/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3978 - accuracy: 0.8201\n","Epoch 19/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4124 - accuracy: 0.8170\n","Epoch 20/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4023 - accuracy: 0.8271\n","Epoch 21/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4034 - accuracy: 0.8197\n","Epoch 22/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3985 - accuracy: 0.8160\n","Epoch 23/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3915 - accuracy: 0.8191\n","Epoch 24/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3822 - accuracy: 0.8330\n","Epoch 25/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3778 - accuracy: 0.8347\n","Epoch 26/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3938 - accuracy: 0.8253\n","Epoch 27/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4107 - accuracy: 0.8328\n","Epoch 28/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3804 - accuracy: 0.8292\n","Epoch 29/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3825 - accuracy: 0.8322\n","Epoch 30/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3646 - accuracy: 0.8388\n","Epoch 31/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3834 - accuracy: 0.8318\n","Epoch 32/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4178 - accuracy: 0.8104\n","Epoch 33/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3814 - accuracy: 0.8268\n","Epoch 34/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3706 - accuracy: 0.8424\n","Epoch 35/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3961 - accuracy: 0.8233\n","Epoch 36/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3635 - accuracy: 0.8402\n","Epoch 37/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3555 - accuracy: 0.8405\n","Epoch 38/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3732 - accuracy: 0.8398\n","Epoch 39/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3706 - accuracy: 0.8448\n","Epoch 40/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3671 - accuracy: 0.8442\n","Epoch 41/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4014 - accuracy: 0.8395\n","Epoch 42/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3761 - accuracy: 0.8376\n","Epoch 43/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3679 - accuracy: 0.8377\n","Epoch 44/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3453 - accuracy: 0.8422\n","Epoch 45/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3695 - accuracy: 0.8322\n","Epoch 46/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3710 - accuracy: 0.8324\n","Epoch 47/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3759 - accuracy: 0.8222\n","Epoch 48/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3688 - accuracy: 0.8309\n","Epoch 49/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3568 - accuracy: 0.8380\n","Epoch 50/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3609 - accuracy: 0.8513\n","Epoch 51/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3462 - accuracy: 0.8400\n","Epoch 52/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3474 - accuracy: 0.8601\n","Epoch 53/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3545 - accuracy: 0.8571\n","Epoch 54/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3464 - accuracy: 0.8585\n","Epoch 55/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3618 - accuracy: 0.8447\n","Epoch 56/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3430 - accuracy: 0.8522\n","Epoch 57/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3560 - accuracy: 0.8378\n","Epoch 58/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3303 - accuracy: 0.8627\n","Epoch 59/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3291 - accuracy: 0.8633\n","Epoch 60/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3337 - accuracy: 0.8533\n","Epoch 61/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3625 - accuracy: 0.8359\n","Epoch 62/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3363 - accuracy: 0.8521\n","Epoch 63/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3496 - accuracy: 0.8512\n","Epoch 64/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3532 - accuracy: 0.8527\n","Epoch 65/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3061 - accuracy: 0.8740\n","Epoch 66/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3121 - accuracy: 0.8765\n","Epoch 67/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3445 - accuracy: 0.8566\n","Epoch 68/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3543 - accuracy: 0.8546\n","Epoch 69/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3205 - accuracy: 0.8625\n","Epoch 70/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3203 - accuracy: 0.8691\n","Epoch 71/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3580 - accuracy: 0.8422\n","Epoch 72/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3487 - accuracy: 0.8545\n","Epoch 73/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3475 - accuracy: 0.8462\n","Epoch 74/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3467 - accuracy: 0.8428\n","Epoch 75/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3326 - accuracy: 0.8630\n","Epoch 76/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3325 - accuracy: 0.8569\n","Epoch 77/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3248 - accuracy: 0.8514\n","Epoch 78/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3406 - accuracy: 0.8527\n","Epoch 79/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3552 - accuracy: 0.8363\n","Epoch 80/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3203 - accuracy: 0.8600\n","Epoch 81/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3138 - accuracy: 0.8661\n","Epoch 82/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3301 - accuracy: 0.8609\n","Epoch 83/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3121 - accuracy: 0.8710\n","Epoch 84/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2978 - accuracy: 0.8883\n","Epoch 85/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3367 - accuracy: 0.8527\n","Epoch 86/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3032 - accuracy: 0.8769\n","Epoch 87/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2983 - accuracy: 0.8779\n","Epoch 88/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3070 - accuracy: 0.8687\n","Epoch 89/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2935 - accuracy: 0.8781\n","Epoch 90/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2854 - accuracy: 0.8723\n","Epoch 91/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3160 - accuracy: 0.8623\n","Epoch 92/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2902 - accuracy: 0.8585\n","Epoch 93/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3093 - accuracy: 0.8731\n","Epoch 94/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3163 - accuracy: 0.8544\n","Epoch 95/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3143 - accuracy: 0.8680\n","Epoch 96/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3041 - accuracy: 0.8704\n","Epoch 97/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2917 - accuracy: 0.8808\n","Epoch 98/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3113 - accuracy: 0.8688\n","Epoch 99/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3123 - accuracy: 0.8570\n","Epoch 100/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3112 - accuracy: 0.8748\n","18/18 [==============================] - 1s 38ms/step - loss: 0.5408 - accuracy: 0.7652\n","Validation Accuracy: 76.52%\n","Epoch 1/100\n","173/173 [==============================] - 4s 14ms/step - loss: 0.4786 - accuracy: 0.8003\n","Epoch 2/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4729 - accuracy: 0.7808\n","Epoch 3/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4261 - accuracy: 0.8168\n","Epoch 4/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4390 - accuracy: 0.8050\n","Epoch 5/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3951 - accuracy: 0.8311\n","Epoch 6/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4261 - accuracy: 0.8111\n","Epoch 7/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4439 - accuracy: 0.8042\n","Epoch 8/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4329 - accuracy: 0.8023\n","Epoch 9/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4069 - accuracy: 0.8037\n","Epoch 10/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4116 - accuracy: 0.8229\n","Epoch 11/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4246 - accuracy: 0.8092\n","Epoch 12/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4135 - accuracy: 0.8016\n","Epoch 13/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3965 - accuracy: 0.8181\n","Epoch 14/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4058 - accuracy: 0.8089\n","Epoch 15/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4079 - accuracy: 0.8145\n","Epoch 16/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4075 - accuracy: 0.8208\n","Epoch 17/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4305 - accuracy: 0.7978\n","Epoch 18/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4046 - accuracy: 0.8199\n","Epoch 19/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3974 - accuracy: 0.8144\n","Epoch 20/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4129 - accuracy: 0.8089\n","Epoch 21/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4225 - accuracy: 0.8096\n","Epoch 22/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4206 - accuracy: 0.8131\n","Epoch 23/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3935 - accuracy: 0.8160\n","Epoch 24/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3970 - accuracy: 0.8029\n","Epoch 25/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3746 - accuracy: 0.8261\n","Epoch 26/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3698 - accuracy: 0.8361\n","Epoch 27/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3996 - accuracy: 0.8127\n","Epoch 28/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3881 - accuracy: 0.8098\n","Epoch 29/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3612 - accuracy: 0.8422\n","Epoch 30/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3784 - accuracy: 0.8110\n","Epoch 31/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3870 - accuracy: 0.8134\n","Epoch 32/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3734 - accuracy: 0.8432\n","Epoch 33/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3678 - accuracy: 0.8423\n","Epoch 34/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3893 - accuracy: 0.8142\n","Epoch 35/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3689 - accuracy: 0.8239\n","Epoch 36/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3677 - accuracy: 0.8373\n","Epoch 37/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3607 - accuracy: 0.8395\n","Epoch 38/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3594 - accuracy: 0.8460\n","Epoch 39/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3528 - accuracy: 0.8346\n","Epoch 40/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3459 - accuracy: 0.8605\n","Epoch 41/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3556 - accuracy: 0.8480\n","Epoch 42/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3632 - accuracy: 0.8267\n","Epoch 43/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3525 - accuracy: 0.8465\n","Epoch 44/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3351 - accuracy: 0.8562\n","Epoch 45/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3535 - accuracy: 0.8387\n","Epoch 46/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3387 - accuracy: 0.8531\n","Epoch 47/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3677 - accuracy: 0.8226\n","Epoch 48/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3788 - accuracy: 0.8186\n","Epoch 49/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3667 - accuracy: 0.8330\n","Epoch 50/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3360 - accuracy: 0.8544\n","Epoch 51/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3563 - accuracy: 0.8473\n","Epoch 52/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3532 - accuracy: 0.8485\n","Epoch 53/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3472 - accuracy: 0.8508\n","Epoch 54/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3237 - accuracy: 0.8523\n","Epoch 55/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3333 - accuracy: 0.8496\n","Epoch 56/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3356 - accuracy: 0.8338\n","Epoch 57/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3773 - accuracy: 0.8353\n","Epoch 58/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3429 - accuracy: 0.8462\n","Epoch 59/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3453 - accuracy: 0.8368\n","Epoch 60/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3271 - accuracy: 0.8459\n","Epoch 61/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3629 - accuracy: 0.8362\n","Epoch 62/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3349 - accuracy: 0.8535\n","Epoch 63/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3114 - accuracy: 0.8584\n","Epoch 64/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3375 - accuracy: 0.8426\n","Epoch 65/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3080 - accuracy: 0.8698\n","Epoch 66/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3086 - accuracy: 0.8590\n","Epoch 67/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3478 - accuracy: 0.8523\n","Epoch 68/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3289 - accuracy: 0.8541\n","Epoch 69/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3294 - accuracy: 0.8595\n","Epoch 70/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3422 - accuracy: 0.8422\n","Epoch 71/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3009 - accuracy: 0.8683\n","Epoch 72/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3143 - accuracy: 0.8663\n","Epoch 73/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3399 - accuracy: 0.8489\n","Epoch 74/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3182 - accuracy: 0.8557\n","Epoch 75/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3062 - accuracy: 0.8512\n","Epoch 76/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3225 - accuracy: 0.8379\n","Epoch 77/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2995 - accuracy: 0.8656\n","Epoch 78/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3079 - accuracy: 0.8714\n","Epoch 79/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2988 - accuracy: 0.8686\n","Epoch 80/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3462 - accuracy: 0.8433\n","Epoch 81/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3184 - accuracy: 0.8629\n","Epoch 82/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2962 - accuracy: 0.8703\n","Epoch 83/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3110 - accuracy: 0.8664\n","Epoch 84/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2909 - accuracy: 0.8597\n","Epoch 85/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3148 - accuracy: 0.8694\n","Epoch 86/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3006 - accuracy: 0.8715\n","Epoch 87/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3158 - accuracy: 0.8493\n","Epoch 88/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2981 - accuracy: 0.8693\n","Epoch 89/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2887 - accuracy: 0.8721\n","Epoch 90/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3225 - accuracy: 0.8540\n","Epoch 91/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3096 - accuracy: 0.8784\n","Epoch 92/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3024 - accuracy: 0.8582\n","Epoch 93/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3150 - accuracy: 0.8577\n","Epoch 94/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3091 - accuracy: 0.8662\n","Epoch 95/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3002 - accuracy: 0.8636\n","Epoch 96/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2644 - accuracy: 0.8851\n","Epoch 97/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2834 - accuracy: 0.8798\n","Epoch 98/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2798 - accuracy: 0.8785\n","Epoch 99/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3022 - accuracy: 0.8723\n","Epoch 100/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2749 - accuracy: 0.8852\n","18/18 [==============================] - 1s 38ms/step - loss: 0.6686 - accuracy: 0.7913\n","Validation Accuracy: 79.13%\n","Epoch 1/100\n","173/173 [==============================] - 4s 14ms/step - loss: 0.4920 - accuracy: 0.7967\n","Epoch 2/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4572 - accuracy: 0.7769\n","Epoch 3/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4350 - accuracy: 0.7889\n","Epoch 4/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4037 - accuracy: 0.8238\n","Epoch 5/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4404 - accuracy: 0.7997\n","Epoch 6/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4465 - accuracy: 0.7923\n","Epoch 7/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4473 - accuracy: 0.8048\n","Epoch 8/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4016 - accuracy: 0.8147\n","Epoch 9/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3946 - accuracy: 0.8264\n","Epoch 10/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4156 - accuracy: 0.8104\n","Epoch 11/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4321 - accuracy: 0.8153\n","Epoch 12/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3978 - accuracy: 0.8168\n","Epoch 13/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4095 - accuracy: 0.8042\n","Epoch 14/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4336 - accuracy: 0.8113\n","Epoch 15/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4268 - accuracy: 0.7995\n","Epoch 16/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4060 - accuracy: 0.8148\n","Epoch 17/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4372 - accuracy: 0.8032\n","Epoch 18/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3745 - accuracy: 0.8251\n","Epoch 19/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3919 - accuracy: 0.8108\n","Epoch 20/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3964 - accuracy: 0.8246\n","Epoch 21/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3818 - accuracy: 0.8351\n","Epoch 22/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4039 - accuracy: 0.8107\n","Epoch 23/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3796 - accuracy: 0.8218\n","Epoch 24/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3749 - accuracy: 0.8451\n","Epoch 25/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3640 - accuracy: 0.8387\n","Epoch 26/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3877 - accuracy: 0.8294\n","Epoch 27/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3812 - accuracy: 0.8333\n","Epoch 28/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3736 - accuracy: 0.8175\n","Epoch 29/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3842 - accuracy: 0.8338\n","Epoch 30/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3834 - accuracy: 0.8319\n","Epoch 31/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3588 - accuracy: 0.8353\n","Epoch 32/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3835 - accuracy: 0.8209\n","Epoch 33/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3737 - accuracy: 0.8347\n","Epoch 34/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3701 - accuracy: 0.8269\n","Epoch 35/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3657 - accuracy: 0.8412\n","Epoch 36/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3480 - accuracy: 0.8583\n","Epoch 37/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3476 - accuracy: 0.8497\n","Epoch 38/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3778 - accuracy: 0.8261\n","Epoch 39/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3912 - accuracy: 0.8156\n","Epoch 40/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3642 - accuracy: 0.8557\n","Epoch 41/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3490 - accuracy: 0.8380\n","Epoch 42/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3401 - accuracy: 0.8466\n","Epoch 43/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3601 - accuracy: 0.8390\n","Epoch 44/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3521 - accuracy: 0.8547\n","Epoch 45/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3796 - accuracy: 0.8341\n","Epoch 46/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3552 - accuracy: 0.8390\n","Epoch 47/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3513 - accuracy: 0.8425\n","Epoch 48/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3405 - accuracy: 0.8423\n","Epoch 49/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3379 - accuracy: 0.8583\n","Epoch 50/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3283 - accuracy: 0.8545\n","Epoch 51/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3504 - accuracy: 0.8559\n","Epoch 52/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3470 - accuracy: 0.8645\n","Epoch 53/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3481 - accuracy: 0.8492\n","Epoch 54/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3176 - accuracy: 0.8523\n","Epoch 55/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3560 - accuracy: 0.8395\n","Epoch 56/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3533 - accuracy: 0.8411\n","Epoch 57/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3271 - accuracy: 0.8610\n","Epoch 58/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3272 - accuracy: 0.8515\n","Epoch 59/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3202 - accuracy: 0.8549\n","Epoch 60/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3326 - accuracy: 0.8531\n","Epoch 61/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3395 - accuracy: 0.8334\n","Epoch 62/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3184 - accuracy: 0.8599\n","Epoch 63/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3385 - accuracy: 0.8490\n","Epoch 64/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3535 - accuracy: 0.8372\n","Epoch 65/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3089 - accuracy: 0.8551\n","Epoch 66/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3180 - accuracy: 0.8638\n","Epoch 67/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3007 - accuracy: 0.8750\n","Epoch 68/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3276 - accuracy: 0.8570\n","Epoch 69/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3105 - accuracy: 0.8638\n","Epoch 70/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3063 - accuracy: 0.8629\n","Epoch 71/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3206 - accuracy: 0.8663\n","Epoch 72/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3201 - accuracy: 0.8504\n","Epoch 73/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3062 - accuracy: 0.8678\n","Epoch 74/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3155 - accuracy: 0.8583\n","Epoch 75/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3161 - accuracy: 0.8544\n","Epoch 76/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.2953 - accuracy: 0.8665\n","Epoch 77/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3139 - accuracy: 0.8558\n","Epoch 78/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3334 - accuracy: 0.8639\n","Epoch 79/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3022 - accuracy: 0.8704\n","Epoch 80/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2875 - accuracy: 0.8847\n","Epoch 81/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3287 - accuracy: 0.8559\n","Epoch 82/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3367 - accuracy: 0.8457\n","Epoch 83/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3101 - accuracy: 0.8544\n","Epoch 84/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.2987 - accuracy: 0.8712\n","Epoch 85/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3180 - accuracy: 0.8576\n","Epoch 86/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3189 - accuracy: 0.8477\n","Epoch 87/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.2816 - accuracy: 0.8753\n","Epoch 88/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3281 - accuracy: 0.8590\n","Epoch 89/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3043 - accuracy: 0.8721\n","Epoch 90/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.2815 - accuracy: 0.8812\n","Epoch 91/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3081 - accuracy: 0.8694\n","Epoch 92/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.2850 - accuracy: 0.8706\n","Epoch 93/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2915 - accuracy: 0.8750\n","Epoch 94/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3024 - accuracy: 0.8644\n","Epoch 95/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2787 - accuracy: 0.8721\n","Epoch 96/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.2788 - accuracy: 0.8765\n","Epoch 97/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2970 - accuracy: 0.8651\n","Epoch 98/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2977 - accuracy: 0.8633\n","Epoch 99/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3092 - accuracy: 0.8702\n","Epoch 100/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2830 - accuracy: 0.8762\n","18/18 [==============================] - 1s 39ms/step - loss: 0.6536 - accuracy: 0.8000\n","Validation Accuracy: 80.00%\n","Epoch 1/100\n","173/173 [==============================] - 4s 15ms/step - loss: 0.4919 - accuracy: 0.7865\n","Epoch 2/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4930 - accuracy: 0.7990\n","Epoch 3/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4519 - accuracy: 0.8104\n","Epoch 4/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4429 - accuracy: 0.8147\n","Epoch 5/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4366 - accuracy: 0.7925\n","Epoch 6/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4300 - accuracy: 0.8254\n","Epoch 7/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4362 - accuracy: 0.8060\n","Epoch 8/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4199 - accuracy: 0.7939\n","Epoch 9/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4342 - accuracy: 0.8020\n","Epoch 10/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4245 - accuracy: 0.8031\n","Epoch 11/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4176 - accuracy: 0.8097\n","Epoch 12/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4289 - accuracy: 0.7999\n","Epoch 13/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4317 - accuracy: 0.8127\n","Epoch 14/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4104 - accuracy: 0.8132\n","Epoch 15/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4093 - accuracy: 0.8274\n","Epoch 16/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4140 - accuracy: 0.8025\n","Epoch 17/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3992 - accuracy: 0.8374\n","Epoch 18/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4117 - accuracy: 0.8071\n","Epoch 19/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4104 - accuracy: 0.8193\n","Epoch 20/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3945 - accuracy: 0.8206\n","Epoch 21/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.4074 - accuracy: 0.8219\n","Epoch 22/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4011 - accuracy: 0.8182\n","Epoch 23/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4182 - accuracy: 0.8034\n","Epoch 24/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.4042 - accuracy: 0.8126\n","Epoch 25/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3809 - accuracy: 0.8321\n","Epoch 26/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3882 - accuracy: 0.8211\n","Epoch 27/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3932 - accuracy: 0.8155\n","Epoch 28/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3865 - accuracy: 0.8316\n","Epoch 29/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3887 - accuracy: 0.8233\n","Epoch 30/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3869 - accuracy: 0.8258\n","Epoch 31/100\n","173/173 [==============================] - 3s 15ms/step - loss: 0.3601 - accuracy: 0.8505\n","Epoch 32/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3836 - accuracy: 0.8231\n","Epoch 33/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3662 - accuracy: 0.8469\n","Epoch 34/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3545 - accuracy: 0.8461\n","Epoch 35/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3727 - accuracy: 0.8427\n","Epoch 36/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3752 - accuracy: 0.8314\n","Epoch 37/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3704 - accuracy: 0.8309\n","Epoch 38/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3531 - accuracy: 0.8508\n","Epoch 39/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3479 - accuracy: 0.8432\n","Epoch 40/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3722 - accuracy: 0.8359\n","Epoch 41/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3396 - accuracy: 0.8471\n","Epoch 42/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3799 - accuracy: 0.8347\n","Epoch 43/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3679 - accuracy: 0.8377\n","Epoch 44/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3503 - accuracy: 0.8472\n","Epoch 45/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3554 - accuracy: 0.8461\n","Epoch 46/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3605 - accuracy: 0.8418\n","Epoch 47/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3507 - accuracy: 0.8531\n","Epoch 48/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3505 - accuracy: 0.8474\n","Epoch 49/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3542 - accuracy: 0.8531\n","Epoch 50/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3444 - accuracy: 0.8618\n","Epoch 51/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3293 - accuracy: 0.8602\n","Epoch 52/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3392 - accuracy: 0.8434\n","Epoch 53/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3526 - accuracy: 0.8461\n","Epoch 54/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3369 - accuracy: 0.8561\n","Epoch 55/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3498 - accuracy: 0.8402\n","Epoch 56/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3451 - accuracy: 0.8493\n","Epoch 57/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3410 - accuracy: 0.8497\n","Epoch 58/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3533 - accuracy: 0.8492\n","Epoch 59/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3354 - accuracy: 0.8639\n","Epoch 60/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3354 - accuracy: 0.8553\n","Epoch 61/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3323 - accuracy: 0.8556\n","Epoch 62/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3530 - accuracy: 0.8495\n","Epoch 63/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3067 - accuracy: 0.8635\n","Epoch 64/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3310 - accuracy: 0.8497\n","Epoch 65/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2993 - accuracy: 0.8795\n","Epoch 66/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3359 - accuracy: 0.8666\n","Epoch 67/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2967 - accuracy: 0.8746\n","Epoch 68/100\n","173/173 [==============================] - 3s 14ms/step - loss: 0.3346 - accuracy: 0.8551\n","Epoch 69/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3324 - accuracy: 0.8676\n","Epoch 70/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3211 - accuracy: 0.8655\n","Epoch 71/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3232 - accuracy: 0.8470\n","Epoch 72/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3165 - accuracy: 0.8731\n","Epoch 73/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3138 - accuracy: 0.8675\n","Epoch 74/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3435 - accuracy: 0.8567\n","Epoch 75/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3333 - accuracy: 0.8533\n","Epoch 76/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3241 - accuracy: 0.8589\n","Epoch 77/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3291 - accuracy: 0.8580\n","Epoch 78/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3233 - accuracy: 0.8547\n","Epoch 79/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3405 - accuracy: 0.8623\n","Epoch 80/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2714 - accuracy: 0.8813\n","Epoch 81/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3108 - accuracy: 0.8743\n","Epoch 82/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3142 - accuracy: 0.8623\n","Epoch 83/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3144 - accuracy: 0.8698\n","Epoch 84/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2951 - accuracy: 0.8621\n","Epoch 85/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3257 - accuracy: 0.8764\n","Epoch 86/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2948 - accuracy: 0.8780\n","Epoch 87/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3120 - accuracy: 0.8708\n","Epoch 88/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2900 - accuracy: 0.8772\n","Epoch 89/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3090 - accuracy: 0.8721\n","Epoch 90/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2969 - accuracy: 0.8794\n","Epoch 91/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2701 - accuracy: 0.8879\n","Epoch 92/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3099 - accuracy: 0.8734\n","Epoch 93/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3050 - accuracy: 0.8745\n","Epoch 94/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2983 - accuracy: 0.8770\n","Epoch 95/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3034 - accuracy: 0.8672\n","Epoch 96/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2948 - accuracy: 0.8758\n","Epoch 97/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2951 - accuracy: 0.8808\n","Epoch 98/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3032 - accuracy: 0.8644\n","Epoch 99/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.2983 - accuracy: 0.8646\n","Epoch 100/100\n","173/173 [==============================] - 2s 14ms/step - loss: 0.3259 - accuracy: 0.8760\n","18/18 [==============================] - 1s 39ms/step - loss: 0.5838 - accuracy: 0.7753\n","Validation Accuracy: 77.53%\n","Validation Accuracy Mean (+/- Std Deviation): 78.29% (+/- 1.35%)\n","MobileNet FT Cross Validation Time = 992.2293410301208s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S9skg_wshQUz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611781806607,"user_tz":-330,"elapsed":6488199,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}},"outputId":"74a1da45-fe1c-4c9c-e784-c43fa5570a20"},"source":["model_mn.summary()"],"execution_count":100,"outputs":[{"output_type":"stream","text":["Model: \"model_13\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_14 (InputLayer)        [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","conv1 (Conv2D)               (None, 112, 112, 32)      864       \n","_________________________________________________________________\n","conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n","_________________________________________________________________\n","conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n","_________________________________________________________________\n","conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n","_________________________________________________________________\n","conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n","_________________________________________________________________\n","conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n","_________________________________________________________________\n","conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n","_________________________________________________________________\n","conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n","_________________________________________________________________\n","conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n","_________________________________________________________________\n","conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n","_________________________________________________________________\n","conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n","_________________________________________________________________\n","conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n","_________________________________________________________________\n","conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n","_________________________________________________________________\n","conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n","_________________________________________________________________\n","conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n","_________________________________________________________________\n","conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n","_________________________________________________________________\n","conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n","_________________________________________________________________\n","conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n","_________________________________________________________________\n","conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n","_________________________________________________________________\n","conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n","_________________________________________________________________\n","conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n","_________________________________________________________________\n","conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n","_________________________________________________________________\n","conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n","_________________________________________________________________\n","conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n","_________________________________________________________________\n","conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n","_________________________________________________________________\n","conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n","_________________________________________________________________\n","conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n","_________________________________________________________________\n","conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n","_________________________________________________________________\n","conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n","_________________________________________________________________\n","conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n","_________________________________________________________________\n","conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n","_________________________________________________________________\n","conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n","_________________________________________________________________\n","conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n","_________________________________________________________________\n","conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n","_________________________________________________________________\n","conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n","_________________________________________________________________\n","conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n","_________________________________________________________________\n","conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n","_________________________________________________________________\n","conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n","_________________________________________________________________\n","global_average_pooling2d_13  (None, 1024)              0         \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 1, 1, 1024)        0         \n","_________________________________________________________________\n","conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n","_________________________________________________________________\n","reshape_2 (Reshape)          (None, 1000)              0         \n","_________________________________________________________________\n","predictions (Activation)     (None, 1000)              0         \n","_________________________________________________________________\n","dense_26 (Dense)             (None, 512)               512512    \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_27 (Dense)             (None, 2)                 1026      \n","=================================================================\n","Total params: 4,767,402\n","Trainable params: 2,600,426\n","Non-trainable params: 2,166,976\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d-G5EELce9gf"},"source":["### SqueezeNet"]},{"cell_type":"markdown","metadata":{"id":"ibaKV-lrrYcl"},"source":["will continue on SqueezeNet as future work."]},{"cell_type":"code","metadata":{"id":"xLfL4akBrhEN","executionInfo":{"status":"ok","timestamp":1611781806608,"user_tz":-330,"elapsed":6488196,"user":{"displayName":"C Hota","photoUrl":"","userId":"00886477891728754612"}}},"source":[""],"execution_count":100,"outputs":[]}]}