{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "accelerator": "GPU",
    "colab": {
      "name": "HE_v0_28.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MBUEnaGfcVYx",
        "I6pKmozJpWkF",
        "a9LFF-vOo6t0",
        "GuVfy-J79VSx",
        "X4BaEWfpoq28",
        "DoV84asAovk9",
        "GlW_uOwYIEv3",
        "0dalPY9JlUjk",
        "rttCQhWPHOCE",
        "y1XTl8F6sKrr",
        "Z__HJG6gIxMj",
        "q4Ryh-JimjiK",
        "Ho0vVgWAmbpf",
        "zs0QIeKrmMQ1",
        "mg96Q_kol8D-",
        "KLXoJsxynoCB",
        "XEayMrPQnvSL",
        "6s5vSukpETho",
        "ertTy-ugCmNB"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTkgKJvoTUxt"
      },
      "source": [
        "**Clinical Heart Failure Detection Using Whole-Slide Images of H&E tissue**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouhtJRBshH6t"
      },
      "source": [
        "**Aim of the Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb4p--zUhL_P"
      },
      "source": [
        "Automated detection of clinical heart failure from Whole-Slide Images of H&E tissue using a Convolutional Neural Network. Determine whether the given histopathology patch image (250x250x3) is normal or has a heart failure (binary classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxg8SxelhV96"
      },
      "source": [
        "**Background**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBCFOHYwhcS3"
      },
      "source": [
        "This project (till Version 0.19) was done as a Capstone Project as part of 'Advanced Program in Digital Health and Imaging - Cohort1 - Aug'20 to Jan'21' from Indian Institute of Science (IISc), Bengaluru.\r\n",
        "- Project Contributors: **Chinmoy Raj Hota** and **Ashwin Kumar**\r\n",
        "- Project Mentor: **Dr. Phaneendra Yalavarthy, Associate Professor, Computational Data Science Dept.(CDS), IISc, Bengaluru**\r\n",
        "- Supported by: **Naveen Paluru, PhD Scholar at CDS, IISc**\r\n",
        "\r\n",
        "We express our sincere gratitude to the Dr. Phaneendra and Naveen for the guidance and support in completing the project. We are very thankful to the Cohort1 Group Members for the class interactions which enhanced our knowledge. We also would like to thank the creators/authors of the information mentioned in the References section which helped us a lot in the project development.\r\n",
        "\r\n",
        "Post course completion, Chinmoy continued on further work beyond Version 0.19. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTgPsClrhQTo"
      },
      "source": [
        "**Capstone Project Summary (till Version 0.19)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYJ5AFFvkB90"
      },
      "source": [
        "**Methods that have been deployed**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otco_wV7kHJ2"
      },
      "source": [
        "- Transfer Learning with ResNet50\r\n",
        "- Transfer Learning and Fine Tuning with MobileNet V1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDm11eAnkOKj"
      },
      "source": [
        "**Computing Resources Utilized**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSTQ_9KQkTWl"
      },
      "source": [
        "- Pre-trained ResNet50 and MobileNet V1\r\n",
        "- Google Colab GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVEfoN_8kZrA"
      },
      "source": [
        "**Dataset Details**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgENMLLtkejs"
      },
      "source": [
        "- Location:Â https://idr.openmicroscopy.org/webclient/?show=project-402\r\n",
        "- Breakup of training/test instances: Training = 770# , Validation = 374#, Test = 1155#\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q7ytHzKkoQL"
      },
      "source": [
        "**Details of Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEepyC1lksWu"
      },
      "source": [
        "- Pre-trained ResNet50 + Custom FCN Layer\r\n",
        "- Pre-trained MobileNet V1 + Custom FCN Layer\r\n",
        "- Hidden Units in FCN after Conv: 512 Neurons, Dropout = 0.4\r\n",
        "- Loss Function = Cross Entropy.  \r\n",
        "- Optimizer = Adam, Learning Rate = 0.01\r\n",
        "- Epoch = 100, Batchsize = 10\r\n",
        "- Cross Validation(CV): Stratified K Fold, 4 Folds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_tKfGXZlT7E"
      },
      "source": [
        "**Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9LuYXh4lXzU"
      },
      "source": [
        "![project_summary.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbWSkog6l7Fm"
      },
      "source": [
        "**Inferences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXeiOEojl9Wp"
      },
      "source": [
        "![project_inference.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA3YAAAC1CAIAAACcW/pdAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAB5zSURBVHhe7Z27jh3LdUDni5iYTPgZ/AAyY2yAH6CAuLHJL1A4IGDgZoQzwYEDWoQFQ8kFCMiRAkmQAsP59d6167GruqofMzXnMWctLOl2V1dVV3fvrt6nz8zw7nd//stvfv9HRERERMRH+ttf/vRrgBQTEREREedYUkz7DwAAAADALEgxAQAAAGAypJgAAAAAMBlSTAAAAACYDCkmAAAAAEyGFBMAAAAAJkOKCQAAAACT2Zdifn1/d3f3/uuvv/749Pru7vWnH7H8pIRB1Du3ohkjsp70EDf48fW9nILAjtoAF8WPr59y/Mp98/7T13zn+Ftg5+2wp9ruOwvOiV2meiINs/3Jr10TMHEQbmgTo+5hwWmtAq5pGqhw9Hn0pKO9EFYG/3SH3zQhljIPG+1D2JVihgMOowkDO8W4OthJ8dHRxssj2HvGrZ5xpvMA8DDcxOVIYexvgZ23w55qe+8sOCt2meq5NMbLia9ds1cbmCuw7Ruz/owA/qGvE3rb8pCEst2VXn1a8ASsDH7G4fcvFrE0Yme1CexKMXU44UjDFTnFsHrYSYlnPMbO4QswYu8ZP92VAZiKhe6dTHR2y/z4Gu+hGM6E9i1Tza6R5gF9KqrnfprohTiOMNJJ8/5KzK8cfLyTjFTBhvU6NDo6upVheHZWu0weP/iVHoYXi1gasLPaBNZTTHdNPJOuyUHspOi+07CW4/DfA5ZnaSfM2nPrz3ha/pH6ev0+tK3PRuqvt0chjvb9e9tqW9YrL/do5NK2fNAbwJJy+zj0o3X6rrx3C/jlTnD6akI3UOs6ktamKp06/fiHE2CXoA6Pdq4cTzi9y1pNu0rurtrS7kRwIRO2yixaGtTxtDWjxtUUWDo2vykt5x9/ioOPg4o0N006V35UsYVM92FTblDfEv6UuViXY9CFMtp9B3VdrAy+2TT1YrkOiKWzxNL1pZjv7RwKi/NjNTw2UjsMvzxo6mOlRht3YmW0x8UW7Xl35UDctrwEcezj3gAW+HugjwWUvwXWb4em2ihQXZ1lle1dwGnoXYKIXaNOjeEU5S93vo6xmm7yW2w57iNSYiYsyZMxN6iqD4fkeuiOL22yavF9UaTsJZEPIRJbfbInUdiahpU2hQbL4aWBrwxp50FdHSuD95ue6GJpD2GJWFoe1NOy44vyMBgdSziW9hSdjvFJNuxU50zdf8KIm3To+Whq/BmPO6qvbWzi663tselE2F85roVN1kqWdUtso9XWegNYUEJnhA+h5XL3dnDVRoFadeWQD965ytou4DTEk97DXd/NCae6rNZpdVXjSuxNV0J500/eHBa0mpVINdfl2pDcslWr91xXa7bZpmqlxlpJo7wQh+JK3H5tfH7HeVPcYqNwo908qOtjZfBuU3tmyjl76MWKJ5RYOlcsbaeYYZzhAMKoTjGoPnZSFDlnacUNp2z32KmPJ9vFWYM/47acK/lNvZUWa9h0cqhy2UmMH3eUkbXeABbkOyCuLylR11vuBKdfHgZqVV/48eOrfGIv392sxz+ciuYSBPxFte0tuX73ssZWYaXpP4djWMjFibQ5/Mft/70rWR1SrO5a5mjy6802vzqO6FhNdxQb2DuoUhDG0PTdaZY3uXVbbFkc1PWxMvjF4XfPTLvNr65cLGKpYXFQT8zVfVEuZ8V2HlfLWPonNJ7FHGdSqTd8f8abs1+tdlYWhK22ze1qu3Jnj8PYXOsNYMkiIJUjP4upy81qWR5Poq5+vAl1j/XUuLILOA12zuvw8BfVti/QbcPLmpq9/hR/s8xd0thoNCG73cVG1lP4GtKXLAlb3TDcYsCvN9v86jiiYzUddaxkaNWyqe3bb2s3uXVbXOC2uR6viZXBLw6/1PLrzTa/unKxUsVArBBKiKWqxyfjKn/dx0iDSyX5OnYHZ1tDWPXOqz/jzdmvVquVtT22o91RubfH1Mr6KTP1+sECLLCo8t+bWAylwPNBOFpuVt3yKFBdnRyzWt2Kl/10VuEE2DmvZ/bqgqXlxYQzvqxK3Bqorqht2JiQtUY9vS9LtmbUWC22St3YPptIq1abbQ7bEjoso7Kay03Nl5v1puWQ4sqex8R1sTJ4t2nlzLQ9VKurp8Y2CrHb3O+ihFiaz9YX5WGUYfhhTKcY0gh3xiPpfKYyq1FRqqfK/WPwZ7w5+9Vqd1tF3KNt8aPdrNzdYx52pmpTUe0NoCH9qmNNmoF81I2Wm1W/PArUUmdZY1kn0KzCCbBzXs8g8YLFC2E1KkL18WUNlM3NBc0buhd6uTWVuL5HQ6pDqB5g/H0M29REWrVaOq/PStpipbmWX60GURH7rocUWew30zmoq6NzWEI4Mn9c0y+WQCw5Ogf1tGylmGEkOpBwIO35OSnVGY+0oSKfou2qK6/jK5VIrNs/Bn/Gm7NfrTbbxnvsjXajcn+POnD3Zwdch2sHC9CjjhkJmvIJ10fdaLlZ3ROovo7uPW+2+zFsWNkFnAY7593ZtVzfwYQzuqyRXtfK6oS82HmvZDykRURZJX2F7zctqvnV/Ja/HWF1QLZSr+UG9Z+McTebHk0Zk/2ORh7GzoO6LuJ5aghnqjmuuRdLIZaMs8TS9q/7PB/CWe1FIAAAnJbTTMgxm5DHadiR+xkOuDgu/GIRS8e5nRSz97kFAADOwMkm5JQXeHgMXCgXfrGIpcPcRIqZ4sK9JwYAgHNw6gm5+raQx8Blc+EXi1g6yC19UQ4AAAAAJ4EUEwAAAAAmQ4oJAAAAAJMhxQQAAACAyZBiAgAAAMBkSDEBAAAAYDKkmAAAAAAwGVJMAAAAAJgMKSYAAAAATIYUEwAAAAAmQ4oJAAAAAJMhxQQAAACAyZBiAgAAAMBkSDEBAAAAYDKkmAAAAAAwGVJMAAAAAJjM3e/+/Jff/P6PiIiIiIiP9F/++5eYYv7hb/94/+//iYiIiIj4SH/7y59iiin/+/7XvyMiIiIiPlLLLwVSTERERESco+WXAikmIiIiIs7R8kuBFBMRERER52j5pUCKiYiIiIhztPxSIMVERERExDlafimQYiIiIiLiHC2/FPanmF/e3L368K0pPIM/f3x1d3f34uP3phzxNvz+4aXcAYGXP/2cy7/99CKWBvKm+3dWUN0yUvj2S1ntqHt5c98UjpW9+8FM9NuXzw+bdkrDS5m78Gkc3BGj8gfeEXgzpgjxpMlQJpNIGz/dwlsNKssvhb0p5ue3cvYuYZoOT763cjnffW43IT57w1MzPS/1rvSpZCfJ0wlRJ0dNQPP9K4Ubt49+kDsyOUr9J/nUVw37iE3D/snBZ+DojhiVP/COwJt1EFS6nCY9gqrV8kthT4qppy/woLl+rvpZ4d1nvZBHXrEgPg+bzMmt9pNCrWDTnE6IdsvsSAfllj92s8ss/CT3Y3O8+20blsPHZ+Xojlgrf8AdgbeqphwpkPxyXA2xRFAttPxS2JFiynmUR1dzx57J9HlCL2T9QA0lxmb56uzzIXwR70Kn4CKm062Oze26/8hHfIyj0A3h15nRQkjXc9/2Z2sN3c4ndZtSS6LmAr7b5/Fb8r7cbroXd/elMbi2aY862nJO9PPwi7fvFg3D4ONB4TNydEeslR++I/BWDRNOnqZyTmkSVGMtvxR2/yxmc8eex/D8CM+M8FzJl9DHgdZJT8FBeXMsVaD4x6Hvyu9x0G0VfznUECcaYi+lSukTlyyHW+OlfToSchym+ExBLmHcyUQrdRe5jks3Qxb7Mjd3EW6fQkOd5OAeqcrdst16aUflXqtuVd+2HZiVl6y3ahhcluBzMERF544YlT/gjsBbVZ/pbtLorNrMRlC1Wn4pXFWK6XM4HU96bo3GtrM8r/o+tfy7TU+9ar1u/aNU6+THPOIhw9PRSBmVRNSHFJn6vDTSE9RCt0xqPvzCPCiErRKiWp562ApjsXQlo3r14WN6F+h20ZlPdWuvc38L+9Uw/nqni3utadvebvYSNFXoDKA+Lrwmj98RK+WH7wh8lm4ElahRkTepOoekktg8TikEVa3ll8I1pZj19Q4X2FbbZ09yVN4cS17tHmMKnUDYOurW3qyEIeUFxMPe/5SDcPGMXM5x3VDsp1MxF9Q4D60kkutHcrBpq3vRVWmllePsqREe20qF7l3TG1izx9Gt1yvXPS7Iqa1tLcNuOlT1QNpUGK/Ch9wRu+6UfXcEPkfXgsrszqIhrhT7TNtMMipBJVp+KVxRipkvrSddwt70MSxvjiWvtsdoe0wleeuoW1HryKb0VG62Ij7SJvbaiM0OJscw05XssN+8bRs/2smu9YFtse3Ttdhtrq+u3JK+ch5AM5JeeRl2z/iQiClF99D8mPG5OLojdt0pO+8IvElHk1iWoBpr+aVwNSmmXrDmeuuQwrNwNLad5Xm1KW8ehxpwvWqV4QH8USqshibiw9z5QNU0sQ1RScIscTyaYtqN8ME3f/uu9C9bc2KXHd0j+SYqq2HYTf286subtt7Yjxt5ZwDdtBuv3BxCZr7uo/JccuCOwFu0REW2Do9OBYIqafmlcC0ppqZuiydZLvRb9yzrwya9zwjldmjNMfpHmm5K1YbdqhpY/m0K4kw1dHN06au7OMdpHJb8SUJ3OTnmEg3m8PRdVgtKt/XbvrDTfC/ofVG+UcpTau3oHhksN7deWfV5YaifB1xuT1dHCy2x8A2DzS7wmTi6I0blySN3BN6gGjMpfpLNlLWY+giqpOWXwpWkmN3LGfM5G1W49kYVFoPy0KHx5l4mo9DJ4hg1yCJS7h9ao90Nh4o4yfDsNKqZa1Quarj6mIwfhEZ39GJOrJ/QuiP3CW3QyaFbsrn13Gq8B2NN19ZXKGMLFULlumH/lQM+C5/+jsCbUyOk93M1JagWT3mCqmj5pbA7xcSd6tPRfUGDeH3KNPrMpsV29kdExCfS8kuBFHOy8sGFXynAa1c/f1evHq9cvgBFRDyVll8KpJjzDF+R8yTDZ+Fzeu33/F7KIiJerpZfCqSYiIiIiDhHyy8FUkxEREREnKPllwIpJiIiIiLO0fJLgRQTEREREedo+aVAiol42eqfE2+Jv4hjv2GWyb9qlppUf9xACjd+Sfzgr/jI3k/8y23fvnx+2G/tlIb86g8i4tNq+aVAiol4TVZ/abz/t3j0jwNrpuj+gHko3PhzrUf/UNGp/z5XdThHbBryB4wQEZ9Syy8FUkzE61FfT5ZsqZ8UakZl2WR5K7kjHTz8ek+S3ZP+VaNZKSZ/hh0R8Sm1/FIgxUS8FjU38jmlJHmdxLGTYu57hRnf7Wmr0m34zj0nZPoONQ7A9xkGZvTfg44q9MotI7yX/4/o3rUwksbm2qaR6FGUbFLf5r54+27RkBeZiIhPqOWXAikm4pVYv8KMKdRL+2dwhZzwaXlKy7T+jleYVVrp0s2Qxb7MzbVaTDdlMDEpDKleZznrC9PY2nK3bNlkGkDIGsOhpcNZtG0HbOUlG64aBpcliIg4ScsvBVJMxEsw5ExGypwkE/qQXh+K7g1i3CqpWMkddTVlmeHVoxC2xteN2lzpplY+8/NdyaheffiY3vm5XZS0VfeV9rtcFUf53KhhOK56MKG576fdixu/VdOXoKlCZwD18SIi4jwtvxRIMREvwPufcg6UcsHmHyPdzIr6FWIuqGlWSLkkOau6NZu2mu/qqrTSyrJV27qXhSH1zNme73CZz7XpoCvvNmx66JWHV5stOdu2reVwlkMKB1iyc0REnKfllwIpJuI1OErUit0U88ubkMaV7LCTb4Vqddv4xlR2qu9NLeP0aVnsVpfPlWL6trUxR3cvg9shkWIiIj6Zll8KpJiIV2AnqWpTN0kTm0RKky1LHI+mmJb/ffDN374r/cvWnMDpMFyH7ahGexw3bOrnVV/etPXGftwRdQbQTccREXGCll8KpJiIV2B8rVgV2svFtCqpVZODSmqVSzTNCgncslpQ+q/f6mkSVtI4zdvKF/c5cw3qMNLY/PJmhcFykxGWVZ8Xhvr5QErG6erEXLMuNDtJJyIiztHyS4EUE/Hy1Yyq98WuJYKBNnHUJj6v0jeRyiC1WqSemtSWEt1RGoD03HQSEj6jzS/NUYVe+TDFDEMqNV1bX6GMOVQIleuGG9+zIyLiY7T8UiDFRERRkshB9vnc1NSzeqmJiIjztPxSIMVERDX8wKV/xfhMHfyoACIiTtHyS4EUExHNW3i9dzsvaxERz6PllwIpJiIiIiLO0fJLgRQTEREREedo+aVAiomIiIiIc7T8UiDFRERERMQ5Wn4pkGIiIiIi4hwtvxRIMRERERFxjpZfCqSYiIiIiDhHyy8FUkxEREREnKPllwIpJiIiIiLO0fJLgRQTEREREedo+aVAiomIiIiIc7T8UiDFRERERMQ5Wn4paIoJAAAAADARUkwAAAAAmAwpJgAAAABMhhQTAAAAACZDigkAAAAAkyHFBAAAAIDJkGICAAAAwGRIMQEAAABgMntSzK/v7zLvv8bCE/Pj0+s4gpaHjejH168/4mJgtX/d+PpTVR/g6ik3dh3dR8sfjXR8rokFLp8yOQ/jrpm/ma1hwI5JzAVTrlOaFZiz9rCZYoZTm86lrpz97n18wrfew+P7B7h45F6u5s+0crT8sWhfTNcwRAMkRsc47nx0Agxwz/aQR3ZmnVCeYmkUcONAhJatFLM5l5eQfj1+DOs9XMIxAjwpTZDn1aPlj+XHp08yy0t3pJjQo460UdxpOREEG2g2U8KkXos0EdYNOBLMIxz8WczRLX5K+mPQ0oSLG19sG1xJ/0iW/ecSW/ha9+A6HOx4EccA50VmyW70Hy3ff0f4G6K9JWQb9whsY+G2jMN+eM4JTngutNGjqWJ7rZs6bRMhxEpuZhWIsTHHUky9Js0JPz1bV71sb2rmWp0eHMutuST0kDfaWr1qg3CLrjXAhaAxKfGp97MRg/VouUX69h2hS+4eKBsMWXdrAH16OYESnkuvQ+wpc4MTngtt+HTDKVz+FA4hsEpoKE2RRVUVVMRYxYEUM5yW5nyfg+ZqCaPQ0Zq967jswbPcmkt0wfXYWQ3VRuMBuAw0IoUclLKeI/dI+d47QhdK8QLZvLIVIASWYFHXEDaWLTnYQvmjgxOeCzqL+Qut692AitOdsNjc9kGMbbE3xQyn7jJOUr5sCRtbg9UosdKGRTe0AsutuaTZNFjV/y6oewQ4J4vJNc6cR8t33hGCNjA6k4jU65QCtKS4W2VucMJzoQ2ebjCFWIilGiIbTYixLXalmOHsuBN3Xpqr2ClYkq9vuLzrDZZbc0mzabC67ADgotAQrWa6OHUeLW9jfX1Vqe9EgGOkwFuD4IQe7RXvxVJT1jRZtiDGtthOMfUsXdTpWF42vWrNheySAqRz4R3Lrbmk2TRa3TsegDPRzpWynkP3SPnOO6Kl7Q6gTyfwFpFDcMIu6ivbvc5NYR0knZAhxrbYSjGH5+h8DK5zKdPLF1aG4bJ6gZf955Jm03BVl8qWPB6AS6GKXbdysLwqHq8O70SAdTRWSuhIIHUCZ1BnFI1GXiU4bwb3KNbL3EsCtEoud/WVJlIUYmyLjRQzXIeWznU5Jf3L40fqtoaASZTyWNw9kmX/uaTZtLaqK4m6N4CLwIVoFaFHyquYX10d3IkAW3QDsgk1F165lOCEBeVSl6f/jlhSmmoBYmyLvb/uAwAAAACwE1JMAAAAAJgMKSYAAAAATIYUEwAAAAAmQ4oJAAAAAJMhxQQAAACAyZBiAgAAAMBkSDEBAAAAYDKkmAAAAAAwGVJMAAAAAJgMKSYAAAAATIYUEwAAAAAmQ4oJAAAAAJMhxQQAAACAyZBiAgAAAMBkSDEBAAAAYDKaYn7/698RERERER+p5ZcCKSYiIiIiztHyS4EUExERERHnaPmlQIqJiIiIiHO0/FIgxURERETEOVp+KZBiIiIiIuIcLb8USDERERERcY6WXwqkmIiIiIg4R8svhT0p5vcPL++MFx+/L7aezDKMwtsvi2q7/fbTi7tXH74tyh/mqLeH7eXbl8/7m+guhHefq/Ivb6Ts5U8/V4W1m2N+2OAREU9nmOuaZ8H9u8WUiLiu5Rh12Njj9TGZxk1q+aWwnWJ+fpvPr97J58sy9fLXew8BsZ5FrTg3f9pM15ryFY82sXugaWKFD0sxsw8YPCLiSQ0p5t3dm3tXSIqJDzA8N32aofnPg3OMG9byS2ErxayTjJ8/vjrf6V6mmKJOLtXMst+5+dOotwfs5WgTrX/35u07f3LkSkkJKSYiPnfDU+DjTy/8dEeKiQ9Sk5wcOfZsfViCcdtafikc+1nMy0sxw5DKS2x70W34KHn14aPMOIE8/ip/cg1Tb+71rVp2FMIuE4d0dC+j6c91ng62M7bK0OTN/Zc35dJIkzCYqiT2UTrZHPPRwSMintr4okFm7PKAqFLMrSkUsRheioc4aXKA4UPQPbUFUlLR8kvhUIr5iFeGE9Sru0wxdSqJuVG4/CkgSjYcL78FhKtT8iff0C0vJqlw7NVJKJ94bC/LkfT3spqslybiYGzesOs397I1jVZKpPP+mXHLm2MuI6l2vTZ4RMSTmuZkna/SHFhm78HshzhSg+fVh/v8+DMHD8HylAyGpypZpuWXws4UM5zcko6cRR1DP8W0qaTKCEU/77hLngMiLzQNy6rLJrVyKPz2vToDVW9H9rKSr+cmsjwcmzPtWoI+dngfvjSXyna9Rp1sjjkvtPsdDx4R8aSW6UjmwPiMyFPWaPZDHBoTnirfGD0E9SlJRLVafikc+6L8rPfnOMUMiZR+qlig9XOeFJv4yEj5k0+dXX3tM3xqyQtRPQ+ZnI2N4k8rDIdXmiT9gMdjK2ph2JdUDoP8/Dat5hSz24kurI05LxwYPCLiSS0pZlgOc5dO0WFy2zOFIjbm+EmuPAT1+3SDF+RJyy+FgylmdTOf2H6KmX9aQiPATyXZdk5ZJFIrc5AuS5zprt0UJvgKYTnWtDqxmt/LcHhL/QD2zI9aaMOzH8eUXddz66gTXVgbc144MHi8Af1sK7dks9pURnxi08QVVjUa5YmQU4Q9UyhiY46f5I6HoOUGQtXwNrX8UthKMdsTXd3Mp7WbYrrx6FB7c4fOKW7MOa/Kc03TsDrkkFx+TE1sq4+z3LaZufLqaC8r+q7WxpbU+vEAP78Nv75jn6XyUEedbI45LzQ9ICJeis1TSSZt+y3GMMuNZj/EFZdxsvcheMYc6YK0/FLYfIvpX+CFs3y2t1nLFFNL3Hjq1RwQIQNL4RLqWAZWEixXWC2r8Q1NLvFxFnt2e4l7H+9lOTxbrfQxuja2aNi11bfRxrNULtagk80xP2TwiIindPFQ1wlKWMz51TLiWA2h5qPI4CHY1CwPzZvW8kthzxfl4cwa+fyeQTeMxOKlpq+TLrNd8vynefL8UoWCa9hMQFqtmr/KD15o8zS7Hd1LKewYd+GnRaM7OfoR+t1J6Jfr1etkc8wPGjwi4gntvDcKU2h+8G9NoYiNnRRTHDwEtXKGh6Nq+aVw9Gcxr9AqTzquNl+GGiIiIiK2Wn4pkGJu+HP+KxiIiIiIuKrllwIp5lhteN6fDUBERES8Ji2/FG4gxURERETEk2j5pUCKiYiIiIhztPxSIMVERERExDlafimQYiIiIiLiHC2/FK4oxfR/kirx4D9y9si/ZISIiIiICy2/FK4sxVz9130QERER8ZxafilcdYop8u+BIiIiIl6Kll8K155ihn+Vu3xd7r9Mt3+Sp20V/hXvd5+rL8pdq+qb92VvQft7mQkSXERERETT8kvh6lNM9y9xh4ww5YiaSobyvBDKUyclxfSt/DvRfm/tD3GGdJMsExEREVG0/FJ4FimmvWJs/936lC/6pDAvLxdKw+Bab74cEREREaOWXwrP5y1m+Aa8JdQvDTsvI9tUMjru7e+f38bV+lt1RERExFvX8kvh6lNMTfhCqld/IV4b01DXw54Uc9RbVN9rBnipiYiIiKhafilce4rpfnpSk8XeV96qVHv14d59x73ri/JRb143AERERMTb1vJL4apTTC1x7xrr1TpHjN9u56+2S2YZWsXyxfKyt+at5yhDRURERLw9Lb8UrizFbFi81PR16sxPU0P3urFKDV2r6scrB72FrhLkl4iIiIhRyy+FK0oxEREREfGitfxSIMVERERExDlafimQYiIiIiLiHC2/FEgxEREREXGOll8KpJiIiIiIOEfLLwVSTERERESco+WXAikmIiIiIs7R8kuBFBMRERER52j5pUCKiYiIiIhztPxSIMVERERExDlafimQYiIiIiLiHC2/FEgxEREREXGOll8KpJiIiIiIOEfLLwVSTERERESco+WXAikmIiIiIs7R8kvh7re//Omf/vXfEBEREREf6T//x3/FFPN//vf/fvfnvyAiIiIiPtI//O0fmmD++uv/AybTmeJA0oAmAAAAAElFTkSuQmCC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d7u_X85mPzL"
      },
      "source": [
        "Reference(1) : https://www.nature.com/articles/s41598-020-58467-9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNtxjpscmbr4"
      },
      "source": [
        "**Other Inferences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsedcrdYmeX8"
      },
      "source": [
        "- The H&E images have a high variety of information in them. Hence, although being a binary classification problem, a DL solution proves to be a best bet.    \r\n",
        "- Batch Normalization, Regularization and Data Augmentation did not help improve the accuracy as the binary classes are balanced. \r\n",
        "- There is site to site process variability in Whole Slide Image Capture. Hence, the model might need site level customization to be more effective. This might require model to get trained on lesser data. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh4o3wefg7xk"
      },
      "source": [
        "**Summary (Post Course Completion / Post Version 0.19)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URopeha6fdrv"
      },
      "source": [
        "![HE_Summary.png](data:image/png;base64,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)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouwKeET6nbZK"
      },
      "source": [
        "**Download Train, Validate and Test Images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvHgttBNTUx2"
      },
      "source": [
        "- Source Link to the Dataset / Annotation File: https://idr.openmicroscopy.org/webclient/?show=project-402\n",
        "- Follow the instructions at following link, install IBM Aspera Desktop Client to download the dataset.\n",
        "- Copy downloaded folders to '**data/images**' folder in your working directory where you have this Jupyter Notebook:\n",
        "  - 'held-out_validation'\n",
        "  - 'training'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa6xmGhlniIH"
      },
      "source": [
        "**Download Label Information for Train, Validate and Test Images** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QpqHhxkTUx2"
      },
      "source": [
        "- Following link will point to below Github link which has the annotation File: https://idr.openmicroscopy.org/webclient/?show=project-402\n",
        "- Source Link for the Annotation File: https://github.com/IDR/idr0042-nirschl-wsideeplearning/tree/master/experimentA\n",
        "- Download and copy file '**idr0042-experimentA-annotation.csv**' to '**data/labels/**' folder in your working directory where you have this Jupyter Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3586paiFoAvW"
      },
      "source": [
        "**Understand Images Folder Structure and Number of Images Available**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVqvp6TDTUx4"
      },
      "source": [
        "Training/Validation\n",
        "- \\..\\training\\fold_1: has images for training = 770#\n",
        "- \\..\\training\\test_fold_1: has images for validation = 374#\n",
        "- Total = 770 + 374 = 1144 images\n",
        "\n",
        "Test\n",
        "- \\..\\held-out_validation: has images for testing = 1155#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avjn1GKeoEd4"
      },
      "source": [
        "**Understand Annotation File and Label Information Available**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MOqlD8qTUx4"
      },
      "source": [
        "Relevant columns of interest:\n",
        "- Column A: Dataset Name: Classifies each row/instance as 'training' or 'test'\n",
        "- Column B: Image Name: Specifies filename of the image for the row/instance\n",
        "- Column Z: Experimental Condition [Diagnosis]: has 3 classes:\n",
        "  - 'chronic heart failure'\n",
        "  - 'heart tissue pathology' - We will treat this as 'not chronic heart failure'\n",
        "  - 'not chronic heart failure'\n",
        "- Column AA: Channels: mentions RGB => images are color images and will have 3 channels Red/Green/Blue (for CNN). \n",
        "  \n",
        "Breakup of training/test instances:\n",
        "- training\n",
        "  - 'chronic heart failure' = 517\n",
        "  - 'not chronic heart failure' = 627\n",
        "- test\n",
        "  - 'chronic heart failure' = 517\n",
        "  - 'not chronic heart failure' = 638\n",
        "\n",
        "Total 'training' = 517 + 627 = 1144  (Note: 'validate' is a portion of this 'training' set.)\n",
        "\n",
        "Total 'test' = 517 + 638 = 1155"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oem7YyjKL7Z"
      },
      "source": [
        "**Load Common Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rqxeoKlTUx5"
      },
      "source": [
        "# install OpenCV package - this is required only once\n",
        "# pip install opencv-python"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvKVTkfxTUx5"
      },
      "source": [
        "# aids in reading image files\r\n",
        "import cv2\r\n",
        "import glob\r\n",
        "# aids in working with arrays\r\n",
        "import numpy as np\r\n",
        "# aids in working with dataframes\r\n",
        "import pandas as pd\r\n",
        "# aids in calculation of time\r\n",
        "import time\r\n",
        "# aids in converting the labels to categorical\r\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKWb8A5_VK_z",
        "outputId": "415de5fc-fa47-4092-a6d3-42ef67a0a2db"
      },
      "source": [
        "pip install keras-flops"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-flops\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/77/e384f6e427e1920624a9229b411010eaa244134cff6a230d303d3b1ea0be/keras_flops-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow<3.0,>=2.2 in /usr/local/lib/python3.6/dist-packages (from keras-flops) (2.4.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.12)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.10.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.6.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.19.5)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.12.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (53.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.25.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (2.10)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.2->keras-flops) (0.4.8)\n",
            "Installing collected packages: keras-flops\n",
            "Successfully installed keras-flops-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTqpP1dMVTmP"
      },
      "source": [
        "# aids in calculation of flops of the model\r\n",
        "from keras_flops import get_flops"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmuzEGsl12zy"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fL4wKtMLhw3"
      },
      "source": [
        "We need to mount the google drive so that we can then access the files from google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhVh4qU1U47e",
        "outputId": "99d73e8a-9f87-4757-ccb3-131232be3755"
      },
      "source": [
        "# run this. click on the link it will ask for. get the authentication code. Copy/Paste in the cell. Hit Enter.\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmu8WoMlNJFY"
      },
      "source": [
        "**Get labels info into a dataframe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAuHkpYPG_ld"
      },
      "source": [
        "We need to import the annotation file into a dataframe so that we can then access the labels information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COjL64aeTUx7"
      },
      "source": [
        "# Google Drive / Colab\r\n",
        "filepath_annotation_file = r'/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/labels/idr0042-experimentA-annotation.csv'\r\n",
        "labels = pd.read_csv(filepath_annotation_file)\r\n",
        "\r\n",
        "# Local Drive / Jupyter\r\n",
        "# labels = pd.read_csv('data/labels/idr0042-experimentA-annotation.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYQ6b9n4IcCk",
        "outputId": "f644c592-29b1-4176-a796-e9c9d21e75e2"
      },
      "source": [
        "### for understanding purposes ###\r\n",
        "print(labels)\r\n",
        "print(type(labels))\r\n",
        "print(labels['Dataset Name'])\r\n",
        "print(labels['Dataset Name'][0])\r\n",
        "type(labels['Dataset Name'][0])\r\n",
        "print(labels['Image Name'])\r\n",
        "print(labels['Image Name'][0])\r\n",
        "type(labels['Image Name'][0])\r\n",
        "print(labels['Experimental Condition [Diagnosis]'])\r\n",
        "print(labels['Experimental Condition [Diagnosis]'][0])\r\n",
        "type(labels['Experimental Condition [Diagnosis]'][0])\r\n",
        "# confirm 'no info' cells have been encoded as 'nan'... check one entry\r\n",
        "print(labels['Characteristics [Disease Subtype]'][463])\r\n",
        "### for understanding purposes ###"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Dataset Name  ... Channels\n",
            "0        training  ...      RGB\n",
            "1        training  ...      RGB\n",
            "2        training  ...      RGB\n",
            "3        training  ...      RGB\n",
            "4        training  ...      RGB\n",
            "...           ...  ...      ...\n",
            "2294         test  ...      RGB\n",
            "2295         test  ...      RGB\n",
            "2296         test  ...      RGB\n",
            "2297         test  ...      RGB\n",
            "2298         test  ...      RGB\n",
            "\n",
            "[2299 rows x 27 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "0       training\n",
            "1       training\n",
            "2       training\n",
            "3       training\n",
            "4       training\n",
            "          ...   \n",
            "2294        test\n",
            "2295        test\n",
            "2296        test\n",
            "2297        test\n",
            "2298        test\n",
            "Name: Dataset Name, Length: 2299, dtype: object\n",
            "training\n",
            "0       33381_0_fal_10_0.png\n",
            "1       33381_0_fal_14_0.png\n",
            "2       33381_0_fal_16_0.png\n",
            "3       33381_0_fal_18_0.png\n",
            "4       33381_0_fal_25_0.png\n",
            "                ...         \n",
            "2294    36175_1_nrm_18_0.png\n",
            "2295     36175_1_nrm_1_0.png\n",
            "2296    36175_1_nrm_20_0.png\n",
            "2297    36175_1_nrm_21_0.png\n",
            "2298     36175_1_nrm_2_0.png\n",
            "Name: Image Name, Length: 2299, dtype: object\n",
            "33381_0_fal_10_0.png\n",
            "0           chronic heart failure\n",
            "1           chronic heart failure\n",
            "2           chronic heart failure\n",
            "3           chronic heart failure\n",
            "4           chronic heart failure\n",
            "                  ...            \n",
            "2294    not chronic heart failure\n",
            "2295    not chronic heart failure\n",
            "2296    not chronic heart failure\n",
            "2297    not chronic heart failure\n",
            "2298    not chronic heart failure\n",
            "Name: Experimental Condition [Diagnosis], Length: 2299, dtype: object\n",
            "chronic heart failure\n",
            "nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K54cMICV2vc9"
      },
      "source": [
        "**Function to prepare images and labels for CNN based Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxnppA2lTUx4"
      },
      "source": [
        "We need to read 'train, validate and test images' to arrays so that we can then use them to feed to our CNN model. We need to prepare the labels to match to CNN model's expectation. All the images are of type '*.png'. We will read filepath for all \"filenames with extension as 'png'\" into a list. Here, filepath means 'relative directory + filename'. We will extract filename of the image from the file path. This filename can then be used to get the label information from the annotation file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hMxdbgmIwW5"
      },
      "source": [
        "### for understanding purposes ###\r\n",
        "# This is useful for Local Drive / Jupyter. This scenario has '\\\\' between the directory and filename. \r\n",
        "# We can split the string to get directory and filename separately\r\n",
        "# directory, filename = filepathlist_train[0].split('\\\\')\r\n",
        "# print(directory)\r\n",
        "# print(filename)\r\n",
        "### for understanding purposes ###"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ897heXIGRk",
        "outputId": "d9f78456-7184-49eb-d946-32dd7b183ec6"
      },
      "source": [
        "### for understanding purposes ###\r\n",
        "# Google Drive / Colab\r\n",
        "filepathlist_train = glob.glob('/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/fold_1/*.png')\r\n",
        "# confirm you have got the total number of desired items in the list\r\n",
        "print(len(filepathlist_train))\r\n",
        "# check what an element in the filelist contain.\r\n",
        "# it has both directory information and the filename, we need to extract filename \r\n",
        "# the filename can then be used to check for the label info in the labels dataframe\r\n",
        "print(filepathlist_train[0])\r\n",
        "print(len(filepathlist_train[0]))\r\n",
        "print(filepathlist_train[0][-19:])\r\n",
        "print(filepathlist_train[0][len(filepathlist_train[0]) - 1])\r\n",
        "print(filepathlist_train[0][-1])\r\n",
        "### for understanding purposes ###"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "770\n",
            "/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/fold_1/33392_0_fal_4_0.png\n",
            "128\n",
            "33392_0_fal_4_0.png\n",
            "g\n",
            "g\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LJaZ8N-KDPy",
        "outputId": "78f79165-4dd7-4d83-f586-63d75ae0f58b"
      },
      "source": [
        "### for understanding purposes ###\r\n",
        "# POC to get filename for a given filepath\r\n",
        "idx = -1\r\n",
        "while (filepathlist_train[0][idx] != '/'):\r\n",
        "  idx = idx - 1 \r\n",
        "# index currently points to '/' location, we need to start reading from next location to get file name\r\n",
        "print(idx)\r\n",
        "filename = filepathlist_train[0][idx + 1:]\r\n",
        "print(filename)\r\n",
        "### for understanding purposes ###"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-20\n",
            "33392_0_fal_4_0.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeBgiYhJKbkK"
      },
      "source": [
        "### for understanding purposes ###\r\n",
        "# POC to iterate over multiple filepaths\r\n",
        "index_filepathlist = 0\r\n",
        "for filepath in filepathlist_train:\r\n",
        "    #print(index_filepathlist, filepath)\r\n",
        "    index_filepathlist += 1\r\n",
        "### for understanding purposes ###"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ2-evaiKo4m"
      },
      "source": [
        "### for understanding purposes ###\r\n",
        "# read a file using the list containing the file path\r\n",
        "img = cv2.imread(filepathlist_train[0])\r\n",
        "### for understanding purposes ###"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KqlbiYajI1D"
      },
      "source": [
        "# function to count ones and zeroes in the label array\r\n",
        "def print_ones_zeroes (labels):\r\n",
        "  count_ones = 0\r\n",
        "  count_zeroes = 0\r\n",
        "  for i in range(len(labels)):\r\n",
        "    if (labels[i] == 1):\r\n",
        "      count_ones += 1\r\n",
        "    elif (labels[i] == 0):\r\n",
        "      count_zeroes += 1\r\n",
        "  print('Total Labels:',(count_ones + count_zeroes))\r\n",
        "  print('# of Class 1:',count_ones)   \r\n",
        "  print('# of Class 0:',count_zeroes)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC6R5bJlpRLR"
      },
      "source": [
        "# function to prepare images & labels for the model\r\n",
        "def prepare_images_labels (path_to_img_files, labels_dataframe, resize = True):\r\n",
        "  start_time = time.time()\r\n",
        "  filepathlist = glob.glob(path_to_img_files)\r\n",
        "  # define the empty list that need to populated with info\r\n",
        "  images = []\r\n",
        "  labels = []\r\n",
        "  index_filepathlist = 0\r\n",
        "  # iterate for all items in the file path list\r\n",
        "  for filepath in filepathlist:\r\n",
        "      # prepare image list\r\n",
        "      img = cv2.imread(filepath)\r\n",
        "      if (resize == True):\r\n",
        "        dim = (224,224)\r\n",
        "        img = cv2.resize(img, dim)#, interpolation = inter)\r\n",
        "      images.append(img)\r\n",
        "      # prepare labels list\r\n",
        "      # extract filename from the file path\r\n",
        "      # Local Drive / Jupyter\r\n",
        "      # directory, filename = filepath.split('\\\\')\r\n",
        "      # Google Drive / Colab\r\n",
        "      index_character = -1\r\n",
        "      while (filepathlist[index_filepathlist][index_character] != '/'):\r\n",
        "        index_character = index_character - 1 \r\n",
        "      # character index currently points to '/' location, we need to start reading from next location to get file name\r\n",
        "      filename = filepathlist[index_filepathlist][index_character + 1:]\r\n",
        "      index_filepathlist += 1\r\n",
        "      # iterate for all items in our labels dataframe to search for the label\r\n",
        "      for index in range(len(labels_dataframe)):\r\n",
        "          # we will compare the filename with all the filenames in the 'Image Name' column of the labels dataframe\r\n",
        "          # when there is a match, we will copy the label from the 'Experimental Condition [Diagnosis]' column\r\n",
        "          if (filename == labels_dataframe['Image Name'][index]):\r\n",
        "              label = labels_dataframe['Experimental Condition [Diagnosis]'][index]\r\n",
        "              # encode Class1 and Class0 as applicable\r\n",
        "              if (label == 'chronic heart failure'):\r\n",
        "                  label = 1\r\n",
        "              elif (label == 'not chronic heart failure'):\r\n",
        "                  label = 0\r\n",
        "              elif (label == 'heart tissue pathology'):\r\n",
        "                  label = 0\r\n",
        "              # append the label to the list\r\n",
        "              labels.append(label)\r\n",
        "  # convert list to a numpy array and the values to float\r\n",
        "  images = np.array(images, dtype = 'float32')\r\n",
        "  # check the shape to confirm it is ready for CNN\r\n",
        "  # number of instances, width, height, number of channels\r\n",
        "  # number of instances = number of image\r\n",
        "  # number of channels = 3 ... as these are color images\r\n",
        "  print('Shape of Images:',images.shape)\r\n",
        "  # convert list to a numpy array and the values to int64\r\n",
        "  labels = np.array(labels, dtype = 'int64')\r\n",
        "  # check the shape to confirm it is ready for CNN\r\n",
        "  print('Shape of Labels:', labels.shape)\r\n",
        "  print_ones_zeroes(labels)\r\n",
        "  duration = time.time() - start_time \r\n",
        "  print(f'Images/Labels Prep Core Time = {duration}s')\r\n",
        "  return images, labels"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2xpvmempoa4"
      },
      "source": [
        "**Prepare Train Images and Train Labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PyeiK-Ulctu",
        "outputId": "17848af0-d66c-4a42-d061-8290076d0816"
      },
      "source": [
        "# read filepath for all \"filenames with extension as 'png'\" into a list\r\n",
        "# here filepath means 'relative directory + filename'\r\n",
        "# Google Drive / Colab\r\n",
        "path_to_img_files = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/fold_1/*.png'\r\n",
        "# Local Drive / Jupyter\r\n",
        "# filepathlist_train = glob.glob('data/images/training/fold_1/*.png')\r\n",
        "train_images, train_labels = prepare_images_labels (path_to_img_files, labels, True) # resize set to True to resize images to 224 x 224\r\n",
        "# save the labels before converting to categorical to use for cross validation splits\r\n",
        "train_labels_before_categorical = train_labels\r\n",
        "print('train_labels_before_categorical:', type(train_labels_before_categorical), len(train_labels_before_categorical), train_labels_before_categorical.shape)\r\n",
        "# convert labels to categorical\r\n",
        "train_labels = to_categorical(train_labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Images: (770, 224, 224, 3)\n",
            "Shape of Labels: (770,)\n",
            "Total Labels: 770\n",
            "# of Class 1: 352\n",
            "# of Class 0: 418\n",
            "Images/Labels Prep Core Time = 554.144868850708s\n",
            "train_labels_before_categorical: <class 'numpy.ndarray'> 770 (770,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtvpF6A6TUyG"
      },
      "source": [
        "**Prepare Validation Images and Validation Labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgWoRGe8Qr4K",
        "outputId": "a182c604-e918-46f7-81e8-ceb4d8bda77c"
      },
      "source": [
        "# read filepath for all \"filenames with extension as 'png'\" into a list\r\n",
        "# here filepath means 'relative directory + filename'\r\n",
        "# Google Drive / Colab\r\n",
        "path_to_img_files = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/training/test_fold_1/*.png'\r\n",
        "# Local Drive / Jupyter\r\n",
        "# filepathlist_validation = glob.glob('data/images/training/test_fold_1/*.png')\r\n",
        "validation_images, validation_labels = prepare_images_labels (path_to_img_files, labels, True) # resize set to True to resize images to 224 x 224\r\n",
        "# save the labels before converting to categorical to use for cross validation splits\r\n",
        "validation_labels_before_categorical = validation_labels\r\n",
        "print('validation_labels_before_categorical:', type(validation_labels_before_categorical), len(validation_labels_before_categorical), validation_labels_before_categorical.shape)\r\n",
        "# convert labels to categorical\r\n",
        "validation_labels = to_categorical(validation_labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Images: (374, 224, 224, 3)\n",
            "Shape of Labels: (374,)\n",
            "Total Labels: 374\n",
            "# of Class 1: 165\n",
            "# of Class 0: 209\n",
            "Images/Labels Prep Core Time = 262.49798560142517s\n",
            "validation_labels_before_categorical: <class 'numpy.ndarray'> 374 (374,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzMWmY9PTUyJ"
      },
      "source": [
        "**Prepare Test Images and Test Labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BSx6BoNSWeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c54da7f-8459-4c90-ad15-eb3c8716a3b7"
      },
      "source": [
        "# read filepath for all \"filenames with extension as 'png'\" into a list\r\n",
        "# here filepath means 'relative directory + filename'\r\n",
        "# Google Drive / Colab\r\n",
        "path_to_img_files = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images /data/images/held-out_validation/*.png'\r\n",
        "# Local Drive / Jupyter\r\n",
        "# filepathlist_test = glob.glob('data/images/held-out_validation/*.png')\r\n",
        "test_images, test_labels = prepare_images_labels (path_to_img_files, labels, True) # resize set to True to resize images to 224 x 224\r\n",
        "# save the labels before converting to categorical to use for cross validation splits\r\n",
        "test_labels_before_categorical = test_labels\r\n",
        "print('test_labels_before_categorical:', type(test_labels_before_categorical), len(test_labels_before_categorical), test_labels_before_categorical.shape)\r\n",
        "# convert labels to categorical\r\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Images: (1155, 224, 224, 3)\n",
            "Shape of Labels: (1155,)\n",
            "Total Labels: 1155\n",
            "# of Class 1: 517\n",
            "# of Class 0: 638\n",
            "Images/Labels Prep Core Time = 808.2478666305542s\n",
            "test_labels_before_categorical: <class 'numpy.ndarray'> 1155 (1155,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2qDQBwAozQt"
      },
      "source": [
        "**Prepare All Images and Labels for Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjOakGJaUhyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9946edff-f494-43e8-d181-85f78bca9144"
      },
      "source": [
        "# confirm all are numpy arrays, length and shape\r\n",
        "print('train_images:', type(train_images), len(train_images), train_images.shape)\r\n",
        "print('validation_images:', type(validation_images), len(validation_images), validation_images.shape)\r\n",
        "#print('test_images:', type(test_images), len(test_images), test_images.shape)\r\n",
        "print('Total Images:', len(train_images) + len(validation_images))# + len(test_images))\r\n",
        "print('train_labels:', type(train_labels), len(train_labels), train_labels.shape)\r\n",
        "print('validation_labels:', type(validation_labels), len(validation_labels), validation_labels.shape)\r\n",
        "#print('test_labels:', type(test_labels), len(test_labels), test_labels.shape)\r\n",
        "print('Total Labels:', len(train_labels) + len(validation_labels))# + len(test_labels))\r\n",
        "# join train / validation / test arrays for images\r\n",
        "all_images = np.concatenate((train_images, validation_images))#, test_images))\r\n",
        "print('all_images:', type(all_images), len(all_images), all_images.shape)\r\n",
        "# join train / validation / test arrays for labels\r\n",
        "all_labels = np.concatenate((train_labels, validation_labels))#, test_labels))\r\n",
        "print('all_labels:', type(all_labels), len(all_labels), all_labels.shape)\r\n",
        "# prepare the labels to enable split during k-cross validation\r\n",
        "all_labels_before_categorical = np.concatenate((train_labels_before_categorical, validation_labels_before_categorical))#, test_labels_before_categorical))\r\n",
        "print('all_labels_before_categorical;', type(all_labels_before_categorical), len(all_labels_before_categorical), all_labels_before_categorical.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_images: <class 'numpy.ndarray'> 770 (770, 224, 224, 3)\n",
            "validation_images: <class 'numpy.ndarray'> 374 (374, 224, 224, 3)\n",
            "Total Images: 1144\n",
            "train_labels: <class 'numpy.ndarray'> 770 (770, 2)\n",
            "validation_labels: <class 'numpy.ndarray'> 374 (374, 2)\n",
            "Total Labels: 1144\n",
            "all_images: <class 'numpy.ndarray'> 1144 (1144, 224, 224, 3)\n",
            "all_labels: <class 'numpy.ndarray'> 1144 (1144, 2)\n",
            "all_labels_before_categorical; <class 'numpy.ndarray'> 1144 (1144,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVZqztGYtAA1"
      },
      "source": [
        "**Define Common Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMuD8SLxtKW_"
      },
      "source": [
        "# 1 epoch = 770 / 10 = 77 batches\r\n",
        "BATCH_SIZE = 10  \r\n",
        "# 1 epoch = 1 complete run of all train samples for training the model\r\n",
        "EPOCHS = 1 #100 \r\n",
        "LEARNING_RATE = 0.01\r\n",
        "DENSE_LAYER_NEURONS = 512\r\n",
        "DENSE_LAYER_DROPOUT = 0.4\r\n",
        "CROSS_VALIDATE = True\r\n",
        "CROSS_VALIDATION_FOLDS = 2 #4 \r\n",
        "TOTAL_TEST_SAMPLES = 1155\r\n",
        "\r\n",
        "# MobileNetV1\r\n",
        "# set trainable layers starting from 80th layer\r\n",
        "# 0 to 72 = Till Conv11 ; # 73 to 79 - Conv12; # 80 to 85 = Conv13 ; # 86 to 91 = Post Conv13 before Custom (GAP...) ; # 92 to 94 = Custom (Dense/Dropout/Dense(2))\r\n",
        "MOBILENETV1_TRAINABLE_START_LAYER = 80\r\n",
        "# MobileNetV2\r\n",
        "MOBILENETV2_TRAINABLE_START_LAYER = 151"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LU3ToUb9j4A"
      },
      "source": [
        "**Function to check values during training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1GuG7z79iou"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\r\n",
        "def checkpoint(path_to_model_parameters_file):\r\n",
        "  # path_to_model_parameters_file: file to which the weights need to be saved\r\n",
        "  # monitor: defines the quantity to monitor ... we will monitor validation accuracy\r\n",
        "  # verbose: verbose yes/no\r\n",
        "  # save_best_only: true then save weghts else save entire model\r\n",
        "  # mode: max if val_acc, min if val_loss, auto decides based on the quantity getting monitored\r\n",
        "  # save_freq: save_freq:  specify the frequency in number of batches seen\r\n",
        "  # period:  check after every epoch therefore 1\r\n",
        "  checkpoint_value = ModelCheckpoint(path_to_model_parameters_file, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_freq = 'epoch') #period=1\r\n",
        "  return checkpoint_value"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3N-zzlle46d"
      },
      "source": [
        "**Define function to train and validate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FmsVrWpfEoi"
      },
      "source": [
        "# trains and validates model ... returns trained model, saves the best parameters file in the location provided\r\n",
        "def train_and_validate_model(model_name, trn_imgs, trn_lbls, val_imgs, val_lbls, path_to_model_params_file):\r\n",
        "  print('Model Train and Validation: Starting')\r\n",
        "  start_time = time.time()\r\n",
        "  model_name.fit(trn_imgs, trn_lbls, epochs = EPOCHS, batch_size = BATCH_SIZE, validation_data = (val_imgs, val_lbls), \r\n",
        "                 callbacks=[checkpoint(path_to_model_params_file)])\r\n",
        "  duration = time.time() - start_time\r\n",
        "  print(f'Train and Validation Time = {duration}s')\r\n",
        "  print('Model Train and Validation: Completed')\r\n",
        "  return model_name"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ao8ckISglsp"
      },
      "source": [
        "**Define function to test model with best parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA1co8phgqFI"
      },
      "source": [
        "# test with best model (params from best epoch)\r\n",
        "def test_model_with_best_params(model_name, path_to_best_params_file, test_imgs, test_lbls):\r\n",
        "  print('Model Test: Starting')\r\n",
        "  model_name.load_weights(path_to_best_params_file)\r\n",
        "  start_time = time.time()\r\n",
        "  test_loss, test_acc = model_name.evaluate(test_imgs, test_lbls)\r\n",
        "  duration = time.time() - start_time\r\n",
        "  print(f'Test Time = {duration}s')\r\n",
        "  print(f'Test Time / sample = {duration/TOTAL_TEST_SAMPLES}s')\r\n",
        "  print('Model Test: Completed')\r\n",
        "  return model_name"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtanhXOwM2uk"
      },
      "source": [
        "**Define function to set the trainable layers for the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjTjWuD7Mv6m"
      },
      "source": [
        "def set_trainable_layers_starting_from(model_name, trainable_start_layer_number):\r\n",
        "  ############################################################################################################################################################################\r\n",
        "  # CONFIGURE LAYERS FOR TRAINING #\r\n",
        "  print(f'Layers Configuration: Starting')\r\n",
        "  for layer in model_name.layers[:trainable_start_layer_number]: \r\n",
        "      layer.trainable=False\r\n",
        "  for layer in model_name.layers[trainable_start_layer_number:]: \r\n",
        "      layer.trainable=True\r\n",
        "  print(f'Layers Configuration: Completed')\r\n",
        "  return model_name\r\n",
        "  ############################################################################################################################################################################"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwlxxNnenMzf"
      },
      "source": [
        "**Define function to cross validate model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrXaiTERfqx7"
      },
      "source": [
        "# cross validate the model and get the path to the file containing best cross validation fold's parameters\r\n",
        "def cross_validate_model(model_name, all_imgs, all_lbls, all_lbls_before_categorical, path_to_bestxfr_params_file = 'NULL'):\r\n",
        "  ###############################################################################################################################################################################\r\n",
        "  # MODEL CROSS VALIDATION #\r\n",
        "  print('Model Cross Validation: Starting')\r\n",
        "  # perform cross validation\r\n",
        "  start_time = time.time()\r\n",
        "  # import libraries\r\n",
        "  from sklearn.model_selection import StratifiedKFold\r\n",
        "  # using stratifiedkfold so that we have balanced classes in each split\r\n",
        "  cvfold = StratifiedKFold(n_splits = CROSS_VALIDATION_FOLDS, shuffle = True)\r\n",
        "  # we will use below to store all individual validation scores\r\n",
        "  cvscores = []\r\n",
        "  # initialize variables for the accuracy analysis for various folds  \r\n",
        "  fold = 0\r\n",
        "  # based on the class value, get the split done and respective train and test index\r\n",
        "  for train_index, val_index in cvfold.split(all_imgs, all_lbls_before_categorical):\r\n",
        "    if (model_name == 'resnet50xfr'):\r\n",
        "      model = define_model_resnet50xfr()\r\n",
        "    elif (model_name == 'mobilenetv1xfr'):\r\n",
        "      model = define_model_mobilenet('V1')\r\n",
        "    elif (model_name == 'mobilenetv1ft'):\r\n",
        "      model = define_model_mobilenet('V1')\r\n",
        "      set_trainable_layers_starting_from(model, MOBILENETV1_TRAINABLE_START_LAYER)\r\n",
        "      model.load_weights(path_to_bestxfr_params_file) \r\n",
        "    elif (model_name == 'mobilenetv2xfr'):\r\n",
        "      model = define_model_mobilenet('V2') \r\n",
        "    elif (model_name == 'mobilenetv2ft'):\r\n",
        "      model = define_model_mobilenet('V2')\r\n",
        "      set_trainable_layers_starting_from(model, MOBILENETV2_TRAINABLE_START_LAYER)\r\n",
        "      model.load_weights(path_to_bestxfr_params_file)    \r\n",
        "    # train based on train index elements\r\n",
        "    #path_to_model_cv_params_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_cv.hdf5'\r\n",
        "    path_to_model_cv_params_file = f'/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_{model_name}_cvfold_{fold}.hdf5'\r\n",
        "    hist = model.fit(all_imgs[train_index], all_lbls[train_index], epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = 1, \r\n",
        "                     validation_data = (all_imgs[val_index], all_lbls[val_index]), callbacks=[checkpoint(path_to_model_cv_params_file)])\r\n",
        "    # get the validation accuracy\r\n",
        "    # hist.history['val_accuracy'] is a list ... hence, get the float value using index 0 of the list\r\n",
        "    cv_score = hist.history['val_accuracy'][0]\r\n",
        "    print(\"Cross Validation Accuracy: %0.2f%%\" % (cv_score*100))\r\n",
        "    # append each iteration validation accuracy score\r\n",
        "    cvscores.append(cv_score*100)\r\n",
        "    # print fold number and increment\r\n",
        "    print(f'Fold #{fold} Complete \\n')\r\n",
        "    fold += 1\r\n",
        "  # print mean and std deviation of the validation accuracy for the complete cross validation i.e. for all iterations\r\n",
        "  print(\"Cross Validation Accuracy Mean (+/- Std Deviation): %0.2f%% (+/- %0.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\r\n",
        "  # determine best fold\r\n",
        "  best_accuracy = 0\r\n",
        "  best_fold = 0\r\n",
        "  for idx in range(CROSS_VALIDATION_FOLDS):\r\n",
        "    if (cvscores[idx] > best_accuracy):\r\n",
        "      best_accuracy = cvscores[idx]\r\n",
        "      best_fold = idx\r\n",
        "  path_to_best_cv_fold_params_file = f'/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_{model_name}_cvfold_{best_fold}.hdf5'\r\n",
        "  duration = time.time() - start_time\r\n",
        "  print(f'Cross Validation Time = {duration}s')\r\n",
        "  print('Model Cross Validation: Completed')\r\n",
        "  return path_to_best_cv_fold_params_file\r\n",
        "  ###############################################################################################################################################################################"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz5PwHsFK3ws"
      },
      "source": [
        "**Define a function to convert Keras Model to TensorFlowLite Model(.tflite)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnog7ZsoLBHY"
      },
      "source": [
        "def convert_keras_model_to_tflite(model_name, path_to_tflite_file):\r\n",
        "  # convert the model\r\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model_name)\r\n",
        "  tflite_model = converter.convert()\r\n",
        "  # save the model\r\n",
        "  with open(path_to_tflite_file, 'wb') as f:\r\n",
        "    f.write(tflite_model) "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMWchS12MDV-"
      },
      "source": [
        "**How To ...**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISzdHYfjMGna"
      },
      "source": [
        "### for understanding purposes ###\r\n",
        "# how to get the keys in your model\r\n",
        "# for key in hist.history:\r\n",
        "#   print(key)\r\n",
        "\r\n",
        "# how to check prediction \r\n",
        "# test_predict = model_mn.predict(test_images, batch_size=10, verbose=0)\r\n",
        "# len(test_predict)\r\n",
        "### for understanding purposes ###"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f-ntz2xgQKW"
      },
      "source": [
        "**A basic CNN - Model Definition, Train, Validate, Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hk8or_Jz05B"
      },
      "source": [
        "Let us see the results with a basic CNN - accuracy might not be great, however, we will get an idea of a working CNN model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqBMXPbi0Jeg"
      },
      "source": [
        "# import libraries\r\n",
        "from keras import models\r\n",
        "from keras import layers"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "523ohH6B0PwH"
      },
      "source": [
        "# define model\r\n",
        "def define_model_basicCNN():\r\n",
        "  model = models.Sequential()\r\n",
        "  # 2 dimensional convolution for 2D image. relu for non-linearity detection\r\n",
        "  model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)))\r\n",
        "  model.add(layers.MaxPooling2D(2,2))\r\n",
        "  model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\r\n",
        "  model.add(layers.MaxPooling2D(2,2))\r\n",
        "  model.add(layers.Conv2D(64, (3,3), activation='relu'))\r\n",
        "  # Data at this stage is in matrix form. We will convert it to vector form to feed to a fully connected network (FCN).\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  # We will design for 64 outputs with activation function as relu (to learn non-linearity).\r\n",
        "  model.add(layers.Dense(64, activation = 'relu'))\r\n",
        "  # This is the final layer. Hence, the outputs will be 2 corresponding to the 2 classes:\r\n",
        "  # clinical heart failure = yes: 1 ; clinical heart failure = no: 0\r\n",
        "  # Activation Function chosen here is softmax to have a probabilistic output. \r\n",
        "  model.add(layers.Dense(2, activation = 'softmax'))\r\n",
        "  return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0epP_4IO5skk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02860258-ac10-437b-ce6b-e5ac5e4860eb"
      },
      "source": [
        "model_basicCNN = define_model_basicCNN()\r\n",
        "# model_basicCNN.summary()\r\n",
        "\r\n",
        "# Define Optimizer, Loss Function and Metrics to be used for the Model\r\n",
        "# Going ahead with the well known functions at this point in time\r\n",
        "# Selected accuracy as the metrics to understand validation accuracy of the model\r\n",
        "model_basicCNN.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# train and validate the model\r\n",
        "model_basicCNN.fit(train_images, train_labels, epochs = EPOCHS, batch_size = BATCH_SIZE, validation_data = (validation_images, validation_labels))\r\n",
        "\r\n",
        "# test model\r\n",
        "test_loss, test_acc = model_basicCNN.evaluate(test_images, test_labels)\r\n",
        "print('test accuracy:', (test_acc*100))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77/77 [==============================] - 8s 21ms/step - loss: 510.7575 - accuracy: 0.5178 - val_loss: 0.6960 - val_accuracy: 0.4572\n",
            "37/37 [==============================] - 1s 14ms/step - loss: 0.6945 - accuracy: 0.4996\n",
            "test accuracy: 49.956709146499634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLrjWjwxrpmY"
      },
      "source": [
        "**ResNet50**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVYSHHC7Ed3E"
      },
      "source": [
        "**ResNet50 Transfer Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9m-f6ZreR4I"
      },
      "source": [
        "**ResNet50 XFR: Import required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hre2PwNacJG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb4cab4-54a7-4668-f7c0-37ba63c7d2f4"
      },
      "source": [
        "###############################################################################################################################################################################\r\n",
        "# IMPORT LIBRARIES #\r\n",
        "print('ResNet50 XFR / Import Libraries: Starting')\r\n",
        "from keras.applications.resnet50 import ResNet50\r\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\r\n",
        "from keras.models import Model\r\n",
        "# from keras.optimizers import SGD\r\n",
        "# from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.optimizers import Adam\r\n",
        "# from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.layers.core import Dense, Dropout, Activation\r\n",
        "print('ResNet50 XFR / Import Libraries: Completed')\r\n",
        "###############################################################################################################################################################################"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet50 XFR / Import Libraries: Starting\n",
            "ResNet50 XFR / Import Libraries: Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXaksRrOeYFJ"
      },
      "source": [
        "**ResNet50 XFR: Define function to define the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJFT0WnGcB53"
      },
      "source": [
        "def define_model_resnet50xfr():\r\n",
        "  ###############################################################################################################################################################################\r\n",
        "  # MODEL DEFINITION #\r\n",
        "  print('ResNet50 XFR / Model Definition: Starting')\r\n",
        "  # load ResNet50 with pre-trained parameters for 'imagenet' challenge\r\n",
        "  # disable the last layer ... so that we can have our own FCN layer for our desired classes\r\n",
        "  resnet50 = ResNet50(include_top=False, weights='imagenet')\r\n",
        "\r\n",
        "  # define the last layers\r\n",
        "\r\n",
        "  # get the output of the last layer of the ResNet50\r\n",
        "  prediction = resnet50.output\r\n",
        "\r\n",
        "  # add a Global Average Pooling layer (GAP) - this helps reduce number of parameters as compared to a flatten/dense layer\r\n",
        "  prediction = GlobalAveragePooling2D()(prediction)\r\n",
        "\r\n",
        "  # add a custom FCN  \r\n",
        "  # prediction = Dense(1024, activation = 'relu')(prediction)\r\n",
        "  # we will split the actions so that we can test Batch Normalization done befor relu\r\n",
        "  prediction = Dense(DENSE_LAYER_NEURONS)(prediction)\r\n",
        "  # BatchNormalization did not help as the binary classes are balanced, hence commented BatchNormalization \r\n",
        "  # prediction = BatchNormalization()(prediction)\r\n",
        "  prediction = Activation('relu')(prediction)\r\n",
        "  # add a dropout to avoid overfitting\r\n",
        "  prediction = Dropout(DENSE_LAYER_DROPOUT)(prediction)\r\n",
        "\r\n",
        "  # add a FCN with 2 output neurons corresponding to the 2 classes we want to predict\r\n",
        "  prediction = Dense(2, activation = 'softmax')(prediction)\r\n",
        "\r\n",
        "  # connect the last layers with ResNet50 output layer to define the model\r\n",
        "  model = Model(inputs = resnet50.input, outputs = prediction)\r\n",
        "\r\n",
        "  # we wish use the pretrained ResNet50 model as is i.e. do not want it's parameters to get updated during training\r\n",
        "  for layer in resnet50.layers:\r\n",
        "    layer.trainable = False\r\n",
        "\r\n",
        "  # define the optimizer, loss function, metrics we will use\r\n",
        "  # Adam provided better results than SGD, hence commented SGD\r\n",
        "  # model.compile(optimizer = SGD(lr=0.0001, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
        "  model.compile(optimizer = Adam(lr=LEARNING_RATE), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "  # run to see layers, number of parameters (total/trainable/non-trainable)\r\n",
        "  # model.summary()\r\n",
        "\r\n",
        "  # calculate FLOPS for the model\r\n",
        "  flops_resnet50_xfr = get_flops(model, batch_size = 1)\r\n",
        "  print(f\"ResNet50 XFR FLOPS: {flops_resnet50_xfr / 10 ** 9:.03} G\")\r\n",
        "  print('ResNet50 XFR / Model Definition: Completed')\r\n",
        "  return model\r\n",
        "  ###############################################################################################################################################################################\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGI0LW7ukVzG"
      },
      "source": [
        "**ResNet50 XFR: Data Augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg9o1x9Redfu"
      },
      "source": [
        "Tried data augmentation - It did not help improve the accuracy as the binary classes are pretty balanced, hence, commented it off. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxci4U3UeJQW"
      },
      "source": [
        "###############################################################################################################################################################################\r\n",
        "# DATA AUGMENTATION #\r\n",
        "# commented as this did not help improve accuracy\r\n",
        "# data augmentation helps change the data slightly so that the model does not overfit\r\n",
        "# train_generator = ImageDataGenerator(rotation_range = 8, width_shift_range = 0.08, shear_range = 0.3, height_shift_range = 0.08, zoom_range = 0.08)\r\n",
        "# validation_generator = ImageDataGenerator()\r\n",
        "# below ensures the augmented data is provided in batches to the model\r\n",
        "# train_augmented = train_generator.flow(train_images, train_labels, batch_size = 10)\r\n",
        "# validation_augmented = validation_generator.flow(validation_images, validation_labels, batch_size = 10)\r\n",
        "# train and validate model with augmented data\r\n",
        "# model.fit(train_augmented, epochs = 20, batch_size = 10, validation_data = validation_augmented)\r\n",
        "###############################################################################################################################################################################"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWonjggxiJAQ"
      },
      "source": [
        "**ResNet50 XFR: Train/Validate/Test/Cross Validate the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZJjUo8xiQMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f32c86-7cfe-4dce-eb76-f3037b54163a"
      },
      "source": [
        "print('#########################################################################################################################################')\r\n",
        "model_resnet50xfr = define_model_resnet50xfr()\r\n",
        "#model_resnet50xfr.summary()\r\n",
        "path_to_resnet50xfr_params_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5'\r\n",
        "model_resnet50xfr = train_and_validate_model(model_resnet50xfr, train_images, train_labels, validation_images, validation_labels,path_to_resnet50xfr_params_file)\r\n",
        "model_resnet50xfr = test_model_with_best_params(model_resnet50xfr,path_to_resnet50xfr_params_file, test_images, test_labels)\r\n",
        "print('#########################################################################################################################################')\r\n",
        "if (CROSS_VALIDATE == True):\r\n",
        "  # cross validate and get the path to the file containing best cross validation fold's parameters\r\n",
        "  path_to_resnet50xfr_best_cv_fold_params_file = cross_validate_model('resnet50xfr', all_images, all_labels, all_labels_before_categorical)\r\n",
        "  print(f'Path to Best CV Fold Params: {path_to_resnet50xfr_best_cv_fold_params_file}')\r\n",
        "  # define a model, load best cross validation fold params, test\r\n",
        "  model_resnet50xfr_cv = define_model_resnet50xfr()\r\n",
        "  model_resnet50xfr_cv = test_model_with_best_params(model_resnet50xfr_cv,path_to_resnet50xfr_best_cv_fold_params_file, test_images, test_labels)\r\n",
        "  # convert to TensorFlowLite Model\r\n",
        "  # as we have loaded the model with params from the best cross validation fold for testing, we need not do it again. \r\n",
        "  # create the folder 'resnet50xfr_cv' at desired location and then run the cell else it is giving error\r\n",
        "  path_to_resnet50xfr_cv_tflite_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/TFLite/resnet50xfr_cv/resnet50xfr_cv.tflite'\r\n",
        "  convert_keras_model_to_tflite(model_resnet50xfr_cv, path_to_resnet50xfr_cv_tflite_file)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#########################################################################################################################################\n",
            "ResNet50 XFR / Model Definition: Starting\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py:4893: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "ResNet50 XFR FLOPS: 0.0021 G\n",
            "ResNet50 XFR / Model Definition: Completed\n",
            "Model Train and Validation: Starting\n",
            "77/77 [==============================] - 8s 54ms/step - loss: 6.5412 - accuracy: 0.6114 - val_loss: 0.5217 - val_accuracy: 0.7380\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.73797, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50_xfr.hdf5\n",
            "Train and Validation Time = 11.66497278213501s\n",
            "Model Train and Validation: Completed\n",
            "Model Test: Starting\n",
            "37/37 [==============================] - 3s 63ms/step - loss: 0.5797 - accuracy: 0.7126\n",
            "Test Time = 2.588782787322998s\n",
            "Test Time / sample = 0.0022413703786346305s\n",
            "Model Test: Completed\n",
            "#########################################################################################################################################\n",
            "Model Cross Validation: Starting\n",
            "ResNet50 XFR / Model Definition: Starting\n",
            "ResNet50 XFR FLOPS: 0.0021 G\n",
            "ResNet50 XFR / Model Definition: Completed\n",
            "58/58 [==============================] - 8s 74ms/step - loss: 6.4244 - accuracy: 0.6036 - val_loss: 0.4260 - val_accuracy: 0.8077\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.80769, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50xfr_cvfold_0.hdf5\n",
            "Cross Validation Accuracy: 80.77%\n",
            "Fold #0 Complete \n",
            "\n",
            "ResNet50 XFR / Model Definition: Starting\n",
            "ResNet50 XFR FLOPS: 0.0021 G\n",
            "ResNet50 XFR / Model Definition: Completed\n",
            "58/58 [==============================] - 8s 81ms/step - loss: 6.3720 - accuracy: 0.5936 - val_loss: 0.5661 - val_accuracy: 0.7220\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.72203, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50xfr_cvfold_1.hdf5\n",
            "Cross Validation Accuracy: 72.20%\n",
            "Fold #1 Complete \n",
            "\n",
            "Cross Validation Accuracy Mean (+/- Std Deviation): 76.49% (+/- 4.28%)\n",
            "Cross Validation Time = 33.71005344390869s\n",
            "Model Cross Validation: Completed\n",
            "Path to Best CV Fold Params: /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50xfr_cvfold_0.hdf5\n",
            "ResNet50 XFR / Model Definition: Starting\n",
            "ResNet50 XFR FLOPS: 0.0021 G\n",
            "ResNet50 XFR / Model Definition: Completed\n",
            "Model Test: Starting\n",
            "37/37 [==============================] - 4s 61ms/step - loss: 0.5683 - accuracy: 0.7303\n",
            "Test Time = 4.0251007080078125s\n",
            "Test Time / sample = 0.003484935677928842s\n",
            "Model Test: Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9zNP4ygcivC"
      },
      "source": [
        "**MobileNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hANLFYuUrv3b"
      },
      "source": [
        "**MobileNet: Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETVbUHdZr1uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e100d201-a623-4c6b-9b6a-a005a3404644"
      },
      "source": [
        "############################################################################################################################################################################\r\n",
        "# IMPORT LIBRARIES #\r\n",
        "# import libraries\r\n",
        "print(f'MobileNet / Import Libraries: Starting')\r\n",
        "import tensorflow as tf\r\n",
        "from keras.models import Model\r\n",
        "# from keras.optimizers import SGD\r\n",
        "from keras.optimizers import Adam\r\n",
        "# from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.layers.core import Dense, Dropout, Activation\r\n",
        "# from keras.preprocessing.image import ImageDataGenerator\r\n",
        "# from tensorflow.keras import regularizers\r\n",
        "print(f'MobileNet / Import Libraries: Completed')\r\n",
        "############################################################################################################################################################################"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MobileNet / Import Libraries: Starting\n",
            "MobileNet / Import Libraries: Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWFbmY6OsA2V"
      },
      "source": [
        "**MobileNet: Define function to define the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgXtxSsvsJkF"
      },
      "source": [
        "def define_model_mobilenet(version):\r\n",
        "  ############################################################################################################################################################################\r\n",
        "  # MODEL DEFINITION #\r\n",
        "  print(f'MobileNet{version} Model Definition: Starting')\r\n",
        "  # load MobileNet with pre-trained parameters for 'imagenet' challenge\r\n",
        "  if (version == 'V1'):\r\n",
        "    # mobilenet = tf.keras.applications.mobilenet.MobileNet()\r\n",
        "    mobilenet = tf.keras.applications.MobileNet()\r\n",
        "  elif (version == 'V2'):\r\n",
        "    mobilenet = tf.keras.applications.MobileNetV2()\r\n",
        "\r\n",
        "  # understand mobilenet layers   \r\n",
        "  # mobilenet.summary()\r\n",
        "\r\n",
        "  # define the last layers\r\n",
        "\r\n",
        "  # get the output of the last layer of the MobileNet\r\n",
        "  prediction = mobilenet.output\r\n",
        "\r\n",
        "  # mobilenet already has a GAP layer, hence we need to only add a FCN\r\n",
        "\r\n",
        "  # add a FCN w/o regularizer\r\n",
        "  prediction = Dense(DENSE_LAYER_NEURONS, activation = 'relu')(prediction)\r\n",
        "  # add FCN w/ regularizer\r\n",
        "  # did not help improve accuracy, hence, commented\r\n",
        "  # prediction = Dense(1024, activation = 'relu', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4), \r\n",
        "  #                      activity_regularizer = regularizers.l2(1e-5))(prediction)\r\n",
        "\r\n",
        "  # batch normalization\r\n",
        "  # did not help improve accuracy, hence, commented\r\n",
        "  # we will split the actions to have the Batch Normalization done befor relu\r\n",
        "  # prediction = Dense(1024)(prediction)\r\n",
        "  # prediction = BatchNormalization()(prediction)\r\n",
        "  # prediction = Activation('relu')(prediction)\r\n",
        "\r\n",
        "  # add a dropout to avoid overfitting\r\n",
        "  prediction = Dropout(DENSE_LAYER_DROPOUT)(prediction)\r\n",
        "\r\n",
        "  # add a FCN with 2 output neurons corresponding to the 2 classes we want to predict\r\n",
        "  # without regularizer\r\n",
        "  prediction = Dense(2, activation = 'softmax')(prediction)\r\n",
        "  # with regularizer\r\n",
        "  # prediction = Dense(2, activation = 'softmax', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4), \r\n",
        "  #                      activity_regularizer = regularizers.l2(1e-5))(prediction)\r\n",
        "\r\n",
        "  # connect the last layer with MobileNet layer to define the model\r\n",
        "  model = Model(inputs = mobilenet.input, outputs = prediction)\r\n",
        "\r\n",
        "  # we wish use the pretrained MobileNet model as is i.e. do not want it's parameters to get updated during training\r\n",
        "  for layer in mobilenet.layers:\r\n",
        "    layer.trainable = False\r\n",
        "\r\n",
        "  # define the optimizer, loss function, metrics we will use\r\n",
        "  # model.compile(optimizer = SGD(lr=0.0001, momentum = 0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
        "  model.compile(optimizer = Adam(lr=LEARNING_RATE), loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "  # run to see layers, number of parameters (total/trainable/non-trainable)\r\n",
        "  # model.summary()\r\n",
        "\r\n",
        "  # calculate FLOPS for the model\r\n",
        "  flops = get_flops(model, batch_size = 1)\r\n",
        "  print(f\"MobileNet{version} FLOPS: {flops / 10 ** 9:.03} G\")\r\n",
        "\r\n",
        "  # let us check the layers in the model \r\n",
        "  # for i,layer in enumerate(model.layers):\r\n",
        "  #  print(i,layer.name)\r\n",
        "\r\n",
        "  print(f'MobileNet{version} Model Definition: Completed')\r\n",
        "  return model\r\n",
        "  ############################################################################################################################################################################"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6lL6XsUecTX"
      },
      "source": [
        "**MobileNetV1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sww0CUIYtWh7"
      },
      "source": [
        "**MobileNetV1 XFR: Train/Validate/Test/Cross Validate/Convert the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CNoi9dHtT4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdbf9e3-1ef7-481d-8d68-493801c04252"
      },
      "source": [
        "print('#######################################################################################################################################')\r\n",
        "model_mobilenetv1xfr = define_model_mobilenet('V1')\r\n",
        "#model_mobilenetv1xfr.summary()\r\n",
        "path_to_mobilenetv1xfr_params_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv1xfr.hdf5'\r\n",
        "model_mobilenetv1xfr = train_and_validate_model(model_mobilenetv1xfr, train_images, train_labels, validation_images, validation_labels,path_to_mobilenetv1xfr_params_file)\r\n",
        "model_mobilenetv1xfr = test_model_with_best_params(model_mobilenetv1xfr, path_to_mobilenetv1xfr_params_file, test_images, test_labels)\r\n",
        "print('#######################################################################################################################################')\r\n",
        "if (CROSS_VALIDATE == True):\r\n",
        "  # cross validate and get the path to the file containing best cross validation fold's parameters\r\n",
        "  path_to_mobilenetv1xfr_best_cv_fold_params_file = cross_validate_model('mobilenetv1xfr', all_images, all_labels, all_labels_before_categorical)\r\n",
        "  print(f'Path to Best CV Fold Params: {path_to_mobilenetv1xfr_best_cv_fold_params_file}')\r\n",
        "  # define a model, load best cross validation fold params, test\r\n",
        "  model_mobilenetv1xfr_cv = define_model_mobilenet('V1')\r\n",
        "  model_mobilenetv1xfr_cv = test_model_with_best_params(model_mobilenetv1xfr_cv, path_to_mobilenetv1xfr_best_cv_fold_params_file, test_images, test_labels)\r\n",
        "  # convert to TensorFlowLite Model\r\n",
        "  # as we have loaded the model with params from the best cross validation fold for testing, we need not do it again. \r\n",
        "  # create the folder 'mobilenetv1xfr_cv' at desired location and then run the cell else it is giving error\r\n",
        "  path_to_mobilenetv1xfr_cv_tflite_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/TFLite/mobilenetv1xfr_cv/mobilenetv1xfr_cv.tflite'\r\n",
        "  convert_keras_model_to_tflite(model_mobilenetv1xfr_cv, path_to_mobilenetv1xfr_cv_tflite_file)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#######################################################################################################################################\n",
            "MobileNetV1 Model Definition: Starting\n",
            "MobileNetV1 FLOPS: 1.15 G\n",
            "MobileNetV1 Model Definition: Completed\n",
            "Model Train and Validation: Starting\n",
            "77/77 [==============================] - 4s 34ms/step - loss: 0.6250 - accuracy: 0.6636 - val_loss: 0.4834 - val_accuracy: 0.8155\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.81551, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv1xfr.hdf5\n",
            "Train and Validation Time = 5.554941892623901s\n",
            "Model Train and Validation: Completed\n",
            "Model Test: Starting\n",
            "37/37 [==============================] - 1s 29ms/step - loss: 0.5398 - accuracy: 0.7463\n",
            "Test Time = 1.1241309642791748s\n",
            "Test Time / sample = 0.0009732735621464717s\n",
            "Model Test: Completed\n",
            "#######################################################################################################################################\n",
            "Model Cross Validation: Starting\n",
            "MobileNetV1 Model Definition: Starting\n",
            "MobileNetV1 FLOPS: 1.15 G\n",
            "MobileNetV1 Model Definition: Completed\n",
            "58/58 [==============================] - 4s 36ms/step - loss: 0.5752 - accuracy: 0.7202 - val_loss: 0.5388 - val_accuracy: 0.7360\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.73601, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv1xfr_cvfold_0.hdf5\n",
            "Cross Validation Accuracy: 73.60%\n",
            "Fold #0 Complete \n",
            "\n",
            "MobileNetV1 Model Definition: Starting\n",
            "MobileNetV1 FLOPS: 1.15 G\n",
            "MobileNetV1 Model Definition: Completed\n",
            "58/58 [==============================] - 4s 36ms/step - loss: 0.6272 - accuracy: 0.6390 - val_loss: 0.4955 - val_accuracy: 0.7745\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.77448, saving model to /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv1xfr_cvfold_1.hdf5\n",
            "Cross Validation Accuracy: 77.45%\n",
            "Fold #1 Complete \n",
            "\n",
            "Cross Validation Accuracy Mean (+/- Std Deviation): 75.52% (+/- 1.92%)\n",
            "Cross Validation Time = 14.351134777069092s\n",
            "Model Cross Validation: Completed\n",
            "Path to Best CV Fold Params: /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv1xfr_cvfold_1.hdf5\n",
            "MobileNetV1 Model Definition: Starting\n",
            "MobileNetV1 FLOPS: 1.15 G\n",
            "MobileNetV1 Model Definition: Completed\n",
            "Model Test: Starting\n",
            "37/37 [==============================] - 2s 28ms/step - loss: 0.5245 - accuracy: 0.7463\n",
            "Test Time = 2.124828338623047s\n",
            "Test Time / sample = 0.0018396782152580492s\n",
            "Model Test: Completed\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpuouie5vn/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpuouie5vn/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWO-NGSLwxmY"
      },
      "source": [
        "**MobileNetV1 FT: Train/Validate/Test/Cross Validate the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veu87gYXOgvW"
      },
      "source": [
        "print('#######################################################################################################################################')\r\n",
        "model_mobilenetv1ft = define_model_mobilenet('V1')\r\n",
        "set_trainable_layers_starting_from(model_mobilenetv1ft, MOBILENETV1_TRAINABLE_START_LAYER)\r\n",
        "model_mobilenetv1ft.load_weights(path_to_mobilenetv1xfr_params_file)\r\n",
        "#model_mobilenetv1ft.summary()\r\n",
        "path_to_mobilenetv1ft_params_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv1ft.hdf5'\r\n",
        "model_mobilenetv1ft = train_and_validate_model(model_mobilenetv1ft, train_images, train_labels, validation_images, validation_labels, path_to_mobilenetv1ft_params_file)\r\n",
        "model_mobilenetv1ft = test_model_with_best_params(model_mobilenetv1ft, path_to_mobilenetv1ft_params_file, test_images, test_labels)\r\n",
        "print('#######################################################################################################################################')\r\n",
        "# we shall provide the best params from transfer learning to initialize the model at cross validation\r\n",
        "if (CROSS_VALIDATE == True):\r\n",
        "  # cross validate and get the path to the file containing best cross validation fold's parameters\r\n",
        "  path_to_mobilenetv1ft_best_cv_fold_params_file = cross_validate_model('mobilenetv1ft', all_images, all_labels, all_labels_before_categorical, path_to_mobilenetv1xfr_params_file)\r\n",
        "  print(f'Path to Best CV Fold Params: {path_to_mobilenetv1ft_best_cv_fold_params_file}')\r\n",
        "  # define a model, load best cross validation fold params, test\r\n",
        "  model_mobilenetv1ft_cv = define_model_mobilenet('V1')\r\n",
        "  model_mobilenetv1ft_cv = test_model_with_best_params(model_mobilenetv1ft_cv, path_to_mobilenetv1ft_best_cv_fold_params_file, test_images, test_labels)\r\n",
        "  # convert to TensorFlowLite Model\r\n",
        "  # as we have loaded the model with params from the best cross validation fold for testing, we need not do it again. \r\n",
        "  # create the folder 'mobilenetv1ft_cv' at desired location and then run the cell else it is giving error\r\n",
        "  path_to_mobilenetv1ft_cv_tflite_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/TFLite/mobilenetv1ft_cv/mobilenetv1ft_cv.tflite'\r\n",
        "  convert_keras_model_to_tflite(model_mobilenetv1ft_cv, path_to_mobilenetv1ft_cv_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgLlO_ddeh5U"
      },
      "source": [
        "**MobileNetV2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzM5VhrDVK1Q"
      },
      "source": [
        "**MobileNetV2 XFR: Train/Validate/Test/Cross Validate the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6FBV_FcVM2U"
      },
      "source": [
        "print('#######################################################################################################################################')\r\n",
        "model_mobilenetv2xfr = define_model_mobilenet('V2')\r\n",
        "#model_mobilenetv2xfr.summary()\r\n",
        "path_to_mobilenetv2xfr_params_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv2xfr.hdf5'\r\n",
        "model_mobilenetv2xfr = train_and_validate_model(model_mobilenetv2xfr, train_images, train_labels, validation_images, validation_labels, path_to_mobilenetv2xfr_params_file)\r\n",
        "model_mobilenetv2xfr = test_model_with_best_params(model_mobilenetv2xfr, path_to_mobilenetv2xfr_params_file, test_images, test_labels)\r\n",
        "print('#######################################################################################################################################')\r\n",
        "if (CROSS_VALIDATE == True):\r\n",
        "  # cross validate and get the path to the file containing best cross validation fold's parameters\r\n",
        "  path_to_mobilenetv2xfr_best_cv_fold_params_file = cross_validate_model('mobilenetv2xfr', all_images, all_labels, all_labels_before_categorical)\r\n",
        "  print(f'Path to Best CV Fold Params: {path_to_mobilenetv2xfr_best_cv_fold_params_file}')\r\n",
        "  # define a model, load best cross validation fold params, test\r\n",
        "  model_mobilenetv2xfr_cv = define_model_mobilenet('V2')\r\n",
        "  model_mobilenetv2xfr_cv = test_model_with_best_params(model_mobilenetv2xfr_cv, path_to_mobilenetv2xfr_best_cv_fold_params_file, test_images, test_labels)\r\n",
        "  # convert to TensorFlowLite Model\r\n",
        "  # as we have loaded the model with params from the best cross validation fold for testing, we need not do it again. \r\n",
        "  # create the folder 'mobilenetv2xfr_cv' at desired location and then run the cell else it is giving error\r\n",
        "  path_to_mobilenetv2xfr_cv_tflite_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/TFLite/mobilenetv2xfr_cv/mobilenetv2xfr_cv.tflite'\r\n",
        "  convert_keras_model_to_tflite(model_mobilenetv2xfr_cv, path_to_mobilenetv2xfr_cv_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjFrxVLbVNHj"
      },
      "source": [
        "**MobileNetV2 FT: Train/Validate/Test/Cross Validate the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIn16VbDVNyz"
      },
      "source": [
        "print('#######################################################################################################################################')\r\n",
        "model_mobilenetv2ft = define_model_mobilenet('V2')\r\n",
        "set_trainable_layers_starting_from(model_mobilenetv2ft, MOBILENETV2_TRAINABLE_START_LAYER)\r\n",
        "model_mobilenetv2ft.load_weights(path_to_mobilenetv2xfr_params_file)\r\n",
        "#model_mobilenetv2ft.summary()\r\n",
        "path_to_mobilenetv2ft_params_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv2ft.hdf5'\r\n",
        "model_mobilenetv2ft = train_and_validate_model(model_mobilenetv2ft, train_images, train_labels, validation_images, validation_labels, path_to_mobilenetv2ft_params_file)\r\n",
        "model_mobilenetv2ft = test_model_with_best_params(model_mobilenetv2ft, path_to_mobilenetv2ft_params_file, test_images, test_labels)\r\n",
        "print('#######################################################################################################################################')\r\n",
        "# we shall provide the best params from transfer learning to initialize the model at cross validation\r\n",
        "if (CROSS_VALIDATE == True):\r\n",
        "  # cross validate and get the path to the file containing best cross validation fold's parameters\r\n",
        "  path_to_mobilenetv2ft_best_cv_fold_params_file = cross_validate_model('mobilenetv2ft', all_images, all_labels, all_labels_before_categorical, path_to_mobilenetv2xfr_params_file)\r\n",
        "  print(f'Path to Best CV Fold Params: {path_to_mobilenetv2ft_best_cv_fold_params_file}')\r\n",
        "  # define a model, load best cross validation fold params, test\r\n",
        "  model_mobilenetv2ft_cv = define_model_mobilenet('V2')\r\n",
        "  model_mobilenetv2ft_cv = test_model_with_best_params(model_mobilenetv2ft_cv, path_to_mobilenetv2ft_best_cv_fold_params_file, test_images, test_labels)\r\n",
        "  # convert to TensorFlowLite Model\r\n",
        "  # as we have loaded the model with params from the best cross validation fold for testing, we need not do it again. \r\n",
        "  # create the folder 'mobilenetv2ft_cv' at desired location and then run the cell else it is giving error\r\n",
        "  path_to_mobilenetv2ft_cv_tflite_file = '/content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/TFLite/mobilenetv2ft_cv/mobilenetv2ft_cv.tflite'\r\n",
        "  convert_keras_model_to_tflite(model_mobilenetv2ft_cv, path_to_mobilenetv2ft_cv_tflite_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTijnel0I8P9"
      },
      "source": [
        "### TODO / Improvement Opportunity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43vNOnzBTUx1"
      },
      "source": [
        "- **TRIED**: As this is a 2 class classification - loss function can be changed to binary_crossentropy instead of categorical_crossentropy\n",
        "- **DONE**: Change model to ResNet50\n",
        "- **DONE**: Convert code sections in data preparation for train/validation/test to functions\n",
        "- **TRIED**: Reduce parameters, epochs.\n",
        "- **TRIED**: Try changing batch size\n",
        "- **TRIED**: Use Data Augmentation\n",
        "- **DONE**: Try to train last few layers of ResNet50 with the data\n",
        "- **TRIED**: Accuracy is fluctuating... optimize hyper parameters to have a smooth increase\n",
        "- **TRIED**: Try Regularization\n",
        "- **DONE**:Our image size is 250x250. ResNet50 expects 224x224. Do we need to do anything or ResNet50 will understand ? Resizing for all models\n",
        "- **DONE**: Change Model to MobileNet\n",
        "- **DONE**: Is image resize done correctly for MobileNet ?\n",
        "- **DONE**: Implement K Cross Validation for Epoch = 1, Fold = 4\n",
        "- **DONE**: Implement FLOPS\n",
        "- **DONE**: Check version of MobileNet ... try using tf.keras.applications.MobileNet() instead of tf.keras.applications.mobilenet.MobileNet()\n",
        "- Query: Should the batch_size be 1 or 10 for FLOPS calculation\n",
        "- Query: There should not be any difference in FLOPS for Transfer/FineTune Model, correct ?\n",
        "- **DONE**: Run K Cross Validation for Epoch = 100, Fold = 4\n",
        "- **DONE**: IO: Convert K-cross validation sections into functions\n",
        "- IO: Save best k fold of MobileNet Transfer and use for FineTune\n",
        "- Use only the train and validation for cross validation ... so that you can use the test for test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w_KqR7YndCM"
      },
      "source": [
        "### Version 0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2nIQ6Q_neD8"
      },
      "source": [
        "- make epoch to 1, cv folds = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq-RW6reJlVe"
      },
      "source": [
        "### Version 0.25-0.27: Make code ready for Android App / Cross validate on Train and Val Data only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mte5dlSMJoYF"
      },
      "source": [
        "- **0.25-0.26**\r\n",
        "  - We will make the Cross Validation to also store the best parameters so that we can then use them for test. For this, we will use only the train and validation images/labels for Cross Validation... so that post Cross Validation, we can use the test images/labels for Testing \r\n",
        "  - We will try converting the models to TensorFlowLite Models so that it can then be ported to Android App - implemented only for MobileNetV1 Transfer Learning\r\n",
        "  - Will make the epoch = 1, cross validation folds = 2 for now.\r\n",
        "  - worked\r\n",
        "- **0.27**\r\n",
        "  - run for epoch = 100, folds - 4\r\n",
        "  - converted MobileNetV1 Fine Tuning Model also to TensorFlowLite.\r\n",
        "  - **Resnet50 XFR**\r\n",
        "    - Conv Layer / Total Params / Trainable Params / FLOPS = 5 / ~24.6M / ~1.1M / 0.0021G\r\n",
        "    - Regular Run: \r\n",
        "      - Total params: 24,637,826, Trainable params: 1,050,114, Non-trainable params: 23,587,712\r\n",
        "      - Train and Validation Time (time) = 554.2369706630707s\r\n",
        "      - Train / Val / Test Acc % = 91.4 / 89.3 / 81.5\r\n",
        "      - Test Time (time) = 4.689838409423828s\r\n",
        "      - Test Time / sample (time) = 0.004060466155345306s\r\n",
        "    - CV: \r\n",
        "      - Cross Validation Time (time) = 2360.335835456848s\r\n",
        "      - Cross Validation Accuracy Mean (+/- Std Deviation): **79.81% (+/- 3.80%)**\r\n",
        "      - Best CV Acc = **82.9%**\r\n",
        "      - Test Acc = **80.2%**\r\n",
        "      - Test Time (time) = 6.264003276824951s\r\n",
        "      - Test Time / sample (time) = 0.005423379460454503s\r\n",
        "      - Path to Best CV Fold Params: /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_resnet50xfr_cvfold_2.hdf5  \r\n",
        "  - **MobileNetV1**\r\n",
        "    - Conv Layer / FLOPS = 13 / 1.15G \r\n",
        "    - **XFR**\r\n",
        "      - Total Params / Trainable Params = ~4.8M / ~0.5M\r\n",
        "        - Total params: 4,767,402 , Trainable params: 513,538 , Non-trainable params: 4,253,864\r\n",
        "      - Regular Run:\r\n",
        "        - Train and Validation Time (time) = 239.36364245414734s\r\n",
        "        - Train / Val / Test Acc % = 78.2 / 84.5 / 79.1\r\n",
        "        - Test Time (time) = 2.1142632961273193s\r\n",
        "        - Test Time / sample (time) = 0.0018305309923180254s\r\n",
        "      - CV: \r\n",
        "        - Cross Validation Time (time) = 1021.4970147609711s\r\n",
        "        - Cross Validation Accuracy Mean (+/- Std Deviation): **75.44% (+/- 4.09%)**\r\n",
        "        - Best CV Acc = **81.1%** \r\n",
        "        - Test Acc = **76.4%**\r\n",
        "        - Test Time (time) = 2.922698497772217s\r\n",
        "        - Test Time / sample (time) = 0.0025304748898460753s\r\n",
        "        - Path to Best CV Fold Params: /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv1xfr_cvfold_3.hdf5\r\n",
        "    - **FT**\r\n",
        "      - Total Params / Trainable Params = ~4.8M / ~2.6M\r\n",
        "        - Total params: 4,767,402 , Trainable params: 2,600,426 , Non-trainable params: 2,166,976\r\n",
        "      - Regular Run: \r\n",
        "        - Train and Validation Time (time) = 237.16838598251343s\r\n",
        "        - Train / Val / Test Acc % = 77.9 / 85.3 / 78.3 \r\n",
        "        - Test Time (time) = 2.079399585723877s\r\n",
        "        - Test Time / sample (time) = 0.0018003459616656944s\r\n",
        "      - CV: \r\n",
        "        - Cross Validation Time (time) = 1007.7840912342072s\r\n",
        "        - Cross Validation Accuracy Mean (+/- Std Deviation): **80.86% (+/- 1.36%)**\r\n",
        "        - Best CV Acc = **82.2%**\r\n",
        "        - Test Acc = **75.7%**\r\n",
        "        - Test Time (time) = 2.910604953765869s\r\n",
        "        - Test Time / sample (time) = 0.0025200042889747783s\r\n",
        "        - Path to Best CV Fold Params: /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv1ft_cvfold_2.hdf5\r\n",
        "\r\n",
        "  - **MobileNetV2**\r\n",
        "  - Conv Layer / FLOPS = TBD / 0.616G \r\n",
        "  - **XFR**\r\n",
        "    - Total Params / Trainable Params = ~4.1M / ~0.5M\r\n",
        "      - Total params: 4,052,522 , Trainable params: 513,538 , Non-trainable params: 3,538,984\r\n",
        "    - Regular Run:\r\n",
        "      - Train and Validation Time (time) = 279.14059805870056s\r\n",
        "      - Train / Val / Test Acc % = 72.8 / 80.8 / 55.3 \r\n",
        "      - Test Time (time) = 2.407776117324829s\r\n",
        "      - Test Time / sample (time) = 0.002084654647034484s\r\n",
        "    - CV: \r\n",
        "      - Cross Validation Time (time) = 1208.8567435741425s\r\n",
        "      - Cross Validation Accuracy Mean (+/- Std Deviation): **71.68% (+/- 3.02%)**\r\n",
        "      - Best CV Acc = **76.2%**\r\n",
        "      - Test Acc = **65.6%**\r\n",
        "      - Test Time (time) = 3.658114194869995s\r\n",
        "      - Test Time / sample (time) = 0.0031671984371168787s\r\n",
        "      - Path to Best CV Fold Params: /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv2xfr_cvfold_1.hdf5\r\n",
        "  - **FT**\r\n",
        "    - Total Params / Trainable Params = ~4.1M / ~2.2M\r\n",
        "      - Total params: 4,052,522 , Trainable params: 2,206,698 , Non-trainable params: 1,845,824\r\n",
        "    - Regular Run: \r\n",
        "      - Train and Validation Time (time) = 281.10192251205444s\r\n",
        "      - Train / Val / Test Acc % = 77.1 / 81.3 / 73.0\r\n",
        "      - Test Time (time) = 2.438354969024658s\r\n",
        "      - Test Time / sample (time) = 0.0021111298433113923s \r\n",
        "    - CV: \r\n",
        "      - Cross Validation Time (time) = 1198.4848034381866s\r\n",
        "      - Cross Validation Accuracy Mean (+/- Std Deviation): **74.83% (+/- 1.08%)**\r\n",
        "      - Best CV Acc = **76.6%**\r\n",
        "      - Test Acc = **73.1%**\r\n",
        "      - Test Time (time) = 3.6701042652130127s\r\n",
        "      - Test Time / sample (time) = 0.003177579450400877s\r\n",
        "      - Path to Best CV Fold Params: /content/gdrive/MyDrive/Colab Notebooks/Clinical Heart Failure using H&E Images/best_mobilenetv2ft_cvfold_2.hdf5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBUEnaGfcVYx"
      },
      "source": [
        "### Version 0.24: Will do full run 100 epoch, CV with the cleaned code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ7yTbnIcipk"
      },
      "source": [
        "- **0.24**\r\n",
        "  - added model.summary() for each model\r\n",
        "  - deleted monolithic commented code for resnet50, mobilenet\r\n",
        "  - XFR = Transfer Learning, FT = Fine tuning\r\n",
        "  - For Regular Run: Train & Test Acc is w.r.t. Best Val Accuracy.\r\n",
        "  - Common Hyper parameters: Batchsize = 10, Learning Rate = 0.01, Neurons after Conv = 512, Dropout = 0.4. \r\n",
        "  - **Resnet50 XFR**\r\n",
        "    - Conv Layer / Total Params / Trainable Params / FLOPS = 5 / ~24.6M / ~1.1M / 0.0021G \r\n",
        "      - Total params: 24,637,826, Trainable params: 1,050,114, Non-trainable params: 23,587,712  \r\n",
        "    - Regular Run:\r\n",
        "      - Train and Validation Time (time) = 441.68549942970276s\r\n",
        "      - Test Time (time) = 3.7353672981262207s\r\n",
        "      - Test Time (time) / sample = 0.0032340842408019226s \r\n",
        "      - Train / Val / Test Acc % = 90.6 / 89.6 / 81.6\r\n",
        "    - CV: \r\n",
        "      - Cross Validation Time (time) = 2435.15261554718s\r\n",
        "      - **Cross Validation Accuracy Mean (+/- Std Deviation): 85.52% (+/- 4.31%)**\r\n",
        "  - **MobileNetV1**\r\n",
        "    - Conv Layer / FLOPS = 13 / 1.15G \r\n",
        "    - **XFR**\r\n",
        "      - Total Params / Trainable Params = ~4.8M / ~0.5M\r\n",
        "        - Total params: 4,767,402 , Trainable params: 513,538 , Non-trainable params: 4,253,864\r\n",
        "      - Regular Run:\r\n",
        "        - Train and Validation Time (time) = 160.18587827682495s\r\n",
        "        - Test Time (time) = 1.4887826442718506s\r\n",
        "        - Test Time (time) / sample = 0.0012889893023998707s\r\n",
        "        - Train / Val / Test Acc % = 76.8 / 84.0 / 78.0\r\n",
        "      - CV: \r\n",
        "        - Cross Validation Time (time) = 900.9457154273987s\r\n",
        "        - **Cross Validation Accuracy Mean (+/- Std Deviation): 79.12% (+/- 2.54%)**\r\n",
        "    - **FT**\r\n",
        "      - Total Params / Trainable Params = ~4.8M / ~2.6M\r\n",
        "        - Total params: 4,767,402 , Trainable params: 2,600,426 , Non-trainable params: 2,166,976\r\n",
        "      - Regular Run: \r\n",
        "        - Train and Validation Time (time) = 161.2263162136078s\r\n",
        "        - Test Time (time) = 1.5055246353149414s\r\n",
        "        - Test Time (time) / sample = 0.001303484532740209s \r\n",
        "        - Train / Val / Test Acc % = 82.4 / 84.2 / 78.9  \r\n",
        "      - CV: \r\n",
        "        - Cross Validation Time (time) = 899.4915227890015s  \r\n",
        "        - **Cross Validation Accuracy Mean (+/- Std Deviation): 78.77% (+/- 0.45%)**\r\n",
        "  - **MobileNetV2**\r\n",
        "    - Conv Layer / FLOPS = TBD / 0.616G \r\n",
        "    - **XFR**\r\n",
        "      - Total Params / Trainable Params = ~4.1M / ~0.5M\r\n",
        "        - Total params: 4,052,522 , Trainable params: 513,538 , Non-trainable params: 3,538,984\r\n",
        "      - Regular Run:\r\n",
        "        - Train and Validation Time (time) = 190.26020073890686s\r\n",
        "        - Test Time (time) = 1.8131637573242188s\r\n",
        "        - Test Time (time) / sample = 0.0015698387509300595s\r\n",
        "        - Train / Val / Test Acc % = 75.0 / 81.0 / 71.9\r\n",
        "      - CV: \r\n",
        "        - Cross Validation Time (time) = 1015.8775858879089s\r\n",
        "        - **Cross Validation Accuracy Mean (+/- Std Deviation): 75.99% (+/- 0.77%)**\r\n",
        "    - **FT**\r\n",
        "      - Total Params / Trainable Params = ~4.1M / ~2.2M\r\n",
        "        - Total params: 4,052,522 , Trainable params: 2,206,698 , Non-trainable params: 1,845,824\r\n",
        "      - Regular Run: \r\n",
        "        - Train and Validation Time (time) = 185.37927341461182s\r\n",
        "        - Test Time (time) = 1.6549708843231201s\r\n",
        "        - Test Time (time) / sample = 0.001432875224522182s \r\n",
        "        - Train / Val / Test Acc % = 76.7 / 80.2 / 73.1  \r\n",
        "      - CV: \r\n",
        "        - Cross Validation Time (time) = 1015.6089019775391s  \r\n",
        "        - **Cross Validation Accuracy Mean (+/- Std Deviation): 76.77% (+/- 1.76%)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6pKmozJpWkF"
      },
      "source": [
        "### Version 0.21-0.23: Cleaning Code and Converting to Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3YbgK28pcv3"
      },
      "source": [
        "- **0.21**\r\n",
        "  - formatted the version sections\r\n",
        "  - changed epochs = 1, cross validation = false for now.\r\n",
        "  - converted whole of resnet50 into a function\r\n",
        "  - converted whole of mobilenet into a function with attribute to specify version (V1, V2)\r\n",
        "- **0.22**\r\n",
        "  - moved version and reference to bottom of notebook\r\n",
        "  - made pending independent cells in  train/val/test prep areas as part of the prep function.\r\n",
        "- **0.23**\r\n",
        "  - converted code sections of basic CNN into functions\r\n",
        "  - converted code sections of resnet50 into functions\r\n",
        "  - converted code sections of mobilenet into functions\r\n",
        "  - made cross validation folds = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9LFF-vOo6t0"
      },
      "source": [
        "### Version 0.20: Tried MobileNetV2 in place of MobileNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHV5dVhU6SV1"
      },
      "source": [
        "\r\n",
        "- Commented MobileNet and called MobileNetV2 in model definition for Regular Run XFR/FT, CV Run  for XFR and CV Run for FT sections\r\n",
        "- Epochs = 1, CV = False, Dropout = 0.4\r\n",
        "  - XFR: Train / Val / Test Acc % = 59 / 75 / 67\r\n",
        "  - FT @ 80th Layer : Train / Val / Test Acc % = 69 / 69 / 65\r\n",
        "- Epochs = 100, CV = False, Dropout = 0.4\r\n",
        "  - Flops = 0.616G\r\n",
        "  - XFR\r\n",
        "    - Total/Trainable Params = ~4M / ~0.5M\r\n",
        "    - Train / Val / Test Acc % = 76.0 / 80.5 / 72.9\r\n",
        "  - FT @ 80th Layer\r\n",
        "    - Total/Trainable Params = ~4M / ~3.8M\r\n",
        "    - Train / Val / Test Acc % = 76.6 / 80.2 / 72.8\r\n",
        "- Epochs = 100, CV = False, Dropout = 0.4\r\n",
        "  - Flops = 0.616G \r\n",
        "  - XFR\r\n",
        "    - Total/Trainable Params = ~4M / ~0.5M \r\n",
        "    - Train / Val / Test Acc % = 72.4 / 80.0 / 71.6 \r\n",
        "  - FT @ 151th Layer\r\n",
        "    - Total/Trainable Params = ~4M / ~2.2M \r\n",
        "    - Train / Val / Test Acc % =  73.9 / 80.8 / 73.2\r\n",
        "- Epochs = 100, CV = False, Dropout = 0.6\r\n",
        "  - Flops = 0.616G \r\n",
        "  - XFR\r\n",
        "    - Total/Trainable Params = ~4M / ~0.5M \r\n",
        "    - Train / Val / Test Acc % = 76.3 / 80.5 / 70.3\r\n",
        "  - FT @ 151th Layer\r\n",
        "    - Total/Trainable Params = ~4M / ~2.2M \r\n",
        "    - Train / Val / Test Acc % = 76.4 / 81.0 / 72.6 \r\n",
        "- Epochs = 100, CV = True, Dropout = 0.4\r\n",
        "  - Flops = 0.616G \r\n",
        "  - XFR\r\n",
        "    - Total/Trainable Params = ~4M / ~0.5M \r\n",
        "    - Validation Accuracy Mean (+/- Std Deviation): 77.03% (+/- 0.79%)\r\n",
        "  - FT @ 151th Layer\r\n",
        "    - Total/Trainable Params = ~4M / ~2.2M \r\n",
        "    - Validation Accuracy Mean (+/- Std Deviation): 78.99% (+/- 1.06%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuVfy-J79VSx"
      },
      "source": [
        "### Version 0.18-0.19: Rerun of v0.17 with time() to get time values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qPxxxso9YF7"
      },
      "source": [
        "- **0.18-0.19**:\r\n",
        "  - Implemented time function to calculate the desired time more precisely as the time from colab and verbose are not matching.\r\n",
        "  - XFR = Transfer Learning, FT = Fine tuning\r\n",
        "  - For Regular Run: Train & Test Acc is w.r.t. Best Val Accuracy.\r\n",
        "  - Common Hyper parameters: Batchsize = 10, Learning Rate = 0.01, Neurons after Conv = 512, Dropout = 0.4. \r\n",
        "  - **Resnet50 XFR**\r\n",
        "    - Conv Layer / Total Params / Trainable Params / FLOPS = 5 / 25M / 1M / 0.0021G \r\n",
        "      - Total params: 24,637,826, Trainable params: 1,050,114, Non-trainable params: 23,587,712  \r\n",
        "    - Regular Run:\r\n",
        "      - Train Time (time / verbose) = 446.35871052742004s / 411s\r\n",
        "      - Test Time (time / verbose) = 4.191006660461426s / 4s\r\n",
        "      - Test Time / sample (time / verbose) = 0.0036285771952046975s / 0.00346s \r\n",
        "      - Train / Val / Test Acc % = 92.2 / 90.4 / 82.6\r\n",
        "    - CV: \r\n",
        "      - Validation Time (time) = 2644.3752892017365s\r\n",
        "      - Validation Accuracy Mean (+/- Std Deviation): 88.30% (+/- 0.80%)\r\n",
        "  - **MobileNet**\r\n",
        "    - Conv Layer / FLOPS = 13 / 1.15G \r\n",
        "    - **XFR**\r\n",
        "      - Total Params / Trainable Params = 4.8M / 0.5M\r\n",
        "        - Total params: 4,767,402 , Trainable params: 513,538 , Non-trainable params: 4,253,864\r\n",
        "      - Regular Run:\r\n",
        "        - Train Time (time / verbose) = 162.90089511871338s / 202s\r\n",
        "        - Test Time (time / verbose) = 1.819808006286621s / 2s\r\n",
        "        - Test Time / sample (time / verbose) = 0.001575591347434304s / 0.00173s\r\n",
        "        - Train / Val / Test Acc % = 83.2 / 85.0 / 78.4\r\n",
        "      - CV: \r\n",
        "        - Validation Time (time) = 988.1067225933075s\r\n",
        "        - Validation Accuracy Mean (+/- Std Deviation): 78.03% (+/- 0.78%)\r\n",
        "    - **FT**\r\n",
        "      - Total Params / Trainable Params = 4.8M / 2.6M\r\n",
        "        - Total params: 4,767,402 , Trainable params: 2,600,426 , Non-trainable params: 2,166,976\r\n",
        "      - Regular Run: \r\n",
        "        - Train Time (time / verbose) = 160.71819162368774s / 200s\r\n",
        "        - Test Time (time / verbose) = 1.453615665435791s / 1s\r\n",
        "        - Test Time / sample (time / verbose) = 0.0012585417016760096s / 0.00087s\r\n",
        "        - Train / Val / Test Acc % = 84.8 / 89.6 / 83.6  \r\n",
        "      - CV: \r\n",
        "        - Validation Time (time) = 992.2293410301208s\r\n",
        "        - Validation Accuracy Mean (+/- Std Deviation): 78.29% (+/- 1.35%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4BaEWfpoq28"
      },
      "source": [
        "### Version 0.17: ResNet50 XFR, MobileNet XFR, MobileNet FT Baseline Values "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HETNgK2Mgbai"
      },
      "source": [
        "- **0.17**: run for Epoch = 100\r\n",
        "  - XFR = Transfer Learning, FT = Fine tuning\r\n",
        "  - For Regular Run: Train & Test Acc is w.r.t. Best Val Accuracy.\r\n",
        "  - Common Hyper parameters: Batchsize = 10, Learning Rate = 0.01, Neurons after Conv = 512, Dropout = 0.4. \r\n",
        "  - **Resnet50 XFR**\r\n",
        "    - Conv Layer / Total Params / Trainable Params / FLOPS = 5 / 25M / 1M / 0.0021G   \r\n",
        "    - Regular Run: \r\n",
        "      - Train Time Verbose / Colab = 404s / 474.015s\r\n",
        "      - Test Time Verbose / Colab (1155 samples) = 4s / 490.921s ?\r\n",
        "      - Test Time per sample = 3.5ms / 425ms ?\r\n",
        "      - Train / Val / Test Acc % = 86.7 / 90.1 / 81.8\r\n",
        "    - CV: \r\n",
        "      - Validation Time (Colab) = 3030.406s\r\n",
        "      - Val Acc Mean (+/- Std Deviation): 87.86% (+/- 1.24%)\r\n",
        "  - **MobileNet**\r\n",
        "    - Conv Layer / FLOPS = 13 / 1.15G \r\n",
        "    - **XFR**\r\n",
        "      - Total Params / Trainable Params = 5M / 0.5M\r\n",
        "      - Regular Run:\r\n",
        "        - Train Time Verbose / Colab =  202s / 3192.38s ?\r\n",
        "        - Test Time Verbose / Colab (1155 samples) = 1s / 3198.253s ?\r\n",
        "        - Test Time per sample = 0.87ms / 2.77s ?\r\n",
        "        - Train / Val / Test Acc % = 82.1 / 84.2 / 77.8\r\n",
        "      - CV: \r\n",
        "        - Validation Time (Colab) = 4169.914s\r\n",
        "        - Val Acc Mean (+/- Std Deviation): 78.34% (+/- 1.30%)\r\n",
        "    - **FT**\r\n",
        "      - Total Params / Trainable Params = 5M / 2.6M\r\n",
        "      - Regular Run: \r\n",
        "        - Train Time Verbose / Colab = 200s / 4328.194s ?\r\n",
        "        - Test Time Verbose / Colab (1155 samples) = 1s / 4333.798s ?\r\n",
        "        - Test Time per sample = 0.87ms / 3.75s ?\r\n",
        "        - Train / Val / Test Acc % = 82.6 / 89.3 / 84.9  \r\n",
        "      - CV: \r\n",
        "        - Validation Time (Colab) = 5311.684s\r\n",
        "        - Val Acc Mean (+/- Std Deviation): 79.16% (+/- 1.23%)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoV84asAovk9"
      },
      "source": [
        "### Version 0.16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4-TN-AYYu1"
      },
      "source": [
        "- **0.16**\r\n",
        "  - Changed 'tf.keras.applications.mobilenet.MobileNet()' to 'mobilenet = tf.keras.applications.MobileNet()' to reconfirm using MobilenetV1\r\n",
        "  - mobilenet = tf.keras.applications.mobilenet.MobileNet()\r\n",
        "    - Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\r\n",
        "  - mobilenet = tf.keras.applications.MobileNet()\r\n",
        "    - Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\r\n",
        "  - ResNet50 Transfer\r\n",
        "      - Regular Run: Train/Val/Test Acc = 61.2 / 74.3 / 73.3   \r\n",
        "      - CV Run:  Validation Accuracy Mean (+/- Std Deviation): 77.90% (+/- 1.05%)\r\n",
        "  - MobileNet Transfer\r\n",
        "      - Regular Run: Train/Val/Test Acc = 70.1 / 76.5 / 74.0\r\n",
        "      - CV Run:  Validation Accuracy Mean (+/- Std Deviation): 76.69% (+/- 1.32%)\r\n",
        "  - MobileNet FineTune\r\n",
        "      - Regular Run: Train/Val/Test Acc = 76.4 / 80.5 / 76.5 \r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 77.77% (+/- 2.34%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlW_uOwYIEv3"
      },
      "source": [
        "### Version 0.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaYet9a9IFz9"
      },
      "source": [
        "- **0.15**: implemented flops\r\n",
        "    - ResNet50 Transfer - 0.0021G\r\n",
        "      - Regular Run: Train/Val/Test Acc = 59.5 / 73.5 / 71.0 \r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 79.34% (+/- 1.76%)\r\n",
        "    - MobileNet Transfer - 1.15G\r\n",
        "      - Regular Run: Train/Val/Test Acc =  71.0 / 82.4 / 75.6\r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 76.03% (+/- 1.57%)\r\n",
        "    - MobileNet FineTune - 1.15G\r\n",
        "      - Regular Run: Train/Val/Test Acc =  76.9 / 83.2 / 77.1  \r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 75.16% (+/- 0.93%)\r\n",
        "\r\n",
        "- Note:Â XFR = Transfer Learning, FT = Fine tuning, Train & Test Acc is w.r.t. Best Val Accuracy. Common Hyper parameters: Batchsize = 10, Learning Rate = 0.01, Neurons after Conv = 512, Dropout = 0.4.\r\n",
        "  - Without cross-validation, withÂ same hyper parameters, Test Accuracy/Total Params/Trainable Params/No. of Convolution Layers/FLOPS/Train Time/Test Time/Test Time per SampleÂ  Â  \r\n",
        "    - Below is for Epoch = 100Â  Â  \r\n",
        "    - Resnet50 XFR (~81%/~25M/~1M/5 Conv/0.0021G/~300s/3s/~2.6ms)Â  Â  \r\n",
        "    - MobileNet XFR (~78%/~5M/~0.5M/13 Conv/1.15G/~200s/1s/~0.87ms)Â  Â  \r\n",
        "    - MobileNet FT (~79%/~5M/~2.6M/13 Conv/1.15G/~200s/1s/~0.87ms)\r\n",
        "  - With cross-validation, with same hyper parameters, Test Accuracy Mean +/- Std Dev/Total Params/Trainable Params/No. of Convolution Layers/FLOPSÂ  Â  \r\n",
        "    - Below is for Epoch = 1, Cross Validation Folds = 4Â  Â  \r\n",
        "    - Resnet50 XFR (79.34%Â (+/-Â 1.76%)/~25M/~1M/5 Conv/0.0021G)Â  Â  \r\n",
        "    - MobileNet XFR (76.03%Â (+/-Â 1.57%)/~5M/~0.5M/13 Conv/1.15G)Â  Â  \r\n",
        "    - MobileNet FT (75.16%Â (+/-Â 0.93%)/~5M/~2.6M/13 Conv/1.15G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dalPY9JlUjk"
      },
      "source": [
        "### Version 0.12-0.14 (Implemented Cross Validation for 1 Epoch, 4 Folds: Other hyperparameters same as in v0.11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdyIzgHjlaS6"
      },
      "source": [
        "- **0.12**: rerun to baseline\r\n",
        "- **0.13**\r\n",
        "  - **epoch = 1, fold = 2**\r\n",
        "  - saved labels before conversion to categorical\r\n",
        "  - added code macros for cross validation = true, fold = 2 \r\n",
        "  - added code for cross-validation for resnet50 transfer learning\r\n",
        "  - added code for cross-validation for mobilenet transfer learning \r\n",
        "  - ResNet50 Transfer\r\n",
        "    - Regular Run: Train/Val/Test Acc = 57.0 / 73.5 / 70.7\r\n",
        "    - CV Run: Validation Accuracy Mean (+/- Std Deviation): 74.64% (+/- 1.51%)\r\n",
        "  - MobileNet Transfer\r\n",
        "    - Regular Run: Train/Val/Test Acc = 69.1 / 77.3 / 74.5\r\n",
        "    - CV Run: Validation Accuracy Mean (+/- Std Deviation): 75.82% (+/- 0.27%)\r\n",
        "- **0.14**\r\n",
        "  - **epoch = 100, fold = 4**\r\n",
        "    - ResNet50 Transfer\r\n",
        "      - Regular Run: Train/Val/Test Acc = 88.1 / 88.8 / 79\r\n",
        "      - CV Run: only for 1 fold ... 88.4 .. later I interrupted\r\n",
        "    - MobileNet Transfer\r\n",
        "      - Regular Run: Train/Val/Test Acc .. later I interrupted\r\n",
        "      - CV Run: .. later I interrupted\r\n",
        "  - **epoch = 1, fold = 4**\r\n",
        "    - ResNet50 Transfer\r\n",
        "      - Regular Run: Train/Val/Test Acc =  60.0 / 72.7 / 69.7\r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 79.16% (+/- 2.54%)\r\n",
        "    - MobileNet Transfer\r\n",
        "      - Regular Run: Train/Val/Test Acc =  71.6 / 80.5 / 74.8\r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 75.64% (+/- 1.61%) \r\n",
        "    - MobileNet FineTune\r\n",
        "      - CV done before the regular run of train/val/test to ensure we use the weights from transfer and not from regular run of finetune.\r\n",
        "      - CV Run:  Validation Accuracy Mean (+/- Std Deviation): 77.82% (+/- 2.03%)\r\n",
        "      - Regular Run: Train/Val/Test Acc =  75.3 / 81.8 / 76.6\r\n",
        "  - Updated code to have separate checkpoint files for each model. Cross-validation of MobileNet FineTune Model uses MobileNet Transfer file for initialization.\r\n",
        "    - **epoch = 1, fold = 4**\r\n",
        "    - ResNet50 Transfer\r\n",
        "      - Regular Run: Train/Val/Test Acc = 61.5 / 71.9 / 72.1 \r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 78.78% (+/- 3.65%)\r\n",
        "    - MobileNet Transfer\r\n",
        "      - Regular Run: Train/Val/Test Acc = 68.0 / 81.3 / 75.6 \r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 76.64% (+/- 0.98%)\r\n",
        "    - MobileNet FineTune\r\n",
        "      - Regular Run: Train/Val/Test Acc = 74.6 / 81.8 / 76.9  \r\n",
        "      - CV Run: Validation Accuracy Mean (+/- Std Deviation): 76.03% (+/- 1.67%)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttCQhWPHOCE"
      },
      "source": [
        "### Version 0.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siGkxsXEHSUJ"
      },
      "source": [
        "- **0.11** \r\n",
        "  - As is Rerun\r\n",
        "    - Epoch = 100, Batchsize = 10, Learning Rate = 0.01, Neurons = 512, Dropout = 0.4. Train & Test Acc is w.r.t. Best Val Accuracy.\r\n",
        "    - ResNet50 (Transfer Learning) - 5 Convolution Layers\r\n",
        "      - Total/Trainable Params: 24.64M/1.05M\r\n",
        "      - Train + Validation Time: (8s x 1) + (3s x 99) = 305s\r\n",
        "      - Test Time: 3s, Test/sample = (3/1155)s = 0.0026s = 2.6ms  \r\n",
        "      - Train/Val/Test Acc: 93.7 / 89.0 / 80.7\r\n",
        "    - MobileNet - 13 Convolution Layers\r\n",
        "      - Transfer Learning\r\n",
        "        - Total/Trainable Params: 4.77M/0.51M\r\n",
        "        - Train + Validation Time: (4s x 1) + (max 2s x 99) = 202s\r\n",
        "        - Test Time: 1s, Test/sample = (1/1155)s = 0.87ms \r\n",
        "        - Train/Val/Test Acc: 79.5 / 84.2 / 78.0\r\n",
        "      - Finetuning\r\n",
        "        - Total/Trainable Params: 4.77M/2.60M\r\n",
        "        - Train + Validation Time: (max 2s x 100) = 200s\r\n",
        "        - Test Time: 1s, Test/sample = (1/1155)s = 0.87ms \r\n",
        "        - Train/Val/Test Acc: 88.2 / 84.2 / 78.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1XTl8F6sKrr"
      },
      "source": [
        "### Version 0.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CrC5fg4sTgX"
      },
      "source": [
        "- **0.10** \r\n",
        "  - Cleaned up indenting\r\n",
        "  - Added hyperparameter macros that can be used for all models\r\n",
        "    - ResNet50 was with 1024 neurons, 40% dropout\r\n",
        "    - MobileNet was with 512 neurons, 60% dropout.\r\n",
        "    - Made EPOCHS = 100, BATCH_SIZE = 10, LEARNING_RATE = 0.01, DENSE_LAYER_NEURONS = 512, DENSE_LAYER_DROPOUT = 0.4\r\n",
        "  - Implemented 'checkpoint' as a function to be used a callback by any model. Enabled callback for ResNet50\r\n",
        "  - Accuracy\r\n",
        "    - ResNet50 (XFR Learning): Best_Train/Best_Val/Test = 89.4 / 88.8 / 80.7\r\n",
        "    - MobileNet (XFR Learning): Best_Train/Best_Val/Test = 83.6 / 85.0 / 77.6\r\n",
        "    - MobileNet (Fine Tuning): Best_Train/Best_Val/Test = 86.9 / 84.0 / 77.7\r\n",
        "  \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z__HJG6gIxMj"
      },
      "source": [
        "### Version 0.09"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E9zAmtKTUx1"
      },
      "source": [
        "- **0.09** **MobileNet**\n",
        "  - **Epoch=100**: img resize: lr=0.01: BN = N: **Dropout = 0.4**: Params (Total/Trainable/Non-trainable)= 5,280,938 / 1,027,074 / 4,253,864: Train/Val/Test Acc = 87.4/80.8/78.0\n",
        "  - Epoch=100: **Best Model**: Train/Val/Test Acc = 82.1/84.0/77.8\n",
        "  - **Epoch=200**: Best Model: Train/Val/Test Acc = 79.0/84.0/78.9\n",
        "  - **Epoch=100**: Best Model: **Regularizer: Kernel/Bias L2(0.01) for Dense(1024)**: Train/Val/Test Acc = 70.6/80.0/72.5\n",
        "  - Epoch=100: Best Model: Regularizer: Kernel/Bias L2(0.01) for Dense(1024), **Dense(2)**: Train/Val/Test Acc = 69.0/78.3/72.6\n",
        "  - Epoch=100: Best Model: Regularizer: Kernel/Bias **L1**(0.01) for Dense(1024), Dense(2): Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n",
        "  - Epoch=100: Best Model: Regularizer: Kernel/Bias/**Activity L2**(0.01) for Dense(1024), Dense(2): Train/Val/Test Acc = 68.1/79.1/72.4\n",
        "  - Epoch=100: Best Model: Regularizer: Kernel/Bias/Activity L2**(0.2)** for Dense(1024), Dense(2): Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n",
        "  - Epoch=100: Best Model: Regularizer: Kernel/Bias/Activity L2**(1e-4/1e-4/1e-5)** for Dense(1024), Dense(2): Train/Val/Test Acc = 77.6/84.0/77.5 ... regularizer is not helping much ... revert to No Regularizer\n",
        "  - **Best Model**: **Epoch=100**: Train/Val/Test Acc = 81.5/84.5/77.8\n",
        "  - Best Model: **Epoch=1**: **Nottrainable/trainabele layers = 0-79/80-94**:  Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n",
        "  - Best Model: **Epoch=100**: NonTrainable(MobileNet)+ Trainable(Dense(1024), Dropout, Dense(2)): Train/Val/Test Acc = 82.3/85/79\n",
        "  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(**512**), Dropout, Dense(2)): Train/Val/Test Acc = 82.1/84.8/78.7\n",
        "  - Best Model: Epoch=100: **MobileNet NT till Conv13 (0-85), T for Rest** + Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n",
        "  - Best Model: Epoch=100: MobileNet NT **till Conv12 (0-79)**, T for Rest** + Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = val acc was ~55% for 20 epochs so interrupted it\n",
        "  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(**512**), Dropout, Dense(2)): Train/Val/Test Acc = 88.5/85.0/77.7\n",
        "  - Best Model: Epoch=100: **NonTrainable(MobileNet)+ Trainable(Dense(**512**), Dropout, Dense(2)) -> save and load weights -> NonTrainable(MobileNet till <86) Trainable (86 and later = GAP...)+ Trainable(Dense(**512**), Dropout, Dense(2))**: Train/Val/Test Acc = 78.7/84.8/76.8 -> ../84.8/76.8\n",
        "  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(512), Dropout, Dense(2)) -> save and load weights -> NonTrainable(MobileNet **till <80**) Trainable (80 and later = **Conv13,GAP...**)+ Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = 82.1/84.2/78.2 -> ../84.2/78.2\n",
        "  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(512), Dropout, Dense(2)) -> save and load weights -> NonTrainable(MobileNet **till <73**) Trainable (73 and later = **Conv12,Conv13,GAP...**)+ Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = 80.1/84.2/78.4 -> ../84.2/78.4 \n",
        "  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(512), Dropout, Dense(2)) -> save and load weights -> **Trainable(MobileNet till <73**) Trainable (73 and later = **Conv12,Conv13,GAP...**)+ Trainable(Dense(512), Dropout, Dense(2)): Train/Val/Test Acc = 81.8/84.2/78.3 -> 86.2/84.5/78.4\n",
        "  - Best Model: Epoch=100: NonTrainable(MobileNet)+ Trainable(Dense(512), Dropout, Dense(2)) -> save and load weights -> NonTrainable(MobileNet **till <80**) Trainable (80 and later = **Conv13,GAP...**)+ Trainable(Dense(512), Dropout, Dense(2)): Params (Total/Trainable/Non-trainable)= 4,767,402 / 2,600,426 / 2,166,976: Train/Val/Test Acc = 79.8/84.8/78.4 -> ../84.8/78.4\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Ryh-JimjiK"
      },
      "source": [
        "### Version 0.08"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pCxVDSZmlkq"
      },
      "source": [
        "- **0.08** **MobileNet**\r\n",
        "  - Changed model to Pre-trained MobileNet\r\n",
        "  - Epoch=1: **img resize**: lr=0.01: BN = N: Dropout = N: Train/Val/Test Acc = 68.2/76.5/73.8\r\n",
        "  - Epoch=10: img resize: lr=0.01: BN = N: Dropout = N: Train/Val/Test Acc = 80.5/82.4/78.9\r\n",
        "  - **Epoch=20**: img resize: lr=0.01: BN = N: Dropout = N:Train/Val/Test Acc = 83.7/79.2/76.5 ... revert to Epoch=10\r\n",
        "  - **Epoch=10**: img resize: **lr=0.0001**: BN = N: Dropout = N:Train/Val/Test Acc = 71.9/78.6/73.6 ... revert to lr=0.01\r\n",
        "  - Epoch=10: img resize: **lr=0.01**: **BN = Y**: Dropout = N: Train/Val/Test Acc = 83.0/77.8/71.0 revert to BN = N\r\n",
        "  - Epoch=10: img resize: lr=0.01: **BN = N**: **Dropout = 0.2**: Train/Val/Test Acc = 77.1/80.8/76.9\r\n",
        "  - Epoch=10: img resize: lr=0.01: BN = N: **Dropout = 0.4**: Train/Val/Test Acc = 78.8/82.6/78.0\r\n",
        "  - **Epoch=20**: img resize: lr=0.01: BN = N: Dropout = 0.4: Train/Val/Test Acc = 81.6/76.6/75.4 ... revert to Epoch = 10\r\n",
        "  - **Epoch=10**: img resize: lr=0.01: BN = N: **Dropout = 0.5**: Train/Val/Test Acc = 78.3/84.2/77.8 ... revert to Dropout = 0.4\r\n",
        "  - Epoch=10: img resize: lr=0.01: BN = N: **Dropout = 0.4**: Params (Total/Trainable/Non-trainable)= 5,280,938 / 1,027,074 / 4,253,864: Train/Val/Test Acc = 78.3/79.1/76.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho0vVgWAmbpf"
      },
      "source": [
        "### Version 0.07"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySQuE0MtmeoC"
      },
      "source": [
        "- **0.07** **ResNet50**\r\n",
        "  - As is rerun: Epoch=20: Adam(lr=0.01): Dropout(0.4): No BN: batch size = 10: Train/Val/Test Acc = 86.7/86.6/81.4\r\n",
        "  - Change **batch size** from 10 to 20: Train/Val/Test Acc = 91.2/83.7/78.9 ... reduces accuracy, so reverted to batch size of 10\r\n",
        "  - Implemented **Data Augmentation** with batch size of 10: Train/Val/Test Acc = 78.1/79.7/69.0 ...reduces accuracy, should we increase batch size?\r\n",
        "  - Implemented **Data Augmentation** with batch size of 100: Train/Val/Test Acc = 89.3/72.2/67.9 ...reduces accuracy, should we decrease batch size?\r\n",
        "  - Implemented **Data Augmentation** with batch size of 5: Train/Val/Test Acc = 58.3/48.4/48.1  ... reduces accuracy, reverted to batch size of 10, and no Data Augmentation\r\n",
        "  - Epoch=20: Adam(lr=0.01): Dropout(0.4): No BN: **batch size = 10**: **No DataAug**: Params (Total/Trainable/Non-trainable)= 25,687,938 / 2,100,226 / 23,587,712: Train/Val/Test Acc = 91.8/90.6/81.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs0QIeKrmMQ1"
      },
      "source": [
        "### Version 0.06"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nvsJYrimP-N"
      },
      "source": [
        "- **0.06** **ResNet50**\r\n",
        "  - Before any modification: full rerun took ~15mins (most of it for loading train/val/test images/labels... and very less for model training/test)\r\n",
        "  - Before any modification: Train/Val/Test Acc = 53/51.1/51.3\r\n",
        "  - Changed model = Pre-trained ResNet50 + Modified FCN Layer\r\n",
        "    - SGD (LR=0.0001, M=0.9), Categorical Crossentropy\r\n",
        "    - 1st run: Train/Val/Test Acc = 57.5/72.7/67.1\r\n",
        "    - Converted ones/zeroes count to function\r\n",
        "    - Converted images/label prep to function\r\n",
        "    - Epoch=1: Train/Val/Test Acc = 61/67.9/67\r\n",
        "    - Epoch=5: Train/Val/Test Acc = 85.6/80.8/75.9\r\n",
        "    - Epoch=10: Train/Val/Test Acc = 93.0/85.6/77.7\r\n",
        "    - Epoch=20: Train/Val/Test Acc = 94.1/89.0/80.4\r\n",
        "    - Epoch=20: Changed loss function to 'binary crossentropy', reduced the accuracy: Train/Val/Test Acc = 90.2/84.0/77.7 Hence, reverted to categorical crossentropy as the loss function\r\n",
        "    - Epoch=20: Changed optimizer to Adam(lr=0.01), increased accuracy: Train/Val/Test Acc = 99.3/86.9/83.2\r\n",
        "    - In above training accuracy is high, validation and test accuracy is low ... it is overfitting ... let us implement Dropout\r\n",
        "    - Epoch=20: Adam(lr=0.01): Dropout(0.2): Train/Val/Test Acc = 93.0/88.8/82.1\r\n",
        "    - Epoch=20: Adam(lr=0.01): Dropout(0.4): Train/Val/Test Acc = 90.8/89.8/83.4\r\n",
        "    - Epoch=20: Adam(lr=0.01): Dropout(0.5): Train/Val/Test Acc = 92.2/90.6/82.3 .. reverted to Dropout(0.4)\r\n",
        "    - Let us try Batch Normalization. ResNet50 -> Dense (1024) -> Batch Norm -> relu -> Dropout -> Dense(2,softmax)\r\n",
        "    - Epoch=20: Adam(lr=0.01): Dropout(0.4): BN: Train/Val/Test Acc = 90.6/81.6/79.0 ... reduced accuracy\r\n",
        "    - Epoch=20: Adam(lr=0.01): Dropout(0.2): BN: Train/Val/Test Acc = 95.2/86.9/81.9 ... reduced accuracy will revert to no BN, Dropout(0.4)\r\n",
        "    - Epoch=20: Adam(lr=0.01): Dropout(0.4): Train/Val/Test Acc = 88.2/89.3/81.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg96Q_kol8D-"
      },
      "source": [
        "### Version 0.01 - 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpcAkTc8hKcL"
      },
      "source": [
        "- **0.05**: Migrate to Google Colab/Drive, changed loss function to 'binary_crossentropy', epochs to 1 : Train/Val/Test Acc = 55.7/55.9/55.2\r\n",
        "- **0.04**: Class Label Info in List was not accurate - fixed it. Now, Train/Validate/Test Accuracy is more realistic = ~55%\r\n",
        "- **0.03**: Tweak CNN model done for MNIST to work for this dataset to have a working end to end CNN model. Train/Validate/Test Accuracy = ~100%\r\n",
        "- **0.02**: Prepare Train/Validate/Test Labels and Images \r\n",
        "- **0.01**: Prepare Train/Validate/Test Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLXoJsxynoCB"
      },
      "source": [
        "### References - Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-HdlAy_TUx3"
      },
      "source": [
        "- Access Google Drive files from Google Colab\n",
        "  - https://www.youtube.com/watch?reload=9&v=lHRC5gFvQnA\n",
        "- Reading an image\n",
        "  - mathplotlib: https://stackoverflow.com/questions/9298665/cannot-import-scipy-misc-imread\n",
        "  - pathlib: https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f#:~:text=To%20use%20it%2C%20you%20just,for%20the%20current%20operating%20system.\n",
        "  - OpenCV: https://www.geeksforgeeks.org/python-opencv-cv2-imread-method/\n",
        "- Load multiple images into a numpy array\n",
        "  - glob / os.listdir: https://stackoverflow.com/questions/39195113/how-to-load-multiple-images-in-a-numpy-array\n",
        "  - glob / cv2: https://medium.com/@muskulpesent/create-numpy-array-of-images-fecb4e514c4b\n",
        "- Load a CSV file\n",
        "  - Datacamp: https://www.datacamp.com/community/tutorials/pandas-read-csv?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=278443377095&utm_targetid=dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=9061994&gclid=EAIaIQobChMIz5TKz-v17QIV1AorCh0bfw96EAAYASAAEgKiGPD_BwE\n",
        "- Split a String\n",
        "  - Python Central: https://www.pythoncentral.io/cutting-and-slicing-strings-in-python/\n",
        "- Image Resize\n",
        "  - https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n",
        "  - https://stackoverflow.com/questions/55571664/mobilenets-for-a-custom-image-size\n",
        "- Merge Train/Val/Test data\n",
        "  - Merge Dataframes\n",
        "    - https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
        "  - Merge and Split Dataframes\n",
        "    - https://datascience.stackexchange.com/questions/81617/how-to-combine-and-separate-test-and-train-data-for-data-cleaning\n",
        "  - \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEayMrPQnvSL"
      },
      "source": [
        "### References - Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CPryaAbn0xA"
      },
      "source": [
        "- ResNet50\r\n",
        "  - https://cv-tricks.com/keras/understand-implement-resnets/\r\n",
        "  - Finetuning ResNet50\r\n",
        "    - https://www.pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/\r\n",
        "- MobileNet\r\n",
        "  - https://deeplizard.com/learn/video/Zrt76AIbeh4\r\n",
        "  - https://towardsdatascience.com/exploring-mobilenets-from-paper-to-keras-f01308ada818\r\n",
        "  - Fine Tuning MobileNet - Last few layers trainable\r\n",
        "    - https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299\r\n",
        "  - MobileNet Version:\r\n",
        "    - https://keras.io/api/applications/mobilenet/\r\n",
        "- SqueezeNet\r\n",
        "  - https://codelabs.developers.google.com/codelabs/keras-flowers-squeezenet#6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s5vSukpETho"
      },
      "source": [
        "### References - Model Validation\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOGLP3V-EcGc"
      },
      "source": [
        "- Keras Optimizer / Adam\r\n",
        "  - https://keras.io/api/optimizers/\r\n",
        "- Regularizer\r\n",
        "  - https://keras.io/api/layers/regularizers/\r\n",
        "- Save Weights for Best Model\r\n",
        "  - https://medium.com/@italojs/saving-your-weights-for-each-epoch-keras-callbacks-b494d9648202\r\n",
        "  - Monitoring Validaiton Accuracy - Skipping Error Solution\r\n",
        "    - https://github.com/tensorflow/tensorflow/issues/33163\r\n",
        "  - Predict using saved model\r\n",
        "    - https://stackoverflow.com/questions/44259651/how-to-use-predefined-trained-hdf5-file-with-wights-to-predict-a-class-of-new\r\n",
        "- K-cross validation: https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538\r\n",
        "  - use non-categorical labels for k-cross validation splits: https://stackoverflow.com/questions/48508036/sklearn-stratifiedkfold-valueerror-supported-target-types-are-binary-mul\r\n",
        "  - https://machinelearningmastery.com/ : Deep Learning with Python Book\r\n",
        "- FLOPS calculation\r\n",
        "  - https://pypi.org/project/keras-flops/\r\n",
        "  - https://www.manongdao.com/article-1967231.html\r\n",
        "- Time calculation\r\n",
        "  - https://www.tutorialspoint.com/How-to-get-current-time-in-milliseconds-in-Python#:~:text=You%20can%20get%20the%20current,1000%20and%20round%20it%20off.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ertTy-ugCmNB"
      },
      "source": [
        "### References - Model Conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HKX8stlbHQ4"
      },
      "source": [
        "- Convert to TensorFlowLite Model\r\n",
        "  - https://heartbeat.fritz.ai/image-recognition-for-android-with-a-custom-tensorflow-lite-model-6418186ecc0e\r\n",
        "\r\n",
        "- Convert a Keras Model to TensorFlowLite\r\n",
        "  - refer the section 'Convert a Keras Model' at: https://www.tensorflow.org/lite/convert\r\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5a9JCX_KxQL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}